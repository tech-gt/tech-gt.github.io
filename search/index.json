[{"content":"什么是响应式编程？ 响应式编程是一种面向数据流 (Data Stream) 和变化传播 (Propagation of Change) 的异步编程范式。 想象一下，你的程序不再是像传统命令式编程那样，主动去请求（pull）数据并等待结果，而是被动地响应一个或多个事件/数据流。当流中有新的数据、错误或者完成信号时，你的程序会被“通知”并执行相应的逻辑。\n它的核心思想可以类比于Excel的公式：\n在 Excel 中，单元格 C1 的值可以定义为 =A1+B1。 你不需要编写一个循环来不断检查 A1 或 B1 是否发生了变化。 当你修改了 A1 或 B1 的值，C1 的值会自动地、响应式地更新。 响应式编程将各种事件（用户点击、HTTP 请求、数据库查询结果等）都看作是数据流。你可以对这些流进行组合、过滤、转换和处理，构建出复杂的异步逻辑。\n响应式编程的优势 响应性 (Responsive): 系统能够及时地对事件做出反应。 弹性 (Resilient): 系统在出现故障时仍能保持响应，例如通过隔离和恢复机制。 伸缩性 (Elastic): 系统在不同负载下都能保持响应性，可以方便地进行扩展。 消息驱动 (Message Driven): 组件之间通过异步消息进行交互，实现松耦合和位置透明性。 微服务中的 RPC 调用：传统方式 vs. 响应式方式 在微服务架构中，一个服务经常需要调用另一个服务提供的接口（RPC），比如订单服务需要调用用户服务来获取用户信息。让我们来看一下两种编程模型的代码对比。\n假设我们有两个服务：OrderService 和 UserService。OrderService 需要调用 UserService 的 getUserById 方法。\n场景：获取订单及其用户信息 1 传统的阻塞式 RPC 调用\n这种方式是最直观的。OrderService 发起一个网络请求到 UserService，然后阻塞当前线程，直到 UserService 返回结果。\n依赖 (常见库): Spring MVC, Feign/Dubbo (默认阻塞模式)\nUserService 接口定义 (例如使用 Feign):\n1 2 3 4 5 6 7 8 9 // 在 OrderService 中定义一个 Feign 客户端来调用 UserService @FeignClient(name = \u0026#34;user-service\u0026#34;) public interface UserServiceClient { // 这是一个标准的、同步阻塞的方法定义 @GetMapping(\u0026#34;/users/{id}\u0026#34;) User getUserById(@PathVariable(\u0026#34;id\u0026#34;) Long id); } OrderService 中的调用代码:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 @Service public class OrderServiceImpl { @Autowired private OrderRepository orderRepository; @Autowired private UserServiceClient userServiceClient; public OrderDetails getOrderDetails(Long orderId) { // 1. 从数据库获取订单 (一般是I/O操作) Order order = orderRepository.findById(orderId).orElse(null); if (order == null) { return null; } // 2. 发起远程RPC调用，线程在此处阻塞，等待UserService响应 // 如果UserService响应慢，整个处理流程都会被卡住 System.out.println(\u0026#34;线程 \u0026#34; + Thread.currentThread().getName() + \u0026#34; 开始调用用户服务...\u0026#34;); User user = userServiceClient.getUserById(order.getUserId()); // \u0026lt;--- 关键点：阻塞发生在这里 System.out.println(\u0026#34;线程 \u0026#34; + Thread.currentThread().getName() + \u0026#34; 用户服务调用完成.\u0026#34;); // 3. 组装最终结果 return new OrderDetails(order, user); } } 传统方式的问题:\n资源浪费: 在等待 UserService 响应期间（这可能包括网络延迟、UserService 自身处理时间等），执行 getOrderDetails 的线程被完全阻塞，不能做任何其他事情。 低吞吐量: 如果有大量并发请求进入 OrderService，就需要大量的线程来处理。线程是昂贵的系统资源，无限增加线程会导致内存耗尽和频繁的上下文切换，反而降低系统整体的吞吐量。 雪崩效应: 如果 UserService 变慢或无响应，所有调用它的 OrderService 线程都会被阻塞。最终，OrderService 的线程池会被耗尽，导致它也无法响应任何其他请求，问题会像雪崩一样蔓延到整个系统。 2 响应式 RPC 调用\n在这种方式下，OrderService 发起请求后不会阻塞线程，而是提供一个“回调”或订阅一个“发布者”。当 UserService 的数据准备好后，响应式框架会使用少量的工作线程来处理这个结果。\n依赖 (常见库): Spring WebFlux, Reactor, RxJava, R2DBC (响应式数据库驱动)\nUserService 接口定义 (例如使用 WebClient 或响应式 Feign):\n1 2 3 4 5 6 7 8 9 // 在 OrderService 中定义一个响应式客户端 // 注意返回类型不再是 User，而是 Mono\u0026lt;User\u0026gt; // Mono 代表一个包含 0 或 1 个元素的异步序列 public interface UserServiceClient { // 返回一个 Mono\u0026lt;User\u0026gt;，表示这是一个异步的调用，未来会返回一个User @GetExchange(\u0026#34;/users/{id}\u0026#34;) Mono\u0026lt;User\u0026gt; getUserById(@PathVariable(\u0026#34;id\u0026#34;) Long id); } OrderService 中的响应式调用代码:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 @Service public class OrderServiceImpl { @Autowired private ReactiveOrderRepository orderRepository; // 响应式数据库操作 @Autowired private UserServiceClient userServiceClient; // 响应式客户端 public Mono\u0026lt;OrderDetails\u0026gt; getOrderDetails(Long orderId) { // 整个调用链是声明式的，在调用 `subscribe()` 之前不会真正执行 System.out.println(\u0026#34;线程 \u0026#34; + Thread.currentThread().getName() + \u0026#34; 开始定义响应式流...\u0026#34;); // 1. 从数据库异步获取订单，返回 Mono\u0026lt;Order\u0026gt; // 这是一个异步的操作，不会阻塞当前线程 // 当数据库返回订单数据时，会触发后续的操作 return orderRepository.findById(orderId) // 2. 当订单数据流到达时，使用 flatMap 切换到另一个异步调用 // flatMap 用于处理异步操作的链式调用，避免了 \u0026#34;回调地狱\u0026#34; .flatMap(order -\u0026gt; { // 3. 异步发起RPC调用，立即返回 Mono\u0026lt;User\u0026gt;，当前线程不会阻塞 // 网络请求会在后台由Netty框架的少数I/O线程处理 System.out.println(\u0026#34;线程 \u0026#34; + Thread.currentThread().getName() + \u0026#34; 准备调用用户服务(非阻塞)...\u0026#34;); Mono\u0026lt;User\u0026gt; userMono = userServiceClient.getUserById(order.getUserId()); // 4. 当用户信息也到达时，将 order 和 user 组合起来 return userMono.map(user -\u0026gt; new OrderDetails(order, user)); }) .doOnSuccess(details -\u0026gt; { // 当最终结果成功产生时，这个回调会被执行 System.out.println(\u0026#34;线程 \u0026#34; + Thread.currentThread().getName() + \u0026#34; 成功组装OrderDetails.\u0026#34;); }); } } 响应式编程的优势总结 通过上面的代码对比，我们可以清晰地看到响应式编程在微服务 RPC 调用中的优势：\n高吞吐量和资源效率 (High Throughput \u0026amp; Resource Efficiency): 非阻塞: 线程在等待网络 I/O 或数据库响应时不会被阻塞，可以立即去处理其他请求。 少量线程处理高并发: 响应式框架（如 Spring WebFlux 底层的 Netty）使用固定数量的少量事件循环线程（Event Loop, 通常与 CPU 核心数相同）来处理成千上万的并发连接。这极大地减少了线程创建和上下文切换的开销，从而用更少的资源支持更高的并发量。 增强的弹性和韧性 (Enhanced Resilience): 背压 (Backpressure): 响应式流原生支持背压机制。背压的典型场景 (Flux) 例如，如果UserService 提供了如下接口：Flux\u0026lt;User\u0026gt; getAllUsers(); 如果消费者（OrderService）处理不过来，它可以向上游的生产者（UserService）发送信号，让其减慢数据发送速度，从而防止消费者因数据过载而崩溃。这是传统阻塞模式难以做到的。 易于实现容错: 响应式库（如 Reactor/RxJava）提供了丰富的操作符（Operators）来处理错误，例如 onErrorReturn (出错时返回默认值), retry (自动重试), timeout (超时处理) 等。这些都可以优雅地整合到调用链中，使容错逻辑更清晰。 1 2 3 4 // 示例：增加超时和降级逻辑 userServiceClient.getUserById(order.getUserId()) .timeout(Duration.ofSeconds(2)) // 2秒超时 .onErrorReturn(new User(\u0026#34;Default User\u0026#34;)); // 出错或超时则返回默认用户 更强的伸缩性 (Better Elasticity): 由于资源利用率更高，单个服务实例可以处理更多的请求。这意味着在流量高峰期，系统可以更平滑地进行水平扩展，而不需要仅仅因为线程阻塞就过早地增加大量实例。 代码更具声明性和可读性 (for complex async logic): 对于简单的 \u0026ldquo;请求-响应\u0026rdquo; 逻辑，传统代码可能更直观。但对于复杂的异步流程（例如：调用A，根据A的结果并行调用B和C，然后合并B和C的结果，再调用D），使用响应式流的链式调用可以避免“回调地狱 (Callback Hell)”，让复杂的异步逻辑像流水线一样清晰。 结论 响应式编程并非银弹，它带来了更高的学习曲线和不同的调试方式。但对于构建高并发、低延迟、资源敏感的现代微服务系统而言，它是一种极其强大的范式。 在 RPC 调用场景下，从阻塞式转向响应式，本质上是从“一个请求一个线程”的模型转变为“用少量线程处理大量并发请求”的模型。 这使得服务在面对高负载和下游服务延迟时，表现得更加健壮、高效和富有弹性，是构建现代化、高性能分布式系统的关键技术之一。\n","date":"2025-07-15T14:30:00+08:00","permalink":"https://tech-gt.github.io/p/%E5%93%8D%E5%BA%94%E5%BC%8F%E7%BC%96%E7%A8%8B%E5%9C%A8%E5%BE%AE%E6%9C%8D%E5%8A%A1%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/","title":"响应式编程在微服务中的应用"},{"content":"构建一个 MCP Server 听起来可能有些复杂，需要对协议规范有深入的理解。在 AI 辅助编程已成为新常态的今天，我们可以借助 AI 的力量，大大简化这一过程。\nMCP Server 核心概念 在深入实践之前，我们先简单了解一下 MCP 的核心架构。MCP 遵循客户端-服务器模型：\nMCP Client：通常内嵌在宿主应用（如 IDE、代码编辑器、聊天工具）中，负责与用户和 LLM 交互。Client一般不需要我们去开发。 MCP Server：一个独立的进程，负责向客户端提供特定的能力，如工具（Tools）、上下文资源（Resources）等。 基于 AI 辅助编写 MCP Server 在官方文档（https://modelcontextprotocol.io/quickstart/server） MCP Server 的开发方式，以及官方提供的各个语言的 SDK 的示例代码。 写的挺清晰的，如果你懂代码，仔细看一遍很快就能上手，但在 AI 时代，从零自己去写肯定不可能了，官方其实也建议通过 AI 来帮我们实现 MCP，所以在文档中单独还提供了一个 Building MCP with LLMs 的章节。 第一步：理解规范 (Understanding the Spec) 大概思路如下：\n在开始之前，收集必要的文档，以帮助 AI 了解 MCP：\n访问 https://modelcontextprotocol.io/llms-full.txt 并复制完整的文档文本。 导航到 MCP 的 TypeScript 软件开发工具包（SDK）或 Python 软件开发工具包的代码仓库。 复制（README）和其他相关文档。 将这些文档粘贴到你与克劳德的对话中。 提供了相关文档之后，向 AI 清晰地描述你想要构建的服务器类型：\n你的服务器将公开哪些资源。 它将提供哪些工具。 它应该给出的任何提示。 它需要与哪些外部系统进行交互。 比如这是一个例子：构建一个 MCP 服务器，该服务器：\n连接到我公司的 PostgreSQL 数据库。 将表模式作为资源公开。 提供用于运行只读 SQL 查询的工具。 包含针对常见数据分析任务的提示。 在实际测试中我发现，上面提到的 https://modelcontextprotocol.io/llms-full.txt 这个文档就是整个文档站的内容，里面包含了很多构建 MCP Server 不需要的内容，反而会给模型造成干扰，大家可以直接参考下面的提示词：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 ## 需求 基于提供的 MCP 相关资料，帮我构建一个 MCP Server，需求如下： - 提供一个获取当前时间的工具 - 接收时区作为参数（可选） - 编写清晰的注释和说明 - 要求功能简洁、只包含关键功能 - 使用 TypeScript 编写 请参考下面四个资料： ## [参考资料 1] MCP 基础介绍 - 粘贴 https://modelcontextprotocol.io/introduction 里的内容。 ## [参考资料 2] MCP 核心架构 - 粘贴 https://modelcontextprotocol.io/docs/concepts/architecture 里的内容。 ## [参考资料 3] MCP Server 开发指引 - 粘贴 https://modelcontextprotocol.io/quickstart/server 里的内容。 ## [参考资料 4] MCP Typescript SDK 文档 - 粘贴 https://github.com/modelcontextprotocol/typescript-sdk/blob/main/README.md 里的内容。 第二步：搭建项目骨架 (Scaffolding) 下面是一个 AI 帮我生成好的 MCP Server 的关键代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 import { McpServer } from \u0026#34;@modelcontextprotocol/sdk/server/mcp.js\u0026#34;; import { StdioServerTransport } from \u0026#34;@modelcontextprotocol/sdk/server/stdio.js\u0026#34;; import { z } from \u0026#34;zod\u0026#34;; const server = new McpServer({ name: \u0026#34;TimeServer\u0026#34;, // 服务器名称 version: \u0026#34;1.0.0\u0026#34;, // 服务器版本 }); server.tool( \u0026#34;getCurrentTime\u0026#34;, // 工具名称, \u0026#34;根据时区（可选）获取当前时间\u0026#34;, // 工具描述 { timezone: z .string() .optional() .describe( \u0026#34;时区，例如 \u0026#39;Asia/Shanghai\u0026#39;, \u0026#39;America/New_York\u0026#39; 等（如不提供，则使用系统默认时区）\u0026#34; ), }, async ({ timezone }) =\u0026gt; { // 具体工具实现，这里省略 } ); /** * 启动服务器，连接到标准输入/输出传输 */ async function startServer() { try { console.log(\u0026#34;正在启动 MCP 时间服务器...\u0026#34;); // 创建标准输入/输出传输 const transport = new StdioServerTransport(); // 连接服务器到传输 await server.connect(transport); console.log(\u0026#34;MCP 时间服务器已启动，等待请求...\u0026#34;); } catch (error) { console.error(\u0026#34;启动服务器时出错:\u0026#34;, error); process.exit(1); } } startServer(); 其实代码非常简单，我们可以拆分为三部分来理解：\n第一步：使用官方提供的 @modelcontextprotocol/sdk/server/mcp.js 包，创建一个 McpServer 实例。 第二步：使用 server.tool 定义提供的工具方法，包括工具方法的名称、工具方法的描述、工具方法的参数、工具方法的具体实现逻辑。\n另外使用了 \u0026ldquo;zod\u0026rdquo; 这个包定义了方法参数的类型以及描述。 第三步：启动 Server，并且使用 SDK 中导出的 StdioServerTransport 来定义工具使用 STDIO 通信协议，等待外部的标准输入，并且把工具的执行结果转化为标准输出反馈到外部。\n就是这么简单，我们只需要按照这个模板来添加更多的工具实现就可以了，另外 Resources、Prompt 的编写方式其实都是类似的，大家只需要按照这套提示词模板，定义好自己的需求，AI（Claude 的准确性最高）基本上都能比较完整的实现。\n使用 inspector 调试 MCP Server 开发完成后，我们可以直接使用官方提供的 MCP Server 调试工具（@modelcontextprotocol/inspector）来进行调试。 比如我们可以调试我们刚刚开发好的工具，这里直接使用 node 运行我们本地构建好的代码：\n1 npx @modelcontextprotocol/inspector node dist/index.js 启动成功后，它会在我们的本地监听 6274 端口，我们点击 Connect 连接成功后，我们点击 List Tools 然后可以看到当前 MCP Server 定义的所有工具，我们这里定义了一个获取当前时间的工具，我们点击这个工具，可以对它进行调试。\n","date":"2025-06-20T15:30:00+08:00","permalink":"https://tech-gt.github.io/p/ai-%E8%BE%85%E5%8A%A9%E7%BC%96%E7%A8%8B%E8%BD%BB%E6%9D%BE%E6%9E%84%E5%BB%BA-mcp-server/","title":"AI 辅助编程：轻松构建 MCP Server"},{"content":"前言 在现代Java应用开发中，线程池的使用已经成为标准实践。然而，线程池的引入却带来了一个棘手的问题：如何在异步执行的任务中传递ThreadLocal上下文？JDK原生的InheritableThreadLocal在线程池环境下失效，而阿里巴巴开源的TransmittableThreadLocal（TTL）正是为了解决这一痛点而生。\n1. 问题背景：ThreadLocal在线程池中的问题 1.1 ThreadLocal的局限性 ThreadLocal为每个线程维护独立的变量副本，在单线程或父子线程场景下工作良好：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // ThreadLocal在单线程中正常工作 public class ThreadLocalDemo { private static final ThreadLocal\u0026lt;String\u0026gt; context = new ThreadLocal\u0026lt;\u0026gt;(); public static void main(String[] args) { context.set(\u0026#34;主线程数据\u0026#34;); System.out.println(\u0026#34;主线程获取: \u0026#34; + context.get()); // 输出: 主线程数据 // 新建子线程 new Thread(() -\u0026gt; { System.out.println(\u0026#34;子线程获取: \u0026#34; + context.get()); // 输出: null }).start(); } } 1.2 InheritableThreadLocal的限制 InheritableThreadLocal可以实现父子线程间的值传递：\n1 2 3 4 5 6 7 8 9 10 11 12 public class InheritableThreadLocalDemo { private static final InheritableThreadLocal\u0026lt;String\u0026gt; context = new InheritableThreadLocal\u0026lt;\u0026gt;(); public static void main(String[] args) { context.set(\u0026#34;父线程数据\u0026#34;); new Thread(() -\u0026gt; { System.out.println(\u0026#34;子线程获取: \u0026#34; + context.get()); // 输出: 父线程数据 }).start(); } } 但在线程池环境下，InheritableThreadLocal失效：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 public class ThreadPoolProblem { private static final InheritableThreadLocal\u0026lt;String\u0026gt; context = new InheritableThreadLocal\u0026lt;\u0026gt;(); public static void main(String[] args) throws Exception { ExecutorService executor = Executors.newFixedThreadPool(1); context.set(\u0026#34;任务1的数据\u0026#34;); executor.submit(() -\u0026gt; { System.out.println(\u0026#34;任务1获取: \u0026#34; + context.get()); // 输出: 任务1的数据 }).get(); context.set(\u0026#34;任务2的数据\u0026#34;); executor.submit(() -\u0026gt; { System.out.println(\u0026#34;任务2获取: \u0026#34; + context.get()); // 输出: 任务1的数据 ❌ }).get(); executor.shutdown(); } } 问题根源：线程池中的线程是预创建并复用的，第二个任务执行时使用的是同一个工作线程，该线程仍然保留着第一个任务的上下文。\n2. TransmittableThreadLocal核心原理 2.1 设计思路 TTL的核心思想是将上下文传递从\u0026quot;父子线程关系\u0026quot;转变为\u0026quot;任务提交时间点到任务执行时间点\u0026quot;的传递：\n1 2 传统模式：父线程 → 子线程 TTL模式：任务提交时的线程上下文 → 任务执行时的线程上下文 2.2 核心机制：CRR模式 TTL采用Capture-Replay-Restore（捕获-回放-恢复）模式：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 // 简化的CRR流程 public class CRRDemo { private static final TransmittableThreadLocal\u0026lt;String\u0026gt; context = new TransmittableThreadLocal\u0026lt;\u0026gt;(); public void demonstrateCRR() { // 设置上下文 context.set(\u0026#34;业务数据\u0026#34;); // 1. Capture: 捕获当前所有TTL值 Object captured = TransmittableThreadLocal.Transmitter.capture(); // 模拟在另一个线程中执行 CompletableFuture.runAsync(() -\u0026gt; { // 2. Replay: 回放捕获的值 Object backup = TransmittableThreadLocal.Transmitter.replay(captured); try { // 这里可以正常获取到上下文 String value = context.get(); // \u0026#34;业务数据\u0026#34; System.out.println(\u0026#34;异步线程获取到: \u0026#34; + value); } finally { // 3. Restore: 恢复线程原始状态 TransmittableThreadLocal.Transmitter.restore(backup); } }).join(); } } 2.3 内部实现机制 TTL内部维护一个全局的WeakHashMap来跟踪所有TTL实例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 // TransmittableThreadLocal核心数据结构（简化版） public class TransmittableThreadLocal\u0026lt;T\u0026gt; extends InheritableThreadLocal\u0026lt;T\u0026gt; { // 全局TTL实例注册表 private static final WeakHashMap\u0026lt;TransmittableThreadLocal\u0026lt;Object\u0026gt;, ?\u0026gt; ttlInstances = new WeakHashMap\u0026lt;\u0026gt;(); @Override public final T get() { T value = super.get(); if (value == null \u0026amp;\u0026amp; !super.isPresent()) { value = initialValue(); if (value != null) super.set(value); } return value; } @Override public final void set(T value) { super.set(value); // 注册当前实例到全局表 addTtlInstance(this); } // 传递器：负责捕获、回放、恢复操作 public static class Transmitter { public static Object capture() { Map\u0026lt;TransmittableThreadLocal\u0026lt;Object\u0026gt;, Object\u0026gt; captured = new HashMap\u0026lt;\u0026gt;(); for (TransmittableThreadLocal\u0026lt;Object\u0026gt; ttl : ttlInstances.keySet()) { captured.put(ttl, ttl.get()); } return captured; } public static Object replay(Object captured) { // 实现回放逻辑 } public static void restore(Object backup) { // 实现恢复逻辑 } } } 3. 三种使用方式详解 3.1 Level 1: 手动包装任务 适用于精确控制特定任务的上下文传递：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 public class ManualWrapperDemo { private static final TransmittableThreadLocal\u0026lt;UserContext\u0026gt; userContext = new TransmittableThreadLocal\u0026lt;\u0026gt;(); public void processOrder() { userContext.set(new UserContext(\u0026#34;张三\u0026#34;, \u0026#34;ADMIN\u0026#34;)); ExecutorService executor = Executors.newCachedThreadPool(); // 手动包装Runnable Runnable task = () -\u0026gt; { UserContext user = userContext.get(); System.out.println(\u0026#34;处理订单，用户: \u0026#34; + user.getName()); }; // 关键：使用TtlRunnable包装 executor.submit(TtlRunnable.get(task)); // 手动包装Callable Callable\u0026lt;String\u0026gt; callableTask = () -\u0026gt; { UserContext user = userContext.get(); return \u0026#34;订单处理完成，操作员: \u0026#34; + user.getName(); }; executor.submit(TtlCallable.get(callableTask)); } } TtlRunnable的实现原理：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 public final class TtlRunnable implements Runnable { private final Object captured; private final Runnable runnable; private TtlRunnable(Runnable runnable) { this.captured = Transmitter.capture(); // 构造时捕获上下文 this.runnable = runnable; } @Override public void run() { Object backup = Transmitter.replay(captured); // 执行前回放 try { runnable.run(); // 执行原始任务 } finally { Transmitter.restore(backup); // 执行后恢复 } } public static TtlRunnable get(Runnable runnable) { if (runnable == null) return null; if (runnable instanceof TtlRunnable) return (TtlRunnable) runnable; return new TtlRunnable(runnable); } } 3.2 Level 2: 装饰线程池 适用于特定线程池的全自动化处理：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 public class ExecutorDecoratorDemo { private static final TransmittableThreadLocal\u0026lt;String\u0026gt; traceId = new TransmittableThreadLocal\u0026lt;\u0026gt;(); public void setupDecoratedExecutor() { // 原始线程池 ExecutorService originalExecutor = Executors.newFixedThreadPool(4); // 使用TTL装饰器 ExecutorService ttlExecutor = TtlExecutors.getTtlExecutorService(originalExecutor); traceId.set(\u0026#34;TRACE-12345\u0026#34;); // 所有提交的任务都会自动包装 ttlExecutor.submit(() -\u0026gt; { System.out.println(\u0026#34;TraceId: \u0026#34; + traceId.get()); // 自动获取到上下文 }); // 支持各种类型的任务提交 ttlExecutor.submit(() -\u0026gt; \u0026#34;Callable任务，TraceId: \u0026#34; + traceId.get()); // ForkJoinPool也支持装饰 ForkJoinPool originalPool = new ForkJoinPool(); ForkJoinPool ttlPool = TtlExecutors.getTtlForkJoinPool(originalPool); // 并行流也会自动传递上下文 List\u0026lt;String\u0026gt; data = Arrays.asList(\u0026#34;A\u0026#34;, \u0026#34;B\u0026#34;, \u0026#34;C\u0026#34;); data.parallelStream() .map(item -\u0026gt; item + \u0026#34;-\u0026#34; + traceId.get()) .forEach(System.out::println); } } TtlExecutors的实现原理：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 public final class TtlExecutors { public static ExecutorService getTtlExecutorService(ExecutorService executor) { return new ExecutorServiceTtlWrapper(executor); } private static class ExecutorServiceTtlWrapper implements ExecutorService { private final ExecutorService executor; ExecutorServiceTtlWrapper(ExecutorService executor) { this.executor = executor; } @Override public Future\u0026lt;?\u0026gt; submit(Runnable task) { // 自动包装任务 return executor.submit(TtlRunnable.get(task)); } @Override public \u0026lt;T\u0026gt; Future\u0026lt;T\u0026gt; submit(Callable\u0026lt;T\u0026gt; task) { return executor.submit(TtlCallable.get(task)); } // 其他方法类似... } } 3.3 Level 3: Java Agent自动增强 适用于企业级应用的全面自动化：\n1 2 3 4 # 启动时添加Agent参数 java -javaagent:ttl-agent-3.x.x.jar \\ -cp your-classpath \\ com.example.Application Agent模式下的应用代码完全无需修改：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 public class AgentModeDemo { private static final TransmittableThreadLocal\u0026lt;RequestContext\u0026gt; requestContext = new TransmittableThreadLocal\u0026lt;\u0026gt;(); @RestController public class OrderController { @PostMapping(\u0026#34;/order\u0026#34;) public String createOrder(@RequestBody OrderRequest request) { // 设置请求上下文 requestContext.set(new RequestContext(request.getUserId(), request.getTenantId())); // 原生JDK线程池，Agent自动增强 ExecutorService executor = Executors.newCachedThreadPool(); executor.submit(() -\u0026gt; { RequestContext ctx = requestContext.get(); // ✅ 自动获取到上下文 processOrder(ctx); }); // CompletableFuture，Agent自动增强 CompletableFuture.supplyAsync(() -\u0026gt; { RequestContext ctx = requestContext.get(); // ✅ 自动获取到上下文 return generateOrderId(ctx); }); // 并行Stream，Agent自动增强 request.getItems().parallelStream() .forEach(item -\u0026gt; { RequestContext ctx = requestContext.get(); // ✅ 自动获取到上下文 validateItem(item, ctx); }); return \u0026#34;success\u0026#34;; } } } 4. Java Agent实现深度解析 4.1 Agent架构设计 TTL Agent基于Java Instrumentation API，采用模块化的Transformlet设计：\n1 2 3 4 5 6 7 8 9 TtlAgent (入口) ↓ TtlTransformer (字节码转换协调器) ↓ TtlTransformlet[] (具体转换器数组) ├── JdkExecutorTtlTransformlet (JDK线程池) ├── ForkJoinTtlTransformlet (ForkJoinPool) ├── TimerTaskTtlTransformlet (Timer/TimerTask) └── PriorityBlockingQueueTtlTransformlet (阻塞队列) 4.2 字节码增强流程 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // TtlAgent.java - Agent入口点 public class TtlAgent { public static void premain(String agentArgs, Instrumentation inst) { // 1. 解析Agent参数 Map\u0026lt;String, String\u0026gt; kvs = parseAgentArgs(agentArgs); // 2. 创建Transformlet列表 List\u0026lt;TtlTransformlet\u0026gt; transformletList = new ArrayList\u0026lt;\u0026gt;(); transformletList.add(new JdkExecutorTtlTransformlet()); transformletList.add(new ForkJoinTtlTransformlet()); transformletList.add(new TimerTaskTtlTransformlet()); // 3. 注册ClassFileTransformer ClassFileTransformer transformer = new TtlTransformer(transformletList); inst.addTransformer(transformer, true); } } 4.3 线程池方法增强示例 以ThreadPoolExecutor.submit()方法为例：\n原始字节码：\n1 2 3 4 5 6 public Future\u0026lt;?\u0026gt; submit(Runnable task) { if (task == null) throw new NullPointerException(); RunnableFuture\u0026lt;Void\u0026gt; ftask = newTaskFor(task, null); execute(ftask); return ftask; } Agent增强后的效果（字节码级别）：\n1 2 3 4 5 6 7 8 9 public Future\u0026lt;?\u0026gt; submit(Runnable task) { // ★ Agent插入的代码 task = com.alibaba.ttl3.agent.transformlet.helper.TtlTransformletHelper.doAutoWrap(task); if (task == null) throw new NullPointerException(); RunnableFuture\u0026lt;Void\u0026gt; ftask = newTaskFor(task, null); execute(ftask); return ftask; } 字节码插入实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // AbstractExecutorTtlTransformlet.java private void updateSubmitMethodsOfExecutorClass(CtMethod method) throws Exception { CtClass[] parameterTypes = method.getParameterTypes(); for (int i = 0; i \u0026lt; parameterTypes.length; i++) { String paramTypeName = parameterTypes[i].getName(); if (\u0026#34;java.lang.Runnable\u0026#34;.equals(paramTypeName)) { String insertCode = String.format( \u0026#34;$%d = com.alibaba.ttl3.agent.transformlet.helper.TtlTransformletHelper.doAutoWrap($%\u0026lt;d);\u0026#34;, i + 1 ); method.insertBefore(insertCode); // Javassist字节码插入 } } } 4.4 自动包装逻辑 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // TtlTransformletHelper.java public class TtlTransformletHelper { public static Runnable doAutoWrap(Runnable runnable) { if (runnable == null) return null; // 获取TTL包装器，避免重复包装 TtlRunnable ttlRunnable = TtlRunnable.get(runnable, false, true); // 标记为自动包装，便于后续识别和解包装 if (ttlRunnable != runnable) { setAutoWrapperAttachment(ttlRunnable); } return ttlRunnable; } private static void setAutoWrapperAttachment(TtlEnhanced ttlEnhanced) { // 使用SPI机制标记自动包装的对象 ttlEnhanced.setTtlAttachment(AUTO_WRAPPER_ATTACHMENT_KEY, true); } } 5. 实际应用场景 5.1 分布式链路追踪 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 @Component public class DistributedTracingDemo { private static final TransmittableThreadLocal\u0026lt;TraceContext\u0026gt; traceContext = new TransmittableThreadLocal\u0026lt;\u0026gt;(); @RestController public class UserController { @GetMapping(\u0026#34;/user/{id}\u0026#34;) public User getUser(@PathVariable Long id) { // 生成链路追踪上下文 TraceContext trace = new TraceContext( \u0026#34;TRACE-\u0026#34; + UUID.randomUUID(), \u0026#34;user-service\u0026#34;, \u0026#34;getUser\u0026#34; ); traceContext.set(trace); // 异步调用用户服务 return CompletableFuture .supplyAsync(() -\u0026gt; { TraceContext ctx = traceContext.get(); // 自动传递 return userService.findById(id, ctx.getTraceId()); }) .thenCompose(user -\u0026gt; CompletableFuture.supplyAsync(() -\u0026gt; { TraceContext ctx = traceContext.get(); // 链式传递 user.setPermissions(permissionService.getPermissions(user.getId(), ctx.getTraceId())); return user; }) ) .join(); } } } 5.2 多租户上下文传递 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 @Component public class MultiTenantDemo { private static final TransmittableThreadLocal\u0026lt;TenantContext\u0026gt; tenantContext = new TransmittableThreadLocal\u0026lt;\u0026gt;(); @Component public class TenantInterceptor implements HandlerInterceptor { @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) { String tenantId = request.getHeader(\u0026#34;X-Tenant-ID\u0026#34;); tenantContext.set(new TenantContext(tenantId)); return true; } @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) { tenantContext.remove(); // 清理上下文 } } @Service public class OrderService { public void processOrderAsync(OrderRequest request) { // 异步处理订单，自动传递租户上下文 CompletableFuture.runAsync(() -\u0026gt; { TenantContext tenant = tenantContext.get(); // 基于租户ID路由到相应的数据库 DataSource dataSource = getDataSourceByTenant(tenant.getTenantId()); // 处理订单逻辑 processOrderInTenant(request, tenant); }); } } } 5.3 请求级缓存 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 @Component public class RequestCacheDemo { private static final TransmittableThreadLocal\u0026lt;Map\u0026lt;String, Object\u0026gt;\u0026gt; requestCache = TransmittableThreadLocal.withInitial(HashMap::new); @Service public class UserService { public User getUserById(Long userId) { String cacheKey = \u0026#34;user:\u0026#34; + userId; Map\u0026lt;String, Object\u0026gt; cache = requestCache.get(); // 检查请求级缓存 User cachedUser = (User) cache.get(cacheKey); if (cachedUser != null) { return cachedUser; } // 异步加载用户信息 return CompletableFuture.supplyAsync(() -\u0026gt; { Map\u0026lt;String, Object\u0026gt; asyncCache = requestCache.get(); // 自动传递 User user = userRepository.findById(userId); asyncCache.put(cacheKey, user); // 更新请求级缓存 return user; }).join(); } } } 总结 TransmittableThreadLocal作为解决线程池环境下上下文传递问题的优雅方案，具有以下核心优势：\n技术优势 零依赖设计：核心实现仅约1000行代码，无外部依赖 多层次支持：从手动包装到完全自动化的渐进式使用方式 高性能：基于CRR模式的高效上下文传递机制 广泛兼容：支持Java 6-21，兼容主流框架和中间件 本文基于TTL v3.x版本进行分析，更多技术细节和最新版本信息请参考：\nTTL官方GitHub仓库 TTL官方文档 ","date":"2025-03-18T16:20:00+08:00","permalink":"https://tech-gt.github.io/p/transmittablethreadlocal%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/","title":"TransmittableThreadLocal的实现原理分析"},{"content":"前言 前段时间，我们需要在生产环境进行一次压测。但问题来了：怎么在不影响线上真实用户数据的情况下，模拟真实的业务流量？\n传统的做法是搭建独立的测试环境，但这样做有几个问题：\n测试环境数据量小，无法真实反映性能 环境配置可能与生产不一致 维护成本高 最终我们选择了ShardingJDBC的影子库方案，在生产环境中实现了数据的完美隔离。今天就来分享一下这个实战经验。\n什么是影子库 影子库（Shadow Database）是一种在生产环境中进行安全测试的技术方案。它的核心思想是：\n生产库：存储真实的业务数据 影子库：与生产库结构完全相同，但只存储测试数据 智能路由：根据请求标识，自动将测试流量路由到影子库 graph TD A[客户端请求] --\u003e B{流量识别} B --\u003e|生产流量| C[生产数据库] B --\u003e|测试流量| D[影子数据库] C --\u003e E[真实业务数据] D --\u003e F[测试数据] style C fill:#e1f5fe style D fill:#fff3e0 ShardingJDBC影子库配置 1. 依赖配置 首先添加ShardingSphere-JDBC依赖：\n1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.shardingsphere\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;shardingsphere-jdbc-core-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.2.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 2. 数据源配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 # application.yml spring: shardingsphere: datasource: names: master-ds,shadow-ds # 生产数据源 master-ds: type: com.zaxxer.hikari.HikariDataSource driver-class-name: com.mysql.cj.jdbc.Driver jdbc-url: jdbc:mysql://prod-db:3306/ecommerce_prod username: ${DB_USER} password: ${DB_PASSWORD} # 影子数据源 shadow-ds: type: com.zaxxer.hikari.HikariDataSource driver-class-name: com.mysql.cj.jdbc.Driver jdbc-url: jdbc:mysql://shadow-db:3306/ecommerce_shadow username: ${DB_USER} password: ${DB_PASSWORD} # 影子库规则配置 rules: shadow: enable: true data-sources: shadow-data-source: production-data-source-name: master-ds shadow-data-source-name: shadow-ds # 影子表配置 tables: t_order: data-source-names: - shadow-data-source shadow-algorithm-names: - user-id-insert-match-algorithm - user-id-select-match-algorithm t_order_item: data-source-names: - shadow-data-source shadow-algorithm-names: - user-id-insert-match-algorithm - user-id-select-match-algorithm # 影子算法配置 shadow-algorithms: user-id-insert-match-algorithm: type: VALUE_MATCH props: operation: insert column: user_id value: 0 user-id-select-match-algorithm: type: VALUE_MATCH props: operation: select column: user_id value: 0 props: sql-show: true 3. 核心业务代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 @Service public class OrderService { @Autowired private OrderMapper orderMapper; @Autowired private OrderItemMapper orderItemMapper; /** * 创建订单 - 支持影子库路由 */ @Transactional public Long createOrder(CreateOrderRequest request) { // 构建订单对象 Order order = Order.builder() .userId(request.getUserId()) .totalAmount(request.getTotalAmount()) .status(OrderStatus.PENDING) .createTime(LocalDateTime.now()) .build(); // 插入订单 - 会根据userId自动路由到对应库 orderMapper.insert(order); // 插入订单项 List\u0026lt;OrderItem\u0026gt; orderItems = request.getItems().stream() .map(item -\u0026gt; OrderItem.builder() .orderId(order.getId()) .userId(request.getUserId()) // 关键：保持userId一致 .productId(item.getProductId()) .quantity(item.getQuantity()) .price(item.getPrice()) .build()) .collect(Collectors.toList()); orderItemMapper.batchInsert(orderItems); return order.getId(); } /** * 查询订单 */ public OrderVO getOrder(Long orderId, Long userId) { // 根据userId路由到对应的数据库 Order order = orderMapper.selectByIdAndUserId(orderId, userId); if (order == null) { return null; } List\u0026lt;OrderItem\u0026gt; items = orderItemMapper.selectByOrderId(orderId, userId); return OrderVO.builder() .order(order) .items(items) .build(); } } 影子流量生成器 为了方便测试，我们需要一个流量生成器：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 @Component public class ShadowTrafficGenerator { private static final Long SHADOW_USER_ID = 0L; // 影子用户ID @Autowired private OrderService orderService; /** * 生成影子订单数据 */ public void generateShadowOrders(int count) { for (int i = 0; i \u0026lt; count; i++) { CreateOrderRequest request = CreateOrderRequest.builder() .userId(SHADOW_USER_ID) // 使用影子用户ID .totalAmount(BigDecimal.valueOf(100 + i)) .items(generateRandomItems()) .build(); try { Long orderId = orderService.createOrder(request); log.info(\u0026#34;Created shadow order: {}\u0026#34;, orderId); } catch (Exception e) { log.error(\u0026#34;Failed to create shadow order\u0026#34;, e); } } } /** * 查询影子数据验证 */ public void verifyShadowData() { // 查询生产数据 OrderVO prodOrder = orderService.getOrder(1L, 1001L); log.info(\u0026#34;Production order: {}\u0026#34;, prodOrder); // 查询影子数据 OrderVO shadowOrder = orderService.getOrder(1L, SHADOW_USER_ID); log.info(\u0026#34;Shadow order: {}\u0026#34;, shadowOrder); } private List\u0026lt;CreateOrderItemRequest\u0026gt; generateRandomItems() { return Arrays.asList( CreateOrderItemRequest.builder() .productId(1001L + new Random().nextInt(100)) .quantity(1 + new Random().nextInt(3)) .price(BigDecimal.valueOf(50 + new Random().nextInt(200))) .build() ); } } 压测控制器 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 @RestController @RequestMapping(\u0026#34;/shadow\u0026#34;) public class ShadowTestController { @Autowired private ShadowTrafficGenerator trafficGenerator; @Autowired private OrderService orderService; /** * 启动影子数据生成 */ @PostMapping(\u0026#34;/generate/{count}\u0026#34;) public ResponseEntity\u0026lt;String\u0026gt; generateShadowData(@PathVariable int count) { try { trafficGenerator.generateShadowOrders(count); return ResponseEntity.ok(\u0026#34;Generated \u0026#34; + count + \u0026#34; shadow orders\u0026#34;); } catch (Exception e) { return ResponseEntity.badRequest().body(\u0026#34;Error: \u0026#34; + e.getMessage()); } } /** * 模拟并发压测 */ @PostMapping(\u0026#34;/stress-test\u0026#34;) public ResponseEntity\u0026lt;String\u0026gt; stressTest() { CompletableFuture.runAsync(() -\u0026gt; { // 模拟高并发场景 for (int i = 0; i \u0026lt; 1000; i++) { CreateOrderRequest request = CreateOrderRequest.builder() .userId(0L) // 影子用户 .totalAmount(BigDecimal.valueOf(199.99)) .items(Arrays.asList( CreateOrderItemRequest.builder() .productId(2001L) .quantity(1) .price(BigDecimal.valueOf(199.99)) .build() )) .build(); orderService.createOrder(request); } }); return ResponseEntity.ok(\u0026#34;Stress test started\u0026#34;); } /** * 数据隔离验证 */ @GetMapping(\u0026#34;/verify\u0026#34;) public ResponseEntity\u0026lt;Map\u0026lt;String, Object\u0026gt;\u0026gt; verifyIsolation() { Map\u0026lt;String, Object\u0026gt; result = new HashMap\u0026lt;\u0026gt;(); // 查询生产数据数量（user_id != 0） // 查询影子数据数量（user_id = 0） // 这里简化实现 result.put(\u0026#34;production_orders\u0026#34;, \u0026#34;真实订单数据\u0026#34;); result.put(\u0026#34;shadow_orders\u0026#34;, \u0026#34;影子订单数据\u0026#34;); result.put(\u0026#34;isolation_status\u0026#34;, \u0026#34;完全隔离\u0026#34;); return ResponseEntity.ok(result); } } 影子库监控 为了确保影子库正常工作，我们需要添加监控：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 @Component @Slf4j public class ShadowDatabaseMonitor { @Autowired private JdbcTemplate jdbcTemplate; /** * 监控数据隔离情况 */ @Scheduled(fixedRate = 60000) // 每分钟检查一次 public void monitorDataIsolation() { try { // 检查生产库是否有影子数据泄漏 String prodCheckSql = \u0026#34;\u0026#34;\u0026#34; SELECT COUNT(*) FROM t_order WHERE user_id = 0 \u0026#34;\u0026#34;\u0026#34;; Integer shadowDataInProd = jdbcTemplate.queryForObject( prodCheckSql, Integer.class); if (shadowDataInProd \u0026gt; 0) { log.error(\u0026#34;ALERT: Found {} shadow records in production database!\u0026#34;, shadowDataInProd); // 发送告警 alertService.sendAlert(\u0026#34;Shadow data leaked to production!\u0026#34;); } // 统计影子库数据量 String shadowCountSql = \u0026#34;\u0026#34;\u0026#34; SELECT COUNT(*) FROM t_order WHERE user_id = 0 \u0026#34;\u0026#34;\u0026#34;; Integer shadowCount = jdbcTemplate.queryForObject( shadowCountSql, Integer.class); log.info(\u0026#34;Shadow database health check - Shadow records: {}\u0026#34;, shadowCount); } catch (Exception e) { log.error(\u0026#34;Shadow database monitoring failed\u0026#34;, e); } } } 影子数据清理策略 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 @Service public class ShadowDataCleanupService { @Autowired private JdbcTemplate jdbcTemplate; /** * 清理过期的影子数据 */ @Scheduled(cron = \u0026#34;0 0 2 * * ?\u0026#34;) // 每天凌晨2点执行 public void cleanupExpiredShadowData() { log.info(\u0026#34;Starting shadow data cleanup...\u0026#34;); try { // 清理7天前的影子订单数据 String cleanupSql = \u0026#34;\u0026#34;\u0026#34; DELETE FROM t_order WHERE user_id = 0 AND create_time \u0026lt; DATE_SUB(NOW(), INTERVAL 7 DAY) \u0026#34;\u0026#34;\u0026#34;; int deletedCount = jdbcTemplate.update(cleanupSql); log.info(\u0026#34;Cleaned up {} expired shadow orders\u0026#34;, deletedCount); // 清理对应的订单项 String cleanupItemsSql = \u0026#34;\u0026#34;\u0026#34; DELETE FROM t_order_item WHERE user_id = 0 AND create_time \u0026lt; DATE_SUB(NOW(), INTERVAL 7 DAY) \u0026#34;\u0026#34;\u0026#34;; int deletedItemsCount = jdbcTemplate.update(cleanupItemsSql); log.info(\u0026#34;Cleaned up {} expired shadow order items\u0026#34;, deletedItemsCount); } catch (Exception e) { log.error(\u0026#34;Shadow data cleanup failed\u0026#34;, e); } } /** * 手动清理所有影子数据 */ public void cleanupAllShadowData() { log.warn(\u0026#34;Manual cleanup of ALL shadow data requested\u0026#34;); try { jdbcTemplate.update(\u0026#34;DELETE FROM t_order_item WHERE user_id = 0\u0026#34;); jdbcTemplate.update(\u0026#34;DELETE FROM t_order WHERE user_id = 0\u0026#34;); log.info(\u0026#34;All shadow data cleaned up successfully\u0026#34;); } catch (Exception e) { log.error(\u0026#34;Manual shadow data cleanup failed\u0026#34;, e); } } } 影子库路由原理 ShardingJDBC影子库的路由原理：\nsequenceDiagram participant App as 应用程序 participant Proxy as ShardingJDBC代理 participant ProdDB as 生产数据库 participant ShadowDB as 影子数据库 App-\u003e\u003eProxy: INSERT INTO t_order (user_id=0, ...) Proxy-\u003e\u003eProxy: 解析SQL，检查user_id值 Proxy-\u003e\u003eProxy: 匹配影子算法规则 Proxy-\u003e\u003eShadowDB: 路由到影子库执行 ShadowDB--\u003e\u003eProxy: 执行结果 Proxy--\u003e\u003eApp: 返回结果 App-\u003e\u003eProxy: INSERT INTO t_order (user_id=1001, ...) Proxy-\u003e\u003eProxy: 解析SQL，检查user_id值 Proxy-\u003e\u003eProxy: 不匹配影子规则 Proxy-\u003e\u003eProdDB: 路由到生产库执行 ProdDB--\u003e\u003eProxy: 执行结果 Proxy--\u003e\u003eApp: 返回结果 注意事项和最佳实践 1. 影子标识选择 1 2 3 4 5 6 7 8 9 10 11 12 13 14 // 推荐做法：使用特殊的标识值 public class ShadowConstants { // 使用不可能出现的业务值 public static final Long SHADOW_USER_ID = 0L; public static final String SHADOW_PREFIX = \u0026#34;shadow_\u0026#34;; // 或者使用范围标识 public static final Long SHADOW_USER_ID_START = 999000000L; public static final Long SHADOW_USER_ID_END = 999999999L; public static boolean isShadowUser(Long userId) { return userId \u0026gt;= SHADOW_USER_ID_START \u0026amp;\u0026amp; userId \u0026lt;= SHADOW_USER_ID_END; } } 2. 事务处理 1 2 3 4 5 6 7 @Transactional public void complexBusinessOperation(Long userId) { // 确保同一事务中的所有操作都路由到同一类型的数据库 orderService.createOrder(userId); paymentService.createPayment(userId); // 必须使用相同的userId inventoryService.decreaseStock(userId); } 3. 监控告警 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 @Component public class ShadowAlertService { /** * 数据泄漏告警 */ public void checkDataLeakage() { // 检查生产库是否有影子数据 // 检查影子库是否有生产数据 if (hasDataLeakage()) { // 立即停止影子流量 shutdownShadowTraffic(); // 发送紧急告警 sendEmergencyAlert(); } } } 4. 性能调优 1 2 3 4 5 6 7 8 9 10 11 # 连接池配置优化 spring: shardingsphere: datasource: shadow-ds: hikari: maximum-pool-size: 20 minimum-idle: 5 connection-timeout: 30000 idle-timeout: 600000 max-lifetime: 1800000 总结 使用影子库需要注意：\n选择合适的影子标识策略 建立完善的监控告警机制 定期清理影子数据 确保所有相关表都正确配置 ","date":"2025-01-22T14:20:00+08:00","permalink":"https://tech-gt.github.io/p/shardingjdbc-shadow-database/","title":"ShardingJDBC：通过影子库生产与测试数据隔离"},{"content":"引言 在数据库日常维护中，我们常常会遇到一些“神奇”的慢查询：昨天还跑得飞快的SQL，今天就突然卡住了；同一个查询在主库和从库上，性能表现却有天壤之别。这些问题的根源，往往指向了MySQL的“大脑”——查询优化器（Query Optimizer）。 核心问题在于，MySQL 的查询优化器（Query Optimizer）并非在所有情况下都能选择最高效的执行计划。当统计信息不准确、数据分布特殊或查询逻辑复杂时，优化器可能会做出错误判断，导致查询性能急剧下降。以下三个案例展示了如何诊断问题并进行针对性优化。\n案例分析 案例一：利用 LIMIT 提前终止无效扫描 场景描述： 开发人员需要检查 app 表中特定 bid 和 appid 的记录是否存在。他们的做法是使用 COUNT(*) 来统计记录数，然后判断结果是否大于 0。\n问题分析： 该业务的真实意图仅仅是 “判断存在性”，即 “有或无”，而并非获取精确的记录总数。当表中数据量巨大时（如此处的 60865 行），COUNT(*) 会进行全表扫描或索引扫描以统计所有满足条件的行，造成了大量的资源浪费。\n低效的实现方式（推断）：\n1 2 -- 原始意图的实现方式，需要扫描所有匹配的行 SELECT COUNT(*) FROM app WHERE bid = 18171817 AND appid = 251; 优化方案与 SQL： 通过添加 LIMIT 1，告知 MySQL 在找到 第一条 满足条件的记录后立即停止搜索并返回。这样可以将原本需要扫描 60865 行的操作，优化为只扫描 1 行。 图片中展示了一个巧妙的 SQL 写法，通过子查询实现了这个逻辑：\n1 2 3 4 5 6 -- 优化后的 SQL SELECT count(*) FROM ( SELECT appid FROM app WHERE bid = 18171817 AND appid = 251 LIMIT 1 ) AS tb; 这条 SQL 的核心在于子查询中的 LIMIT 1，它使得 app 表的查询工作在找到一条记录后就结束了。外层的 count(*) 只是对这个临时结果（0 或 1 行）进行计数，执行成本极低。\n案例二：解决两表关联顺序错误 场景描述： 一个定时任务的 SQL 查询，过去平均执行时间为分钟级，现在突然恶化到小时级。进一步发现，同一个 SQL 在主库和从库的执行性能相差 10 倍。\n问题分析： 通过 EXPLAIN 分析发现，性能差异的根源在于 MySQL 优化器在主库和从库上选择了不同的 表关联顺序。例如，在主库上可能选择了 a JOIN b，而在从库上选择了 b JOIN a。这种不一致性通常是由于两个库之间的 统计信息（Table Statistics）有偏差 造成的。当统计信息不能准确反映真实的数据分布时，优化器就可能被误导，选择了一个成本更高的执行计划。\n有问题的 SQL：\n1 2 3 4 5 6 -- 这个查询的性能在不同库上表现不一 SELECT b.indid, a.content, a.url, a.type, a.creatda FROM black a, balck_ind b WHERE a.id = b.blackid AND a.status = 1 ORDER BY a.id LIMIT 300000, 5000; 注意：这里的 FROM black a, balck_ind b 是隐式的 INNER JOIN，优化器有权自由决定哪张表先作为驱动表。\n优化方案与原则： 为了避免优化器在不同环境或数据变化时“摇摆不定”，可以人工指定表的关联顺序。基本原则是：\n小表驱动大表：用记录数较少的表（经过 WHERE 条件过滤后）作为驱动表。 被驱动表的关联列必须有索引：确保在大表上进行关联查找时，可以使用索引以提高效率。 可以通过 LEFT JOIN 或者 STRAIGHT_JOIN 来强制指定关联顺序。例如，如果 black 是小表，balck_ind 是大表，可以改写为：\n1 2 3 4 5 6 7 -- 使用 STRAIGHT_JOIN 强制 a 作为驱动表 SELECT b.indid, a.content, a.url, a.type, a.creatda FROM black a STRAIGHT_JOIN balck_ind b ON a.id = b.blackid WHERE a.status = 1 ORDER BY a.id LIMIT 300000, 5000; STRAIGHT_JOIN 会强制优化器按照 SQL 中 FROM 子句的书写顺序（从左到右）进行关联。\n案例三：稳定复杂多表关联的执行计划 场景描述： 一个涉及超过 10 张表的复杂关联查询，之前性能稳定在 1 秒左右。在新增了一张关联表后，查询性能急剧下降到数分钟。\n问题分析： 通过 EXPLAIN 对比优化前后的执行计划发现，问题依然出在 表关联顺序 上。新表的加入，或者某张表的统计信息恰好处于一个“临界点”，导致优化器重新评估后，生成了一个完全不同的、非常低效的执行计划。这种执行计划的“抖动”是复杂 SQL 在维护过程中常见的性能陷阱。\n优化方案与 SQL： 对于这种极其复杂的查询，让优化器次次都选对执行计划的风险很高。最稳妥的办法是 人工干预，将之前性能最好的那个执行计划的关联顺序固定下来。\n解决方案： 使用 STRAIGHT_JOIN 关键字重写整个查询，按照业务逻辑和已验证的高效顺序来排列所有的表。\n1 2 3 4 5 6 7 8 -- 概念性 SQL SELECT ... FROM table1 -- 驱动表 STRAIGHT_JOIN table2 ON table1.id = table2.t1_id -- 按指定顺序关联 STRAIGHT_JOIN table3 ON table2.id = table3.t2_id -- 继续按指定顺序关联 ... -- 以此类推，关联所有表 STRAIGHT_JOIN table_new ON ... WHERE ...; 通过这种方式，我们等于告诉 MySQL：“不要再自己判断了，就按照我写的这个顺序去执行”。这可以消除因统计信息变化带来的性能抖动，保证查询的稳定性。\n总结 这组案例的核心启示是：\nSQL 优化需切合业务意图：明确查询的最终目的，避免多余的计算（如用 LIMIT 1 代替 COUNT）。 执行计划是关键：使用 EXPLAIN 是排查慢查询的必备技能，它可以揭示优化器的决策过程。 不要盲信优化器：在复杂场景下，特别是多表关联时，优化器可能会犯错。通过 STRAIGHT_JOIN 或调整 JOIN 写法来人工指定执行计划，是稳定和提升性能的终极手段之一。 ","date":"2025-01-20T11:00:00+08:00","permalink":"https://tech-gt.github.io/p/mysql%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96%E6%A1%88%E4%BE%8B%E4%BC%98%E5%8C%96%E5%99%A8%E4%B8%BA%E4%BD%95%E4%BC%9A%E9%80%89%E9%94%99%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92/","title":"MySQL查询优化案例：优化器为何会选错执行计划"},{"content":"引言 OAuth2 是现代 Web 应用中最广泛使用的授权协议，它解决了第三方应用安全访问用户资源的问题。今天，我们通过分析 ChatGPT 的实际登录流程，来深入理解 OAuth2 授权码流程（Authorization Code Flow）的完整过程。\nChatGPT 登录 URL 解析 让我们先看看 ChatGPT 的登录 URL：\n1 https://auth.openai.com/api/accounts/authorize?client_id=app_X8zY6vW2pQ9tR3dE7nK1jL5gH\u0026amp;scope=openid%20email%20profile%20offline_access%20model.request%20model.read%20organization.read%20organization.write\u0026amp;response_type=code\u0026amp;redirect_uri=https%3A%2F%2Fchatgpt.com%2Fapi%2Fauth%2Fcallback%2Fopenai\u0026amp;audience=https%3A%2F%2Fapi.openai.com%2Fv1\u0026amp;device_id=7f3e33fa-e528-4e41-92ef-b6644375466d\u0026amp;prompt=login\u0026amp;screen_hint=login\u0026amp;ext-oai-did=7f3e33fa-e528-4e41-92ef-b6644375466d\u0026amp;auth_session_logging_id=e723095f-1dd2-4323-a562-dc116515718d\u0026amp;state=d76BSEOC_1nCl4Vkr9JPdFQiPfAhbuNLfIjyrWcNdKE 这个 URL 包含了 OAuth2 授权请求的所有关键参数，让我们逐一解析：\n基础参数 参数 值 说明 client_id app_X8zY6vW2pQ9tR3dE7nK1jL5gH ChatGPT 应用在 OpenAI 授权服务器注册的唯一标识符 response_type code 表示使用授权码流程，服务器将返回授权码而不是直接返回访问令牌 redirect_uri https://chatgpt.com/api/auth/callback/openai 授权成功后的回调地址，必须与注册时一致 权限范围（Scope） 1 scope=openid%20email%20profile%20offline_access%20model.request%20model.read%20organization.read%20organization.write URL 解码后为：\n1 scope=openid email profile offline_access model.request model.read organization.read organization.write 这些 scope 定义了 ChatGPT 请求的权限：\nopenid：使用 OpenID Connect 协议，获取用户身份信息 email：访问用户的邮箱地址 `profile``：访问用户的基本资料信息 offline_access：获取刷新令牌，用于长期访问 model.request：请求 AI 模型的权限 model.read：读取模型信息的权限 organization.read：读取组织信息的权限 organization.write：修改组织信息的权限 安全参数 参数 值 说明 state d76BSEOC_1nCl4Vkr9JPdFQiPfAhbuNLfIjyrWcNdKE CSRF 防护令牌，防止跨站请求伪造攻击 audience https://api.openai.com/v1 指定访问令牌的目标 API 用户体验参数 参数 值 说明 prompt login 强制显示登录界面，即使用户已经登录 screen_hint login 提示显示登录界面 device_id 7f3e33fa-e528-4e41-92ef-b6644375466d 设备标识符，用于多设备管理 ext-oai-did 7f3e33fa-e528-4e41-92ef-b6644375466d OpenAI 扩展的设备 ID auth_session_logging_id e723095f-1dd2-4323-a562-dc116515718d 会话日志 ID，用于审计和调试 OAuth2 授权码流程详解 第一步：用户访问应用 sequenceDiagram participant User as 用户 participant App as ChatGPT participant Auth as OpenAI Auth Server User-\u003e\u003eApp: 访问 ChatGPT App-\u003e\u003eUser: 重定向到授权服务器 User-\u003e\u003eAuth: 访问授权 URL 当用户访问 ChatGPT 时，如果未登录，应用会重定向到上述授权 URL。\n第二步：用户授权 sequenceDiagram participant User as 用户 participant Auth as OpenAI Auth Server Auth-\u003e\u003eUser: 显示登录界面 User-\u003e\u003eAuth: 输入用户名密码 Auth-\u003e\u003eUser: 显示授权确认页面 User-\u003e\u003eAuth: 点击\"授权\"按钮 在授权服务器上，用户需要：\n登录 OpenAI 账户 查看 ChatGPT 请求的权限范围 确认授权 第三步：返回授权码 sequenceDiagram participant User as 用户 participant Auth as OpenAI Auth Server participant App as ChatGPT Auth-\u003e\u003eUser: 重定向到回调地址 User-\u003e\u003eApp: 携带授权码访问回调地址 Note over App: 回调地址: https://chatgpt.com/api/auth/callback/openai 授权成功后，服务器重定向到回调地址，URL 类似：\n1 https://chatgpt.com/api/auth/callback/openai?code=AUTHORIZATION_CODE\u0026amp;state=d76BSEOC_1nCl4Vkr9JPdFQiPfAhbuNLfIjyrWcNdKE 第四步：交换访问令牌 sequenceDiagram participant App as ChatGPT participant Auth as OpenAI Auth Server App-\u003e\u003eAuth: POST /oauth/token Note over App: 发送授权码、client_id、client_secret Auth-\u003e\u003eApp: 返回访问令牌和刷新令牌 ChatGPT 后端使用授权码向授权服务器请求访问令牌：\n1 2 3 4 5 6 7 8 POST https://auth.openai.com/oauth/token Content-Type: application/x-www-form-urlencoded grant_type=authorization_code \u0026amp;code=AUTHORIZATION_CODE \u0026amp;client_id=app_X8zY6vW2pQ9tR3dE7nK1jL5gH \u0026amp;client_secret=CLIENT_SECRET \u0026amp;redirect_uri=https://chatgpt.com/api/auth/callback/openai 服务器返回：\n1 2 3 4 5 6 7 { \u0026#34;access_token\u0026#34;: \u0026#34;eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9...\u0026#34;, \u0026#34;token_type\u0026#34;: \u0026#34;Bearer\u0026#34;, \u0026#34;expires_in\u0026#34;: 3600, \u0026#34;refresh_token\u0026#34;: \u0026#34;v1.local.REFRESH_TOKEN...\u0026#34;, \u0026#34;scope\u0026#34;: \u0026#34;openid email profile offline_access model.request model.read organization.read organization.write\u0026#34; } 第五步：使用访问令牌 sequenceDiagram participant App as ChatGPT participant API as OpenAI API App-\u003e\u003eAPI: 请求用户信息 Note over App: Authorization: Bearer ACCESS_TOKEN API-\u003e\u003eApp: 返回用户信息 ChatGPT 使用访问令牌调用 OpenAI API：\n1 2 GET https://api.openai.com/v1/user Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9... 安全考虑 1. State 参数防 CSRF state 参数是防止 CSRF 攻击的关键：\n1 2 3 4 5 6 7 8 9 10 // 生成随机 state const state = generateRandomString(32); // 存储到 session 或 cookie sessionStorage.setItem(\u0026#39;oauth_state\u0026#39;, state); // 验证回调中的 state if (urlParams.get(\u0026#39;state\u0026#39;) !== sessionStorage.getItem(\u0026#39;oauth_state\u0026#39;)) { throw new Error(\u0026#39;CSRF attack detected\u0026#39;); } 2. PKCE 扩展（可选） 对于公共客户端，可以使用 PKCE（Proof Key for Code Exchange）：\n1 2 3 4 5 6 7 8 9 // 生成 code_verifier 和 code_challenge const codeVerifier = generateRandomString(128); const codeChallenge = await generateCodeChallenge(codeVerifier); // 在授权请求中包含 code_challenge const authUrl = `https://auth.openai.com/api/accounts/authorize?code_challenge=${codeChallenge}\u0026amp;code_challenge_method=S256\u0026amp;...`; // 在令牌请求中包含 code_verifier const tokenRequest = `grant_type=authorization_code\u0026amp;code=${code}\u0026amp;code_verifier=${codeVerifier}\u0026amp;...`; 3. 令牌安全 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // 安全存储访问令牌 const secureTokenStorage = { setToken: (token) =\u0026gt; { // 使用 httpOnly cookie 或内存存储 sessionStorage.setItem(\u0026#39;access_token\u0026#39;, token); }, getToken: () =\u0026gt; { return sessionStorage.getItem(\u0026#39;access_token\u0026#39;); }, clearToken: () =\u0026gt; { sessionStorage.removeItem(\u0026#39;access_token\u0026#39;); } }; 实现示例 前端授权请求 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 class OAuth2Client { constructor(config) { this.clientId = config.clientId; this.redirectUri = config.redirectUri; this.scope = config.scope; this.authUrl = config.authUrl; } // 发起授权请求 authorize() { const state = this.generateState(); const params = new URLSearchParams({ client_id: this.clientId, response_type: \u0026#39;code\u0026#39;, redirect_uri: this.redirectUri, scope: this.scope, state: state, prompt: \u0026#39;login\u0026#39;, screen_hint: \u0026#39;login\u0026#39; }); // 存储 state 用于验证 sessionStorage.setItem(\u0026#39;oauth_state\u0026#39;, state); // 重定向到授权服务器 window.location.href = `${this.authUrl}?${params.toString()}`; } // 处理授权回调 handleCallback() { const urlParams = new URLSearchParams(window.location.search); const code = urlParams.get(\u0026#39;code\u0026#39;); const state = urlParams.get(\u0026#39;state\u0026#39;); // 验证 state if (state !== sessionStorage.getItem(\u0026#39;oauth_state\u0026#39;)) { throw new Error(\u0026#39;Invalid state parameter\u0026#39;); } // 清除 state sessionStorage.removeItem(\u0026#39;oauth_state\u0026#39;); return { code, state }; } generateState() { return Math.random().toString(36).substring(2, 15) + Math.random().toString(36).substring(2, 15); } } 后端令牌交换 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 @Service public class OAuth2Service { @Autowired private RestTemplate restTemplate; public TokenResponse exchangeCodeForToken(String code, String redirectUri) { HttpHeaders headers = new HttpHeaders(); headers.setContentType(MediaType.APPLICATION_FORM_URLENCODED); MultiValueMap\u0026lt;String, String\u0026gt; body = new LinkedMultiValueMap\u0026lt;\u0026gt;(); body.add(\u0026#34;grant_type\u0026#34;, \u0026#34;authorization_code\u0026#34;); body.add(\u0026#34;code\u0026#34;, code); body.add(\u0026#34;client_id\u0026#34;, clientId); body.add(\u0026#34;client_secret\u0026#34;, clientSecret); body.add(\u0026#34;redirect_uri\u0026#34;, redirectUri); HttpEntity\u0026lt;MultiValueMap\u0026lt;String, String\u0026gt;\u0026gt; request = new HttpEntity\u0026lt;\u0026gt;(body, headers); return restTemplate.postForObject( \u0026#34;https://auth.openai.com/oauth/token\u0026#34;, request, TokenResponse.class ); } public UserInfo getUserInfo(String accessToken) { HttpHeaders headers = new HttpHeaders(); headers.setBearerAuth(accessToken); HttpEntity\u0026lt;String\u0026gt; request = new HttpEntity\u0026lt;\u0026gt;(headers); return restTemplate.exchange( \u0026#34;https://api.openai.com/v1/user\u0026#34;, HttpMethod.GET, request, UserInfo.class ).getBody(); } } 总结 通过分析 ChatGPT 的实际登录流程，我们可以看到 OAuth2 授权码流程的完整实现：\n授权请求：应用重定向用户到授权服务器，携带必要的参数 用户授权：用户在授权服务器上登录并确认授权 返回授权码：授权服务器重定向回应用，携带授权码 交换令牌：应用使用授权码向授权服务器请求访问令牌 使用令牌：应用使用访问令牌访问受保护的资源 ","date":"2024-06-15T16:30:00+08:00","permalink":"https://tech-gt.github.io/p/oauth2%E7%99%BB%E5%BD%95%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90%E4%BB%A5chatgpt%E4%B8%BA%E4%BE%8B/","title":"OAuth2登录流程解析：以ChatGPT为例"},{"content":"在Java并发编程中，AQS（AbstractQueuedSynchronizer）是JUC包下同步器的核心基础。无论是ReentrantLock、CountDownLatch还是Semaphore，都是基于AQS实现的。 直接看源码可能会不太好理解，因为源码考虑了很多情况，会比较复杂一些。 今天我们就通过手写一个简化版的AQS，快速理解AQS原理，并可以学习AQS的模版方法模式，看看它是如何优雅地解决同步问题的。\n一、AQS的核心思想 AQS的设计非常巧妙，它采用了模版方法模式来实现同步器的框架：\n状态管理：通过一个volatile的int类型state变量来表示同步状态 队列管理：通过一个FIFO的等待队列来管理获取锁失败的线程 模版方法：提供了一套模版方法，让子类只需要实现特定的方法即可 AQS的核心组件 1 2 3 4 5 6 7 8 9 10 11 12 public abstract class AbstractQueuedSynchronizer { private volatile int state; // 同步状态 private Node head; // 等待队列头节点 private Node tail; // 等待队列尾节点 // 需要子类实现的模版方法 protected boolean tryAcquire(int arg) { throw new UnsupportedOperationException(); } protected boolean tryRelease(int arg) { throw new UnsupportedOperationException(); } protected int tryAcquireShared(int arg) { throw new UnsupportedOperationException(); } protected boolean tryReleaseShared(int arg) { throw new UnsupportedOperationException(); } protected boolean isHeldExclusively() { throw new UnsupportedOperationException(); } } 二、AQS的模版方法详解 AQS通过模版方法模式，将复杂的同步逻辑分解成几个简单的模版方法，让子类只需要关注业务逻辑：\n1. 独占锁相关的模版方法 1 2 3 4 5 6 7 8 // 尝试获取独占锁 protected boolean tryAcquire(int arg) // 尝试释放独占锁 protected boolean tryRelease(int arg) // 当前线程是否独占此锁 protected boolean isHeldExclusively() 2. 模版方法的职责 tryAcquire(int arg)：尝试获取锁，成功返回true，失败返回false tryRelease(int arg)：尝试释放锁，完全释放返回true，否则返回false isHeldExclusively()：当前线程是否独占资源 AQS已经帮我们实现了复杂的队列管理、线程阻塞/唤醒等逻辑，我们只需要实现这几个简单的方法即可。\n三、手写一个简化版AQS 我们来实现一个简化版的AQS：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 import java.util.concurrent.atomic.AtomicInteger; import java.util.concurrent.locks.LockSupport; import java.util.concurrent.ConcurrentLinkedQueue; public abstract class SimpleAQS { // 同步状态 private final AtomicInteger state = new AtomicInteger(0); // 等待队列 private final ConcurrentLinkedQueue\u0026lt;Thread\u0026gt; waiters = new ConcurrentLinkedQueue\u0026lt;\u0026gt;(); // 获取同步状态 protected final int getState() { return state.get(); } // 设置同步状态 protected final void setState(int newState) { state.set(newState); } // CAS修改同步状态 protected final boolean compareAndSetState(int expect, int update) { return state.compareAndSet(expect, update); } // 子类需要实现的模版方法 protected boolean tryAcquire(int arg) { throw new UnsupportedOperationException(); } protected boolean tryRelease(int arg) { throw new UnsupportedOperationException(); } protected boolean isHeldExclusively() { throw new UnsupportedOperationException(); } // 获取锁（可能阻塞） public final void acquire(int arg) { if (!tryAcquire(arg)) { // 获取失败，加入等待队列 waiters.add(Thread.currentThread()); // 循环尝试获取锁 while (!tryAcquire(arg)) { LockSupport.park(this); } // 获取成功，从等待队列中移除 waiters.remove(Thread.currentThread()); } } // 释放锁 public final boolean release(int arg) { if (tryRelease(arg)) { // 释放成功，唤醒等待线程 Thread next = waiters.poll(); if (next != null) { LockSupport.unpark(next); } return true; } return false; } } 四、基于SimpleAQS实现一个独占锁 现在我们来实现一个不可重入的独占锁，看看模版方法是如何工作的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 public class SimpleExclusiveLock extends SimpleAQS { @Override protected boolean tryAcquire(int arg) { // 独占锁：state从0变为1表示获取成功 return compareAndSetState(0, 1); } @Override protected boolean tryRelease(int arg) { // 释放锁：将state设为0 setState(0); return true; // 完全释放 } @Override protected boolean isHeldExclusively() { return getState() == 1; } // 对外提供的接口 public void lock() { acquire(1); } public void unlock() { release(1); } public boolean isLocked() { return isHeldExclusively(); } } 五、实现一个可重入锁 我们再来实现一个可重入锁，体会一下模版方法的灵活性：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 public class SimpleReentrantLock extends SimpleAQS { private Thread owner; // 锁的持有者 @Override protected boolean tryAcquire(int arg) { Thread current = Thread.currentThread(); int c = getState(); if (c == 0) { // 锁未被占用，尝试获取 if (compareAndSetState(0, arg)) { owner = current; return true; } } else if (current == owner) { // 当前线程已持有锁，重入 int nextc = c + arg; setState(nextc); return true; } return false; } @Override protected boolean tryRelease(int arg) { Thread current = Thread.currentThread(); if (current != owner) { throw new IllegalMonitorStateException(); } int c = getState() - arg; boolean free = false; if (c == 0) { // 完全释放锁 free = true; owner = null; } setState(c); return free; } @Override protected boolean isHeldExclusively() { return owner == Thread.currentThread(); } // 对外提供的接口 public void lock() { acquire(1); } public void unlock() { release(1); } public boolean isLocked() { return getState() != 0; } public int getHoldCount() { return isHeldExclusively() ? getState() : 0; } } 六、实际使用示例 让我们看看如何使用这些自定义的锁：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 public class LockDemo { public static void main(String[] args) throws InterruptedException { testSimpleReentrantLock(); } // 测试可重入锁 private static void testSimpleReentrantLock() throws InterruptedException { SimpleReentrantLock lock = new SimpleReentrantLock(); Runnable task = () -\u0026gt; { String threadName = Thread.currentThread().getName(); System.out.println(threadName + \u0026#34; 尝试获取锁\u0026#34;); lock.lock(); try { System.out.println(threadName + \u0026#34; 获取到锁，持有次数：\u0026#34; + lock.getHoldCount()); // 重入 lock.lock(); try { System.out.println(threadName + \u0026#34; 重入成功，持有次数：\u0026#34; + lock.getHoldCount()); Thread.sleep(1000); } finally { lock.unlock(); System.out.println(threadName + \u0026#34; 释放一次锁，持有次数：\u0026#34; + lock.getHoldCount()); } } catch (InterruptedException e) { e.printStackTrace(); } finally { lock.unlock(); System.out.println(threadName + \u0026#34; 完全释放锁，持有次数：\u0026#34; + lock.getHoldCount()); } }; Thread t1 = new Thread(task, \u0026#34;线程A\u0026#34;); Thread t2 = new Thread(task, \u0026#34;线程B\u0026#34;); t1.start(); t2.start(); t1.join(); t2.join(); System.out.println(\u0026#34;========== 可重入锁测试完成 ==========\u0026#34;); } } 七、运行结果 1 2 3 4 5 6 7 8 9 10 11 线程A 尝试获取锁 线程A 获取到锁，持有次数：1 线程A 重入成功，持有次数：2 线程B 尝试获取锁 线程A 释放一次锁，持有次数：1 线程A 完全释放锁，持有次数：0 线程B 获取到锁，持有次数：1 线程B 重入成功，持有次数：2 线程B 释放一次锁，持有次数：1 线程B 完全释放锁，持有次数：0 ========== 可重入锁测试完成 ========== 八、AQS模版方法的优势 通过上面的例子，我们可以看到AQS模版方法模式的优势：\n关注点分离：子类只需要关注业务逻辑（如何获取/释放锁），不需要关心复杂的队列管理 代码复用：所有同步器都可以复用AQS的队列管理、线程阻塞/唤醒等逻辑 扩展性强：通过重写不同的模版方法，可以实现各种不同的同步器 性能优化：AQS内部使用了大量的性能优化技巧，子类可以直接受益 九、总结 AQS的模版方法模式是一个经典的设计模式应用。它通过几个简单的模版方法，让我们可以轻松实现各种复杂的同步器。\n在实际工作中，当你需要实现自定义的同步器时，不妨考虑使用AQS：\n明确你的同步语义（独占还是共享） 定义好状态的含义 实现对应的模版方法 提供友好的对外接口 独占锁 vs 共享锁 独占锁（Exclusive）：同一时刻只能有一个线程持有锁\n典型例子：ReentrantLock、synchronized 使用场景：临界区保护，确保同一时刻只有一个线程能访问共享资源 实现方式：重写tryAcquire和tryRelease方法 共享锁（Shared）：同一时刻可以有多个线程持有锁\n典型例子：CountDownLatch（倒计时锁）、Semaphore（信号量）、ReadWriteLock的读锁 使用场景：允许多个线程同时访问，但需要控制访问数量或等待某个条件 实现方式：重写tryAcquireShared和tryReleaseShared方法 让我们通过一个具体的例子来理解：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 // 独占锁示例：停车场只有1个车位 public class ParkingLot extends SimpleAQS { public ParkingLot() { setState(1); // 1个车位 } @Override protected boolean tryAcquire(int arg) { // 独占：要么有车位（1），要么没有（0） return compareAndSetState(1, 0); } @Override protected boolean tryRelease(int arg) { setState(1); // 释放车位 return true; } public void park() { acquire(1); } public void leave() { release(1); } } // 共享锁示例：停车场有N个车位 public class MultiParkingLot extends SimpleAQS { public MultiParkingLot(int capacity) { setState(capacity); // N个车位 } @Override protected int tryAcquireShared(int arg) { for (;;) { int current = getState(); int remaining = current - arg; if (remaining \u0026lt; 0) { return remaining; // 没有足够车位 } if (compareAndSetState(current, remaining)) { return remaining; // 成功获取车位 } } } @Override protected boolean tryReleaseShared(int arg) { for (;;) { int current = getState(); int next = current + arg; if (compareAndSetState(current, next)) { return true; // 成功释放车位 } } } public void park() { acquireShared(1); } public void leave() { releaseShared(1); } } 通过这个停车场的例子：\n独占锁：整个停车场只有1个车位，同一时刻只能停1辆车 共享锁：停车场有N个车位，可以同时停N辆车，但不能超过容量 在选择同步语义时，关键是要明确：你的资源是否允许多个线程同时访问？\n如果资源天然互斥（如银行账户余额修改），选择独占锁 如果资源可以被多个线程同时使用（如数据库连接池），选择共享锁 理解了AQS的模版方法，再去看JUC包下的各种同步器源码，你会发现它们都是这个套路，只是在具体的业务逻辑上有所不同。\n","date":"2024-06-08T10:00:00+08:00","permalink":"https://tech-gt.github.io/p/aqs-demo/","title":"Java实现一个简单的AQS，快速理解AQS原理"},{"content":" “程序有两部分，一部分是正常流程，另一部分是异常流程。” —— I.M. Wright\n错误处理是每个程序员都绕不开的话题。一个健壮的系统，其优雅的错误处理机制必不可少。\n1. Java：传统的“异常” Java 的错误处理机制是典型的“异常”（Exception）驱动模型。它将错误视为一种不寻常的、中断正常流程的事件。\n核心思想是：在可能出错的地方 try 一下，如果真的出错了，就 catch 住这个异常，做一些补救措施，无论如何 finally 都要执行收尾工作。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public String readFile(String path) { try { File file = new File(path); Scanner scanner = new Scanner(file); StringBuilder content = new StringBuilder(); while (scanner.hasNextLine()) { content.append(scanner.nextLine()); } return content.toString(); } catch (FileNotFoundException e) { // 文件找不到，是一种可预见的“异常” log.error(\u0026#34;File not found: {}\u0026#34;, path, e); return null; // 或者抛出一个自定义的业务异常 } finally { // 资源清理 System.out.println(\u0026#34;File operation finished.\u0026#34;); } } Java 还把异常分为两类：\nChecked Exceptions（受检异常）：比如 IOException, SQLException。编译器强制你必须处理（try-catch 或 throws）。设计初衷是好的，提醒你别忘了处理这些常见的外部错误。 Unchecked Exceptions（非受检异常）：比如 NullPointerException, IllegalArgumentException。通常是程序逻辑错误，编译器不强制处理。 优点：\n关注点分离：正常业务逻辑和错误处理逻辑被 try 和 catch 块清晰地分开了。 自动传播：如果不 catch，异常会沿着调用栈一路向上冒泡，直到被捕获或导致程序终止，不容易“不小心”忽略错误。 缺点：\n异常的抛出和捕获是一种非本地的 goto，会让代码的执行路径变得不那么直观。而且异常处理机制本身也有性能开销，需要维护调用栈信息，在高性能场景下可能成为瓶颈。 在实践中，受检异常常常导致大量的样板代码，或者被开发者用 throws Exception 粗暴地抛给上层，违背了其设计的初衷。 2. Go：务实的“错误值” Go 语言则完全抛弃了异常模型，它的设计哲学是：“错误也是一种值”。\n在 Go 中，一个函数如果可能出错，它通常会返回两个值：一个正常的结果，一个 error。调用方必须显式地检查这个 error 值。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 func ReadFile(path string) (string, error) { data, err := ioutil.ReadFile(path) if err != nil { // 如果 err 不是 nil，说明出错了 return \u0026#34;\u0026#34;, fmt.Errorf(\u0026#34;failed to read file %s: %w\u0026#34;, path, err) } return string(data), nil // 没出错，err 是 nil } func main() { content, err := ReadFile(\u0026#34;my.txt\u0026#34;) if err != nil { log.Fatalf(\u0026#34;An error occurred: %v\u0026#34;, err) } fmt.Println(content) } 这种 if err != nil 的写法在 Go 代码中随处可见。\n优点：\n显式处理：错误处理是代码的“一等公民”，你必须正视它、处理它，控制流非常清晰，所见即所得。 简单统一：没有复杂的异常类型系统，error 只是一个内置的接口类型，任何实现了 Error() 方法的类型都可以作为错误，简单而灵活。 缺点：\n代码冗余：大量的 if err != nil 会让代码显得重复和啰嗦，有时会干扰对核心业务逻辑的阅读。 容易忽略：虽然是显式的，但开发者仍然可能因为疏忽而忘记检查 err，而 Go 的编译器对此无能为力。 3. Rust：安全的“结果” Rust 在错误处理上，可以说是集大成者。它既要 Go 的显式，又要避免其啰嗦；既要 Java 的传播便利性，又要杜绝其隐式的控制流。\nRust 的法宝是 Result\u0026lt;T, E\u0026gt; 枚举类型。一个可能失败的函数，其返回值会被 Result 包裹起来，它要么是 Ok(T)（成功，T 是结果），要么是 Err(E)（失败，E 是错误）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 use std::fs; use std::io; fn read_file(path: \u0026amp;str) -\u0026gt; Result\u0026lt;String, io::Error\u0026gt; { let content = fs::read_to_string(path)?; // 注意这个问号 Ok(content) } fn main() { match read_file(\u0026#34;my.txt\u0026#34;) { Ok(content) =\u0026gt; println!(\u0026#34;File content: {}\u0026#34;, content), Err(e) =\u0026gt; eprintln!(\u0026#34;Failed to read file: {}\u0026#34;, e), } } Result 是一个枚举，你必须通过 match 或其他方式来处理它的两种可能性，编译器会强制你这么做，想忽略都不行。\n而那个神秘的 ? 操作符，是 Rust 的语法糖。如果 read_file 返回 Ok(value)，? 会把 value 解包出来；如果返回 Err(error)，? 会让当前函数立刻返回这个 Err(error)。它优雅地实现了错误的提前返回和传播，让“快乐路径”的代码无比清爽。\n优点：\n编译时保证：Rust 的类型系统强制你处理每一个可能的错误，从根本上杜绝了被忽略的错误。 优雅简洁：? 操作符既保留了错误传播的便利性，又让控制流保持显式和清晰，是 Go if err != nil 的完美替代品。 零成本抽象：Result 和 ? 在编译后会被优化成与手写 if-else 分支几乎无异的代码，没有运行时开销。 缺点：\n心智负担：对于初学者，理解 Result, Option, match 和 ? 这些概念需要一定的时间。 总结 特性 Java (Exception) Go (error value) Rust (Result\u0026lt;T, E\u0026gt;) 核心思想 错误是特殊事件 错误是普通的值 错误是返回值的一部分 控制流 隐式，非本地跳转 显式，本地 if 显式，? 语法糖 强制性 编译器强制(Checked) 靠开发者自觉 编译器强制 简洁性 业务代码简洁 错误处理啰嗦 ? 带来极致简洁 安全性 运行时可能忽略 编译时可能忽略 编译时安全 三种语言的错误处理方式，恰好反映了它们的设计哲学：\nJava 试图用复杂的类和规则体系来管理大型工程，但有时会陷入过度设计的泥潭。 Go 崇尚大道至简，用最朴素的方式解决问题，简单有效，但有时略显笨拙。 Rust 则追求极致的安全与性能，并为此打造了一套强大的类型系统和语法糖，既要安全也要优雅。 没有绝对的银弹，但如果你问我，我可能会投 Rust 一票\n","date":"2024-03-18T14:55:00+08:00","permalink":"https://tech-gt.github.io/p/%E5%91%8A%E5%88%AB-try-catchjavago-%E5%92%8C-rust-%E7%9A%84%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86%E5%93%B2%E5%AD%A6/","title":"告别 Try-Catch？Java、Go 和 Rust 的错误处理哲学"},{"content":"前言 作为一个有C++经验的程序员，当我第一次接触Rust时，所有权系统看起来很陌生。但深入学习后发现，Rust的所有权机制其实和C++智能指针有很多相似之处，只是Rust把这套机制内置到了语言层面。\n如果你已经熟悉C++智能指针，那么理解Rust所有权会比想象中容易得多。今天就从C++程序员的角度，来看看如何快速掌握Rust的所有权机制。\n内存管理的痛点 在开始对比之前，先回顾一下传统C/C++的内存管理问题：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 // 经典的内存泄漏 void bad_example() { int* data = new int[1000]; if (some_condition()) { return; // 忘记delete，内存泄漏！ } delete[] data; } // 悬垂指针 int* dangling_pointer() { int* ptr = new int(42); delete ptr; return ptr; // 返回已释放的指针 } // 双重释放 void double_free() { int* ptr = new int(42); delete ptr; delete ptr; // 二次删除，未定义行为 } 这些问题在大型项目中经常出现，debug起来非常痛苦。\n核心概念映射：从智能指针到所有权 在深入细节之前，让我们先建立C++智能指针和Rust所有权的概念映射：\nC++智能指针 Rust所有权 核心思想 unique_ptr\u0026lt;T\u0026gt; T (值类型) 独占所有权，自动销毁 shared_ptr\u0026lt;T\u0026gt; Arc\u0026lt;T\u0026gt; 共享所有权，引用计数 weak_ptr\u0026lt;T\u0026gt; Weak\u0026lt;T\u0026gt; 弱引用，避免循环 T\u0026amp; (引用) \u0026amp;T (借用) 临时访问，不拥有 T* (裸指针) *const T 不安全的直接访问 关键： Rust的所有权系统本质上是把C++智能指针的语义内置到了类型系统中。在C++中，我们需要主动选择使用哪种智能指针；在Rust中，编译器会强制我们遵循这些规则。\nC++智能指针回顾：为Rust做准备 C++11引入了智能指针来解决这些问题：\n1. unique_ptr - 独占所有权 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 #include \u0026lt;memory\u0026gt; #include \u0026lt;iostream\u0026gt; class Resource { public: Resource(int id) : id_(id) { std::cout \u0026lt;\u0026lt; \u0026#34;Resource \u0026#34; \u0026lt;\u0026lt; id_ \u0026lt;\u0026lt; \u0026#34; created\\n\u0026#34;; } ~Resource() { std::cout \u0026lt;\u0026lt; \u0026#34;Resource \u0026#34; \u0026lt;\u0026lt; id_ \u0026lt;\u0026lt; \u0026#34; destroyed\\n\u0026#34;; } void process() { std::cout \u0026lt;\u0026lt; \u0026#34;Processing resource \u0026#34; \u0026lt;\u0026lt; id_ \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; } private: int id_; }; void unique_ptr_example() { // 自动管理内存，离开作用域自动销毁 auto resource = std::make_unique\u0026lt;Resource\u0026gt;(1); resource-\u0026gt;process(); // 转移所有权 auto moved_resource = std::move(resource); // resource现在为nullptr if (moved_resource) { moved_resource-\u0026gt;process(); } } // moved_resource自动销毁 2. shared_ptr - 共享所有权 1 2 3 4 5 6 7 8 9 10 11 12 13 void shared_ptr_example() { auto resource1 = std::make_shared\u0026lt;Resource\u0026gt;(2); std::cout \u0026lt;\u0026lt; \u0026#34;Reference count: \u0026#34; \u0026lt;\u0026lt; resource1.use_count() \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; // 1 { auto resource2 = resource1; // 复制，引用计数+1 std::cout \u0026lt;\u0026lt; \u0026#34;Reference count: \u0026#34; \u0026lt;\u0026lt; resource1.use_count() \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; // 2 resource2-\u0026gt;process(); } // resource2销毁，引用计数-1 std::cout \u0026lt;\u0026lt; \u0026#34;Reference count: \u0026#34; \u0026lt;\u0026lt; resource1.use_count() \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; // 1 } // resource1销毁，引用计数变0，对象被删除 3. weak_ptr - 避免循环引用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 class Node { public: int value; std::shared_ptr\u0026lt;Node\u0026gt; next; std::weak_ptr\u0026lt;Node\u0026gt; parent; // 避免循环引用 Node(int v) : value(v) {} ~Node() { std::cout \u0026lt;\u0026lt; \u0026#34;Node \u0026#34; \u0026lt;\u0026lt; value \u0026lt;\u0026lt; \u0026#34; destroyed\\n\u0026#34;; } }; void weak_ptr_example() { auto root = std::make_shared\u0026lt;Node\u0026gt;(1); auto child = std::make_shared\u0026lt;Node\u0026gt;(2); root-\u0026gt;next = child; child-\u0026gt;parent = root; // weak_ptr不增加引用计数 // 检查parent是否还存在 if (auto parent = child-\u0026gt;parent.lock()) { std::cout \u0026lt;\u0026lt; \u0026#34;Parent value: \u0026#34; \u0026lt;\u0026lt; parent-\u0026gt;value \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; } } 从C++智能指针思维理解Rust所有权 现在让我们用C++程序员熟悉的概念来理解Rust所有权：\n1. unique_ptr → Rust值类型：独占所有权 C++版本：\n1 2 3 4 5 6 7 void cpp_unique_ownership() { auto data = std::make_unique\u0026lt;std::string\u0026gt;(\u0026#34;hello\u0026#34;); auto moved_data = std::move(data); // 转移所有权 // data现在为nullptr，不能再使用 std::cout \u0026lt;\u0026lt; *moved_data \u0026lt;\u0026lt; std::endl; // 只能通过moved_data访问 } // moved_data自动销毁 Rust等价版本：\n1 2 3 4 5 6 7 fn rust_unique_ownership() { let data = String::from(\u0026#34;hello\u0026#34;); // 相当于unique_ptr let moved_data = data; // 自动move，相当于std::move // data现在无效，不能再使用 println!(\u0026#34;{}\u0026#34;, moved_data); // 只能通过moved_data访问 } // moved_data自动销毁 关键相似点：\n都保证只有一个所有者 转移所有权后，原变量失效 离开作用域自动销毁 零运行时开销 2. 引用 → 借用：临时访问权 C++版本：\n1 2 3 4 5 6 7 8 9 int calculate_length(const std::string\u0026amp; s) { // 引用参数 return s.length(); // 只读访问，不拥有 } void cpp_reference_example() { auto data = std::make_unique\u0026lt;std::string\u0026gt;(\u0026#34;hello\u0026#34;); int len = calculate_length(*data); // 传递引用 std::cout \u0026lt;\u0026lt; *data \u0026lt;\u0026lt; \u0026#34; has length \u0026#34; \u0026lt;\u0026lt; len \u0026lt;\u0026lt; std::endl; // data仍然有效 } Rust等价版本：\n1 2 3 4 5 6 7 8 9 fn calculate_length(s: \u0026amp;String) -\u0026gt; usize { // 借用参数 s.len() // 只读访问，不拥有 } fn rust_borrowing_example() { let data = String::from(\u0026#34;hello\u0026#34;); // 拥有者 let len = calculate_length(\u0026amp;data); // 借用 println!(\u0026#34;{} has length {}\u0026#34;, data, len); // data仍然有效 } 关键相似点：\n都不转移所有权 都允许临时访问数据 原所有者保持有效 3. 可变引用 → 可变借用：独占修改权 C++版本：\n1 2 3 4 5 6 7 8 9 void modify_string(std::string\u0026amp; s) { // 可变引用 s.append(\u0026#34;, world\u0026#34;); } void cpp_mutable_reference() { auto data = std::make_unique\u0026lt;std::string\u0026gt;(\u0026#34;hello\u0026#34;); modify_string(*data); // 传递可变引用 std::cout \u0026lt;\u0026lt; *data \u0026lt;\u0026lt; std::endl; // 输出: \u0026#34;hello, world\u0026#34; } Rust等价版本：\n1 2 3 4 5 6 7 8 9 fn modify_string(s: \u0026amp;mut String) { // 可变借用 s.push_str(\u0026#34;, world\u0026#34;); } fn rust_mutable_borrowing() { let mut data = String::from(\u0026#34;hello\u0026#34;); modify_string(\u0026amp;mut data); // 传递可变借用 println!(\u0026#34;{}\u0026#34;, data); // 输出: \u0026#34;hello, world\u0026#34; } 4. 理解Rust的严格规则：消除C++的常见问题 Rust的借用规则看起来严格，但实际上是在编译时防止C++中的常见错误：\nC++中的问题：\n1 2 3 4 5 6 7 8 9 10 11 12 void cpp_danger() { std::vector\u0026lt;int\u0026gt; vec = {1, 2, 3}; // 获取引用 int\u0026amp; first = vec[0]; // 修改vector可能导致重新分配，引用失效 vec.push_back(4); // 可能导致first成为悬垂引用 // 使用可能无效的引用 - 未定义行为！ std::cout \u0026lt;\u0026lt; first \u0026lt;\u0026lt; std::endl; } Rust防止这类问题：\n1 2 3 4 5 6 7 8 9 10 11 12 fn rust_safety() { let mut vec = vec![1, 2, 3]; let first = \u0026amp;vec[0]; // 不可变借用 // vec.push(4); // 编译错误！不能在借用期间修改 println!(\u0026#34;{}\u0026#34;, first); // 安全使用 // first离开作用域后，才能修改vec vec.push(4); // 现在可以了 } shared_ptr → Arc：共享所有权的升级 当你需要共享所有权时，C++和Rust的思路是相似的：\nC++的shared_ptr 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 #include \u0026lt;memory\u0026gt; #include \u0026lt;thread\u0026gt; #include \u0026lt;vector\u0026gt; void cpp_shared_ownership() { // 创建共享数据 auto shared_data = std::make_shared\u0026lt;std::vector\u0026lt;int\u0026gt;\u0026gt;(10000, 42); std::vector\u0026lt;std::thread\u0026gt; threads; // 多个线程共享同一数据 for (int i = 0; i \u0026lt; 4; ++i) { threads.emplace_back([shared_data, i]() { // 每个线程都拥有一份引用计数 std::cout \u0026lt;\u0026lt; \u0026#34;Thread \u0026#34; \u0026lt;\u0026lt; i \u0026lt;\u0026lt; \u0026#34; accessing data size: \u0026#34; \u0026lt;\u0026lt; shared_data-\u0026gt;size() \u0026lt;\u0026lt; std::endl; }); } for (auto\u0026amp; t : threads) { t.join(); } // 所有线程结束后，shared_data自动销毁 } Rust的Arc (Atomic Reference Counted) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 use std::sync::Arc; use std::thread; fn rust_shared_ownership() { // 创建共享数据 let shared_data = Arc::new(vec![42; 10000]); let mut handles = vec![]; // 多个线程共享同一数据 for i in 0..4 { let data_clone = Arc::clone(\u0026amp;shared_data); // 增加引用计数 let handle = thread::spawn(move || { // 每个线程都拥有一份引用 println!(\u0026#34;Thread {} accessing data size: {}\u0026#34;, i, data_clone.len()); }); handles.push(handle); } for handle in handles { handle.join().unwrap(); } // 所有线程结束后，shared_data自动销毁 } 关键相似点：\n都使用引用计数管理生命周期 都支持多线程安全的共享 都在最后一个引用销毁时自动释放内存 Arc::clone 相当于 shared_ptr 的复制 C++程序员的Rust学习路径 基于智能指针的经验，我推荐这样的学习顺序：\n第1步：理解move语义的增强 如果你熟悉C++11的move语义，Rust的move是类似的，但更严格：\nC++：\n1 2 3 auto s1 = std::make_unique\u0026lt;std::string\u0026gt;(\u0026#34;hello\u0026#34;); auto s2 = std::move(s1); // s1变为nullptr，但仍可赋值 s1 = std::make_unique\u0026lt;std::string\u0026gt;(\u0026#34;new\u0026#34;); // 可以重新赋值 Rust：\n1 2 3 let s1 = String::from(\u0026#34;hello\u0026#34;); let s2 = s1; // s1完全失效 // let s3 = s1; // 编译错误！不能再使用s1 第2步：把引用当作\u0026quot;自动管理的引用\u0026quot; 在C++中，你需要小心引用的生命周期：\nC++：\n1 2 3 4 std::string\u0026amp; get_reference() { std::string local = \u0026#34;hello\u0026#34;; return local; // 危险！返回局部变量的引用 } Rust：\n1 2 3 4 fn get_reference() -\u0026gt; \u0026amp;String { let local = String::from(\u0026#34;hello\u0026#34;); \u0026amp;local // 编译错误！Rust会阻止这种错误 } 第3步：用\u0026quot;排他锁\u0026quot;理解可变借用 可变借用类似于对数据加了排他锁：\n1 2 3 4 5 6 7 8 9 10 11 12 13 let mut data = vec![1, 2, 3]; // 相当于获得排他锁 let exclusive = \u0026amp;mut data; // 其他人不能访问（连读都不行） // let reader = \u0026amp;data; // 编译错误！ // 使用完毕，\u0026#34;锁\u0026#34;自动释放 drop(exclusive); // 现在可以再次访问 let reader = \u0026amp;data; // OK 实战应用：从C++项目迁移思路 让我们看一个实际的从C++到Rust的迁移例子：\nC++版本：链表实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 template\u0026lt;typename T\u0026gt; class LinkedList { private: struct Node { T data; std::unique_ptr\u0026lt;Node\u0026gt; next; Node(T value) : data(std::move(value)) {} }; std::unique_ptr\u0026lt;Node\u0026gt; head; public: void push_front(T value) { auto new_node = std::make_unique\u0026lt;Node\u0026gt;(std::move(value)); new_node-\u0026gt;next = std::move(head); head = std::move(new_node); } std::optional\u0026lt;T\u0026gt; pop_front() { if (!head) { return std::nullopt; } T value = std::move(head-\u0026gt;data); head = std::move(head-\u0026gt;next); return value; } void print() const { Node* current = head.get(); while (current) { std::cout \u0026lt;\u0026lt; current-\u0026gt;data \u0026lt;\u0026lt; \u0026#34; \u0026#34;; current = current-\u0026gt;next.get(); } std::cout \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; } }; Rust版本：链表实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 struct Node\u0026lt;T\u0026gt; { data: T, next: Option\u0026lt;Box\u0026lt;Node\u0026lt;T\u0026gt;\u0026gt;\u0026gt;, } struct LinkedList\u0026lt;T\u0026gt; { head: Option\u0026lt;Box\u0026lt;Node\u0026lt;T\u0026gt;\u0026gt;\u0026gt;, } impl\u0026lt;T\u0026gt; LinkedList\u0026lt;T\u0026gt; { fn new() -\u0026gt; Self { LinkedList { head: None } } fn push_front(\u0026amp;mut self, value: T) { let new_node = Box::new(Node { data: value, next: self.head.take(), // take()获取所有权并留下None }); self.head = Some(new_node); } fn pop_front(\u0026amp;mut self) -\u0026gt; Option\u0026lt;T\u0026gt; { self.head.take().map(|node| { self.head = node.next; node.data }) } } impl\u0026lt;T: std::fmt::Display\u0026gt; LinkedList\u0026lt;T\u0026gt; { fn print(\u0026amp;self) { let mut current = \u0026amp;self.head; while let Some(node) = current { print!(\u0026#34;{} \u0026#34;, node.data); current = \u0026amp;node.next; } println!(); } } 快速建立心理模型：Rust = \u0026ldquo;强制的智能指针\u0026rdquo; 对C++程序员来说，理解Rust最快的方法是把它想象成\u0026quot;强制使用智能指针的C++\u0026quot;：\n1 2 3 4 5 6 7 // C++：你可以选择不安全的方式 int* raw_ptr = new int(42); // 危险但可编译 auto safe_ptr = std::make_unique\u0026lt;int\u0026gt;(42); // 安全但可选 // Rust：强制你使用安全的方式 let safe_value = 42; // 等价于unique_ptr，但是强制的 // 没有\u0026#34;unsafe\u0026#34;的裸指针创建方式（除非显式使用unsafe块） 关键理解：\nRust的普通变量 ≈ C++的unique_ptr Rust的\u0026amp;T ≈ C++的const T\u0026amp; Rust的\u0026amp;mut T ≈ C++的T\u0026amp; Rust的Arc\u0026lt;T\u0026gt; ≈ C++的shared_ptr\u0026lt;T\u0026gt; 一旦建立了这个对应关系，很多Rust概念就变得直观了。\n性能对比 运行时开销 1 2 3 4 5 6 7 8 9 10 11 // Rust - 零运行时开销 fn rust_performance() { let data = vec![1, 2, 3, 4, 5]; process_data(\u0026amp;data); // 编译时确保安全，无运行时检查 } fn process_data(data: \u0026amp;Vec\u0026lt;i32\u0026gt;) { for item in data.iter() { println!(\u0026#34;{}\u0026#34;, item); } } 1 2 3 4 5 6 7 8 9 10 11 // C++ - shared_ptr有引用计数开销 void cpp_performance() { auto data = std::make_shared\u0026lt;std::vector\u0026lt;int\u0026gt;\u0026gt;{1, 2, 3, 4, 5}; process_data(data); // 每次传递都要原子操作更新引用计数 } void process_data(std::shared_ptr\u0026lt;std::vector\u0026lt;int\u0026gt;\u0026gt; data) { for (const auto\u0026amp; item : *data) { std::cout \u0026lt;\u0026lt; item \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } } 内存布局对比 graph TD subgraph \"C++ shared_ptr\" A[对象] --\u003e B[引用计数] C[智能指针1] --\u003e A D[智能指针2] --\u003e A E[智能指针3] --\u003e A end subgraph \"Rust 所有权\" F[所有者] --\u003e G[对象] H[借用1] -.-\u003e G I[借用2] -.-\u003e G end Rust如何防止C++常见陷阱 Rust的严格规则实际上是在防止C++中容易出现的问题：\n防止迭代器失效 C++中的隐患：\n1 2 3 4 5 6 7 8 9 10 void cpp_iterator_danger() { std::vector\u0026lt;int\u0026gt; vec = {1, 2, 3, 4, 5}; for (auto it = vec.begin(); it != vec.end(); ++it) { if (*it == 3) { vec.erase(it); // 危险！iterator可能失效 // 如果忘记break，下次++it就是未定义行为 } } } Rust的解决方案：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 fn rust_safe_iteration() { let mut vec = vec![1, 2, 3, 4, 5]; // 编译器强制使用安全的方式 vec.retain(|\u0026amp;x| x != 3); // 内置的安全方法 // 或者明确的两阶段操作 let to_remove: Vec\u0026lt;_\u0026gt; = vec.iter() .enumerate() .filter(|(_, \u0026amp;value)| value == 3) .map(|(index, _)| index) .collect(); for \u0026amp;index in to_remove.iter().rev() { vec.remove(index); } } 防止悬垂引用 C++需要小心的情况：\n1 2 3 4 5 6 7 8 9 10 11 class DataManager { std::vector\u0026lt;std::string\u0026gt; storage; public: const std::string\u0026amp; get_data(size_t index) { if (index \u0026lt; storage.size()) { return storage[index]; // 返回引用 } return storage.emplace_back(\u0026#34;default\u0026#34;); // 可能导致重新分配！ } }; Rust在编译时阻止：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 struct DataManager { storage: Vec\u0026lt;String\u0026gt;, } impl DataManager { fn get_data(\u0026amp;mut self, index: usize) -\u0026gt; \u0026amp;String { if index \u0026lt; self.storage.len() { \u0026amp;self.storage[index] } else { self.storage.push(\u0026#34;default\u0026#34;.to_string()); \u0026amp;self.storage[self.storage.len() - 1] // 编译错误！ // 不能在修改后返回引用 } } // 正确的做法：返回拥有的值或使用不同的设计 fn get_data_safe(\u0026amp;mut self, index: usize) -\u0026gt; String { if index \u0026lt; self.storage.len() { self.storage[index].clone() } else { self.storage.push(\u0026#34;default\u0026#34;.to_string()); self.storage[self.storage.len() - 1].clone() } } } 适用场景分析 选择C++智能指针的场景 现有C++项目迁移 1 2 3 4 5 6 7 8 // 渐进式重构现有代码 class LegacySystem { // 原来：raw pointer // SomeClass* ptr_; // 重构后：smart pointer std::unique_ptr\u0026lt;SomeClass\u0026gt; ptr_; }; 需要动态多态 1 2 3 std::vector\u0026lt;std::unique_ptr\u0026lt;Shape\u0026gt;\u0026gt; shapes; shapes.push_back(std::make_unique\u0026lt;Circle\u0026gt;(5.0)); shapes.push_back(std::make_unique\u0026lt;Rectangle\u0026gt;(3.0, 4.0)); 选择Rust所有权的场景 新项目且要求极高的安全性 1 2 3 4 5 // 系统级编程，要求零成本抽象 fn process_large_data(data: \u0026amp;[u8]) -\u0026gt; Result\u0026lt;Vec\u0026lt;u8\u0026gt;, Error\u0026gt; { // 编译时保证内存安全 Ok(data.iter().map(|\u0026amp;b| b ^ 0xFF).collect()) } 并发密集型应用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 use std::sync::Arc; use std::thread; fn concurrent_processing(data: Arc\u0026lt;Vec\u0026lt;i32\u0026gt;\u0026gt;) { let handles: Vec\u0026lt;_\u0026gt; = (0..4).map(|i| { let data = Arc::clone(\u0026amp;data); thread::spawn(move || { // 编译时保证线程安全 process_chunk(\u0026amp;data[i*1000..(i+1)*1000]); }) }).collect(); for handle in handles { handle.join().unwrap(); } } 给C++程序员的Rust学习建议 通过对比学习，我发现Rust的所有权系统并没有想象中那么难理解：\n核心相似性总结 思维模式相同：都是通过类型系统管理资源生命周期 RAII原则：都遵循\u0026quot;获取即初始化，离开即销毁\u0026quot; 零成本抽象：都能在编译时优化掉管理开销 移动语义：都支持高效的所有权转移 主要区别：编译时 vs 运行时 方面 C++智能指针 Rust所有权 检查时机 运行时（部分编译时） 完全编译时 学习方式 可渐进采用 必须全面掌握 错误发现 运行时崩溃/泄漏 编译期阻止 性能开销 shared_ptr有开销 零开销 ","date":"2024-01-18T16:45:00+08:00","permalink":"https://tech-gt.github.io/p/rust-ownership-vs-cpp-smart-pointers/","title":"Rust的所有权机制和C++智能指针对比"},{"content":"在构建分布式系统时，我们经常面临一个棘手的问题：如何保证跨服务的操作要么都成功，要么都失败？举个最经典的例子：电商系统中的订单服务创建了订单后，需要通知库存服务扣减库存。如果订单创建成功，但扣减库存的通知消息丢失了，就会导致超卖，这在业务上是不可接受的。\n能不能让发送消息这个动作也加入到本地数据库事务里？ 这就是事务消息。 它的核心目标是：如果你的数据库操作成功了，那么这条消息就必须成功发送出去；如果你的数据库操作因为任何原因回滚了，那么这条消息就绝对不能被发送出去。\n事务消息的实现原理 (两阶段提交) 事务消息通常采用一种“两阶段提交”(2PC - Two-Phase Commit) 的思想来实现。以支持事务消息的 RocketMQ 为例，其流程如下：\n阶段一：发送“半消息”（Half Message / Pre-committed Message） 生产者（例如订单服务）先将一条“半消息”发送到 MQ 服务器。 这条“半消息”对下游的消费者是完全不可见的。它的作用是向 MQ 服务器“预定”一个消息位，告诉 MQ：“我准备要发一条消息了，请你先占个位置，但别让消费者看到。” MQ 服务器收到半消息后，会将其持久化，并向生产者返回一个“半消息发送成功”的确认。 阶段二：执行本地事务并提交最终状态 生产者收到了“半消息发送成功”的确认后，开始执行自己的本地数据库事务（即创建订单的操作）。 根据本地事务的执行结果，生产者会向 MQ 服务器发送一个最终确认 (Commit / Rollback)： 如果本地事务成功提交 (Commit)： 生产者就向 MQ 服务器发送一个 Commit 请求。MQ 服务器收到后，会将之前的“半消息”标记为可投递状态，此时消费者才能真正地拉取到这条消息。 如果本地事务失败回滚 (Rollback)： 生产者就向 MQ 服务器发送一个 Rollback 请求。MQ 服务器收到后，会直接删除之前的“半消息”。这条消息仿佛从未存在过，消费者自然也永远不会收到它。 异常情况处理：事务状态回查机制 一个棘手的问题是：如果在第二阶段，生产者执行完本地事务后，在发送最终 Commit 或 Rollback 请求时宕机了怎么办？\n此时，MQ 服务器上的那条“半消息”会一直处于中间状态，既不被投递也不被删除。\n为了解决这个问题，支持事务消息的 MQ 系统通常带有一个状态回查机制：\nMQ 服务器会定期（或在超时后）向消息的生产者主动发起一个“回查”请求。 生产者的应用程序需要提供一个回查接口。在这个接口里，生产者需要去检查对应那条消息的本地事务的最终状态（比如去数据库里查一下那个订单号是否存在且状态是“已支付”）。 根据查询到的本地事务状态，生产者在回查接口中再次告诉 MQ 服务器应该 Commit 还是 Rollback 这条半消息。 一、RabbitMQ原生事务的局限 RabbitMQ本身提供了事务机制。但在实际生产中，这套原生事务机制却很少被使用。\nRabbitMQ通过三个核心命令提供了事务功能：\ntx.Select: 告诉服务器，当前Channel要开启一个事务。 tx.Commit: 提交事务。 tx.Rollback: 回滚事务。 使用起来大概是这样（伪代码）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 try { // 1. 开启事务 channel.txSelect(); // 2. 发送消息 channel.basicPublish(\u0026#34;exchange\u0026#34;, \u0026#34;routingKey\u0026#34;, null, message.getBytes()); // 模拟业务异常 if (someCondition) { throw new RuntimeException(\u0026#34;业务异常\u0026#34;); } // 3. 提交事务 channel.txCommit(); } catch (Exception e) { // 4. 回滚事务 channel.txRollback(); } 这看起来似乎完美地解决了问题。如果在txCommit()之前发生任何异常，我们可以通过txRollback()来撤销所有已发送但未提交的消息。\n但它为什么会被冷落呢？\n根本原因在于性能。RabbitMQ的事务机制是同步阻塞的。当一个Channel调用txSelect()后，这个Channel上发布的所有消息都会在Broker端被缓存，直到txCommit()被调用，这些消息才会被真正地投递到目标队列。在这个过程中，Publisher会一直等待Broker的响应，这极大地降低了消息发送的吞吐量。官方文档也明确指出，使用事务会让消息吞吐量下降2到10倍。\n对于需要高吞吐量的互联网应用来说，这种性能损失是致命的。因此，我们必须寻找替代方案。\n二、发送方确认机制 (Publisher Confirms) 的局限 为了解决原生事务的性能问题，RabbitMQ引入了Publisher Confirms机制。这是一种轻量级的、异步的确认方式，用来保证消息被成功发送到了Broker。\n它的核心思想是：Producer将Channel设置为Confirm模式后，后续在该Channel上发布的消息都会被分配一个唯一的ID。一旦消息被Broker正确接收，Broker就会发送一个确认（Ack）给Producer。如果消息因为Broker内部错误无法被处理，Broker则会发送一个否定确认（Nack）。\n因为是异步的，Producer在发送消息后可以不必等待，继续发送下一条消息，大大提高了性能。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // 开启发送方确认模式 channel.confirmSelect(); // 添加确认监听器 channel.addConfirmListener(new ConfirmListener() { @Override public void handleAck(long deliveryTag, boolean multiple) throws IOException { // deliveryTag: 消息的唯一ID // multiple: 是否是批量确认 System.out.println(\u0026#34;消息 \u0026#34; + deliveryTag + \u0026#34; 已被确认\u0026#34;); // 在这里可以安全地认为消息已到达Broker } @Override public void handleNack(long deliveryTag, boolean multiple) throws IOException { System.out.println(\u0026#34;消息 \u0026#34; + deliveryTag + \u0026#34; 未被确认，需要重试或记录日志\u0026#34;); // 进行消息重发、记录日志等操作 } }); // 发送消息 channel.basicPublish(\u0026#34;my-exchange\u0026#34;, \u0026#34;routing-key\u0026#34;, null, \u0026#34;Hello\u0026#34;.getBytes()); Publisher Confirms机制解决了消息从Producer到Broker的可靠性问题，但它依然无法解决我们开篇提到的分布式事务问题——业务操作和消息发送，这两个动作如何原子化？\n三、推荐方案：基于“本地消息表”的最终一致性 这是业界解决分布式事务最经典、最通用的模式之一，其核心思想是将业务操作和“发送消息”这个动作捆绑在同一个本地事务中。\nsequenceDiagram participant User as 用户 participant OrderSvc as 订单服务 participant OrderDB as 订单库(本地消息表) participant Scheduler as 定时任务 participant RabbitMQ participant InventorySvc as 库存服务 User-\u003e\u003e+OrderSvc: 创建订单请求 OrderSvc-\u003e\u003eOrderDB: 开启数据库事务 Note right of OrderSvc: 1. 在本地事务中执行业务 OrderSvc-\u003e\u003eOrderDB: 1.1 INSERT INTO orders ... OrderSvc-\u003e\u003eOrderDB: 1.2 INSERT INTO message_log (status='PENDING') ... OrderSvc-\u003e\u003eOrderDB: 提交数据库事务 OrderSvc--\u003e\u003e-User: 下单成功 loop 定时扫描 Scheduler-\u003e\u003e+OrderDB: 2. SELECT * FROM message_log WHERE status='PENDING' OrderDB--\u003e\u003e-Scheduler: 返回待发送消息列表 end Scheduler-\u003e\u003e+RabbitMQ: 3. 发送消息 RabbitMQ--\u003e\u003e-Scheduler: 4. 返回Publisher Confirm (Ack) alt 收到Ack Scheduler-\u003e\u003e+OrderDB: 5. UPDATE message_log SET status='SENT' OrderDB--\u003e\u003e-Scheduler: 更新成功 else 收到Nack或超时 Scheduler-\u003e\u003eScheduler: 重试或记录错误 end RabbitMQ-\u003e\u003e+InventorySvc: 6. 投递消息 Note right of InventorySvc: 7. 消费者处理业务 InventorySvc-\u003e\u003eInventorySvc: 扣减库存等操作 InventorySvc-\u003e\u003e-RabbitMQ: 8. 发送ack (消费者确认) 整个流程分解如下：\n执行本地事务：当订单服务要创建订单时，它会开启一个本地数据库事务。在这个事务里，它不仅会向orders业务表插入数据，还会向一张local_message（本地消息表）里插入一条记录。这条消息记录了需要发送给下游的消息内容，其初始状态为“发送中”（Pending）。 事务提交：由于业务操作和写消息日志在同一个事务里，因此它们要么都成功，要么都失败。这就保证了只要订单创建成功，要发送的消息就一定被存下来了。 定时任务投递消息：一个独立的后台任务（或者线程池）会定期扫描local_message表，拉取状态为“发送中”的消息。 可靠发送：定时任务将消息发送到RabbitMQ，并使用Publisher Confirms机制等待Broker的确认。 更新消息状态：如果收到Broker的Ack，就将本地消息表中的对应记录状态更新为“已发送”（Sent）。如果收到Nack或者超时未收到确认，则可以根据策略进行重试。 消费者处理：库存服务作为消费者，接收到消息后处理自己的业务（扣减库存）。为了防止消息处理失败导致消息丢失，消费者必须使用手动ack模式。只有当业务逻辑成功处理完毕后，才向RabbitMQ发送ack，此时RabbitMQ才会真正地将消息从队列中删除。 这个方案通过一张额外的日志表，巧妙地将分布式事务问题转化为了一个本地事务问题，并通过定时任务和重试机制，保证了消息最终一定能被成功发送和消费，实现了系统的最终一致性。\n结语 技术选型没有绝对的好坏，只有适不适合。RabbitMQ的原生事务（txSelect）因其性能问题，在大部分场景下都不是一个好的选择。相比之下，Publisher Confirms + 手动ack + 本地消息表的组合拳，虽然实现上更复杂一些，但它提供了一种健壮的、高性能的、可扩展的分布式事务解决方案，是构建可靠微服务系统的事实标准之一。\n","date":"2024-01-18T16:20:00+08:00","permalink":"https://tech-gt.github.io/p/rabbitmq%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF/","title":"RabbitMQ如何实现事务消息？"},{"content":"一、问题背景 近日，收到开发环境一台服务器的磁盘空间告警，提示根分区使用率已达 96%。该服务器主要用于运行各类应用的 Docker 容器，日常数据量和日志增长相对稳定，因此初步判断问题可能出在 Docker 本身。本文旨在记录完整的排查思路与最终的解决方案。\n二、排查过程 确认磁盘使用情况\n首先，登录服务器，使用 df -h 命令检查磁盘各分区的详细使用情况。\n1 2 3 4 $ df -h Filesystem Size Used Avail Use% Mounted on /dev/vda1 100G 96G 4.0G 96% / ... 输出证实了根分区 / 确实即将耗尽。\n定位大文件目录\n接下来，需要找出是哪个目录占用了大量空间。我们从根目录开始，使用 du -sh /* 命令逐层分析。\n1 2 3 4 5 # 为了避免权限问题，建议使用 sudo $ sudo du -sh /* | sort -rh 78G /var 15G /usr ... 很快定位到 /var 目录异常庞大。继续深入排查 /var 目录。\n1 2 3 $ sudo du -sh /var/* | sort -rh 75G /var/lib ... 最终，我们将目标锁定在 /var/lib/docker 目录，它占用了超过 70G 的空间。\n分析 Docker 磁盘占用\n既然确定是 Docker 的问题，就可以使用 Docker 自带的命令进行分析。docker system df 是一个非常有用的命令，可以清晰地列出 Docker 各类资源的占用情况。\n1 2 3 4 5 6 $ docker system df TYPE TOTAL ACTIVE SIZE RECLAIMABLE Images 58 12 25.8GB 22.1GB (85%) Containers 15 10 1.2GB 250MB (20%) Local Volumes 22 5 8.9GB 6.5GB (73%) Build Cache 541 0 35.6GB 35.6GB (100%) 结果一目了然：\nImages：存在大量未使用的镜像，可回收空间巨大。 Local Volumes：存在许多无主（dangling）的数据卷。 Build Cache：构建缓存占用了惊人的 35.6GB，且全部可以回收。 这些可回收空间（RECLAIMABLE）的总和，正是导致我们磁盘爆满的元凶。\n三、原因剖析 overlay2 是 Docker 使用的默认存储驱动，它负责管理镜像层和容器的读写层。我们拉取的每一个镜像、构建的每一个中间层、运行的每一个容器，都会在 /var/lib/docker/overlay2 目录下留下数据。随着时间推移，以下几类资源会不断累积：\n悬空镜像（Dangling Images）：镜像的新版本覆盖了旧版本后，没有标签（tag）的旧镜像层并未被删除。 停止运行的容器：执行 docker stop 后的容器虽然不占用计算资源，但其文件系统层依然占用磁盘。 无主数据卷（Dangling Volumes）：删除了容器但未删除其关联的数据卷，这些卷会一直存在。 构建缓存（Build Cache）：docker build 过程中会产生大量的中间镜像层作为缓存，以加速后续构建，这是最容易被忽视的“空间大户”。 四、解决方案 针对以上问题，Docker 提供了强大的 prune 系列命令用于清理。\n方案一：一键“瘦身”（适用于清理开发环境） 对于开发或测试环境，可以使用以下命令进行一次彻底的清理，它会删除所有未被容器使用的资源。\n1 2 3 4 # -a: 清理所有未被容器引用的资源，而不仅仅是悬空的 # --volumes: 同时清理无主的数据卷 # -f: 强制执行，无需交互式确认 docker system prune -a -f --volumes 警告：--volumes 参数会删除所有未被任何现有容器引用的数据卷。在生产环境执行前，请务必确认这些数据卷不再需要，否则可能导致数据永久丢失。\n方案二：精细化清理（推荐） 更安全、更可控的方式是分类进行清理。\n清理已停止的容器\n1 docker container prune -f 清理无用镜像\n1 2 3 4 5 # 只清理悬空镜像 docker image prune -f # 清理所有未被使用的镜像（慎用） docker image prune -a -f 清理无用数据卷\n1 docker volume prune -f 清理构建缓存\n1 docker builder prune -f 执行完上述清理操作后，再次运行 df -h，可以看到磁盘空间被成功释放。\n五、建立长效机制 为了避免问题复现，建议建立自动化的清理机制。例如，可以设置一个 cron 定时任务，在业务低峰期（如每日凌晨）自动执行清理。\n1 2 3 4 5 # 编辑 crontab crontab -e # 添加以下任务，每天凌晨3点执行清理 0 3 * * * /usr/bin/docker system prune -f --volumes \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 同时，在编写 Dockerfile 时，应遵循最佳实践，例如合并多个 RUN 命令、使用 .dockerignore 文件，以减少镜像体积和构建缓存。\n","date":"2024-01-10T15:30:00+08:00","permalink":"https://tech-gt.github.io/p/%E8%AE%B0%E4%B8%80%E6%AC%A1-docker-overlay2-%E7%9B%AE%E5%BD%95%E5%AF%BC%E8%87%B4%E7%A3%81%E7%9B%98%E7%88%86%E6%BB%A1%E7%9A%84%E6%8E%92%E6%9F%A5%E4%B8%8E%E8%A7%A3%E5%86%B3/","title":"记一次 Docker overlay2 目录导致磁盘爆满的排查与解决"},{"content":"-XX:NewRatio、-XX:SurvivorRatio、-XX:MaxTenuringThreshold\u0026hellip;一堆参数让人头大。\n但时代变了。随着JVM垃圾回收器的不断进化，那些复杂的调优参数正在成为历史。 今天我们就来聊聊：在现代JDK版本中，我们还需要那么复杂的JVM调优吗？\n一、传统GC的调优噩梦 Serial GC 和 Parallel GC 时代 在早期的JDK版本中，我们主要使用Serial GC和Parallel GC。这些收集器虽然简单，但需要大量的手工调优：\n1 2 3 4 5 6 7 8 9 # 传统的复杂调优参数 -XX:+UseParallelGC -XX:ParallelGCThreads=8 -XX:NewRatio=3 -XX:SurvivorRatio=8 -XX:MaxTenuringThreshold=15 -XX:+UseAdaptiveSizePolicy -XX:MaxGCPauseMillis=200 -XX:GCTimeRatio=19 每个参数都需要根据应用特性精心调整，稍有不慎就可能导致：\nYoung GC频繁，影响吞吐量 Full GC时间过长，造成应用卡顿 内存分配不合理，浪费堆空间 CMS时代的复杂性 CMS（Concurrent Mark Sweep）的出现让我们看到了低延迟的希望，但也带来了更多的调优复杂性：\n1 2 3 4 5 6 7 8 # CMS的复杂配置 -XX:+UseConcMarkSweepGC -XX:+CMSParallelRemarkEnabled -XX:CMSInitiatingOccupancyFraction=70 -XX:+UseCMSInitiatingOccupancyOnly -XX:+CMSClassUnloadingEnabled -XX:+CMSPermGenSweepingEnabled -XX:CMSMaxAbortablePrecleanTime=5000 这些参数需要深入理解CMS的工作原理，调优门槛极高。\n二、G1：自适应调优的开始 G1垃圾回收器的出现标志着JVM调优开始向简化方向发展。G1最大的亮点是目标导向的调优：\n1 2 3 4 # G1的简化配置 -XX:+UseG1GC -XX:MaxGCPauseMillis=200 -Xms8g -Xmx8g 相比传统GC，G1只需要设置一个核心参数：MaxGCPauseMillis。G1会自动调整其内部参数来尽量达到这个停顿时间目标。\nG1的自适应机制 G1内部实现了复杂的自适应算法：\n动态调整Region大小：根据堆大小自动计算最优的Region大小 智能选择Collection Set：优先回收垃圾最多的Region 自适应的并发线程数：根据CPU核心数自动调整 这意味着大部分场景下，我们不再需要手动调整那些复杂的内存分代参数。\n三、ZGC：调优的终极简化 美团的ZGC实践：从复杂到简单 美团技术团队在《新一代垃圾回收器ZGC的探索与实践》中分享了一个典型案例：\n升级前（CMS/G1）：\n需要精心调优十几个GC参数 Young GC平均40ms，高峰期频繁 P999响应时间超过70ms 经常因为GC调优问题导致线上故障 升级后（ZGC）：\n1 2 3 # ZGC的极简配置 -XX:+UseZGC -Xms10g -Xmx10g 仅仅两行配置，就实现了：\nP999响应时间降低到10ms以下 GC停顿时间稳定在亚毫秒级别 几乎不需要任何调优参数 ZGC为什么不需要复杂调优？ ZGC的设计哲学就是**\u0026ldquo;开箱即用\u0026rdquo;**：\n无分代设计：不需要调整新生代、老年代比例 着色指针技术：自动处理对象移动，无需手动优化 并发回收：几乎所有GC工作都与应用线程并发进行 自适应算法：内部算法会自动优化回收策略 1 2 3 4 5 6 7 8 9 10 11 12 // ZGC的核心优势：极简配置 public class ZGCExample { public static void main(String[] args) { // 无论堆多大，无论对象多少 // ZGC都能保持稳定的低延迟 List\u0026lt;Object\u0026gt; objects = new ArrayList\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; 1000000; i++) { objects.add(new Object()); // GC停顿时间始终 \u0026lt; 10ms } } } 四、现代JDK：能升级就升级 JDK版本选择策略 基于美团等公司的实践经验，我的建议是：\n1 2 3 4 5 # 推荐的JDK版本选择 JDK 8 -\u0026gt; 尽快升级到 JDK 17/21 JDK 11 -\u0026gt; 升级到 JDK 17/21 JDK 17 -\u0026gt; 当前最佳选择 JDK 21 -\u0026gt; 最新LTS，推荐新项目使用 升级带来的调优简化 JDK 8时代的复杂配置：\n1 2 3 4 5 6 7 8 -XX:+UseG1GC -XX:MaxGCPauseMillis=200 -XX:G1HeapRegionSize=16m -XX:G1NewSizePercent=30 -XX:G1MaxNewSizePercent=40 -XX:G1MixedGCLiveThresholdPercent=85 -XX:G1MixedGCCountTarget=8 -XX:G1OldCSetRegionThresholdPercent=10 JDK 17+ ZGC的简化配置：\n1 2 -XX:+UseZGC -Xms8g -Xmx8g 差距一目了然！\n五、实战 1. 优先选择现代GC 1 2 3 4 5 6 7 8 9 10 11 # 推荐的GC选择策略 # 延迟敏感应用 -XX:+UseZGC # JDK 15+ # 吞吐量优先应用 -XX:+UseG1GC # JDK 9+ -XX:MaxGCPauseMillis=100 # 避免使用的老旧GC # -XX:+UseParallelGC # 除非特殊场景 # -XX:+UseConcMarkSweepGC # 已废弃 2. 关注应用层面优化 现代JVM调优的重点已经从GC参数转向应用层面：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 // 现代Java应用优化重点 public class ModernOptimization { // 1. 减少对象分配 private static final List\u0026lt;String\u0026gt; CACHE = new ArrayList\u0026lt;\u0026gt;(); // 2. 使用对象池 private static final ObjectPool\u0026lt;StringBuilder\u0026gt; POOL = new ObjectPool\u0026lt;\u0026gt;(StringBuilder::new); // 3. 合理使用缓存 @Cacheable(\u0026#34;userCache\u0026#34;) public User getUser(Long id) { return userRepository.findById(id); } // 4. 异步处理减少延迟 @Async public CompletableFuture\u0026lt;Void\u0026gt; processAsync(Data data) { // 异步处理逻辑 return CompletableFuture.completedFuture(null); } } 3. 监控和观测 现代JVM调优更注重监控和观测：\n1 2 3 4 5 # 启用现代监控参数 -XX:+FlightRecorder -XX:StartFlightRecording=duration=60s,filename=gc.jfr -XX:+UnlockExperimentalVMOptions -XX:+UseJVMCICompiler # GraalVM 六、迁移实践：美团的经验总结 迁移步骤 基于美团的实践，ZGC迁移可以分为以下步骤：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 第一步：环境准备 # 升级到JDK 17+ sudo update-alternatives --install /usr/bin/java java /opt/jdk-17/bin/java 1 # 第二步：简化JVM参数 # 移除所有复杂的GC调优参数 # 只保留核心配置 -XX:+UseZGC -Xms16g -Xmx16g -XX:+AlwaysPreTouch # 第三步：依赖升级 # 升级不兼容的依赖库 # Lombok -\u0026gt; 1.18.20+ # Netty -\u0026gt; 4.1.65+ 七、总结：调优的未来 调优理念的转变 从美团的实践和现代JDK的发展趋势来看，JVM调优正在发生根本性转变：\n传统调优：\n关注GC参数的精细调整 需要深入理解GC算法 调优门槛高，风险大 现代调优：\n优先升级JDK版本 选择合适的GC算法 关注应用层面优化 重视监控和观测 实用建议 能升级就升级：JDK 17/21 带来的收益远超调优参数 选择现代GC：ZGC/G1 比复杂的参数调优更有效 关注应用优化：减少对象分配比调优GC参数更重要 建立监控体系：用数据说话，而不是凭感觉调优 技术的进步让复杂的事情变得简单。就像我们不再需要手动管理内存一样，复杂的JVM调优也正在成为历史。\n","date":"2023-09-18T14:20:00+08:00","permalink":"https://tech-gt.github.io/p/jvm%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8%E7%9A%84%E8%BF%9B%E5%8C%96%E8%BF%98%E9%9C%80%E8%A6%81jvm%E8%B0%83%E4%BC%98%E5%90%97/","title":"JVM垃圾回收器的进化：还需要JVM调优吗？"},{"content":"前言 在做企业级系统开发时，权限控制是绕不开的话题。最近在设计一个文档管理系统，需要支持复杂的权限管理：不同部门的用户对文档有不同的操作权限，同时还要支持临时授权和细粒度控制。\n在调研过程中，我发现RBAC（基于角色的访问控制）和ACL（访问控制列表）是两种最经典的权限控制模型。虽然理论很清楚，但在实际项目中如何选择和实现，还是有很多细节需要考虑。\n今天就来聊聊这两种权限模型的设计思路、实现方案，以及在不同场景下的选择策略。\n权限控制基础概念 在深入RBAC和ACL之前，先明确几个核心概念：\n主体(Subject)：发起访问请求的实体，通常是用户 客体(Object)：被访问的资源，如文件、数据、功能模块 操作(Action)：对资源的具体操作，如读取、修改、删除 权限(Permission)：主体对客体执行某种操作的许可 graph LR A[主体/用户] --\u003e|执行| B[操作] B --\u003e|作用于| C[客体/资源] D[权限策略] --\u003e|控制| B style A fill:#e1f5fe style C fill:#f3e5f5 style D fill:#e8f5e8 RBAC：基于角色的访问控制 基本原理 RBAC的核心思想是在用户和权限之间引入角色(Role)这个中间层：\n1 用户(User) → 角色(Role) → 权限(Permission) → 资源(Resource) 这样做的好处是将用户和具体权限解耦，通过角色来批量管理权限。\nRBAC模型层次 RBAC0：基础模型 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 // 用户实体 @Entity public class User { @Id private Long id; private String username; private String email; @ManyToMany @JoinTable(name = \u0026#34;user_role\u0026#34;, joinColumns = @JoinColumn(name = \u0026#34;user_id\u0026#34;), inverseJoinColumns = @JoinColumn(name = \u0026#34;role_id\u0026#34;)) private Set\u0026lt;Role\u0026gt; roles = new HashSet\u0026lt;\u0026gt;(); } // 角色实体 @Entity public class Role { @Id private Long id; private String name; private String description; @ManyToMany @JoinTable(name = \u0026#34;role_permission\u0026#34;, joinColumns = @JoinColumn(name = \u0026#34;role_id\u0026#34;), inverseJoinColumns = @JoinColumn(name = \u0026#34;permission_id\u0026#34;)) private Set\u0026lt;Permission\u0026gt; permissions = new HashSet\u0026lt;\u0026gt;(); } // 权限实体 @Entity public class Permission { @Id private Long id; private String name; // 权限名称，如 \u0026#34;user:create\u0026#34; private String resource; // 资源，如 \u0026#34;user\u0026#34; private String action; // 操作，如 \u0026#34;create\u0026#34; private String description; } RBAC1：角色层次模型 支持角色继承，子角色自动拥有父角色的权限：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 @Entity public class Role { @Id private Long id; private String name; // 父角色 @ManyToOne @JoinColumn(name = \u0026#34;parent_id\u0026#34;) private Role parent; // 子角色 @OneToMany(mappedBy = \u0026#34;parent\u0026#34;) private Set\u0026lt;Role\u0026gt; children = new HashSet\u0026lt;\u0026gt;(); @ManyToMany private Set\u0026lt;Permission\u0026gt; permissions = new HashSet\u0026lt;\u0026gt;(); /** * 获取所有权限（包括继承的） */ public Set\u0026lt;Permission\u0026gt; getAllPermissions() { Set\u0026lt;Permission\u0026gt; allPermissions = new HashSet\u0026lt;\u0026gt;(permissions); // 递归获取父角色的权限 if (parent != null) { allPermissions.addAll(parent.getAllPermissions()); } return allPermissions; } } RBAC实现示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 @Service public class RBACPermissionService { @Autowired private UserRepository userRepository; /** * 检查用户是否有指定权限 */ public boolean hasPermission(Long userId, String resource, String action) { User user = userRepository.findById(userId) .orElseThrow(() -\u0026gt; new UserNotFoundException(\u0026#34;用户不存在\u0026#34;)); String permissionName = resource + \u0026#34;:\u0026#34; + action; return user.getRoles().stream() .flatMap(role -\u0026gt; role.getAllPermissions().stream()) .anyMatch(permission -\u0026gt; permission.getName().equals(permissionName)); } /** * 获取用户所有权限 */ public Set\u0026lt;String\u0026gt; getUserPermissions(Long userId) { User user = userRepository.findById(userId) .orElseThrow(() -\u0026gt; new UserNotFoundException(\u0026#34;用户不存在\u0026#34;)); return user.getRoles().stream() .flatMap(role -\u0026gt; role.getAllPermissions().stream()) .map(Permission::getName) .collect(Collectors.toSet()); } /** * 为用户分配角色 */ @Transactional public void assignRole(Long userId, Long roleId) { User user = userRepository.findById(userId) .orElseThrow(() -\u0026gt; new UserNotFoundException(\u0026#34;用户不存在\u0026#34;)); Role role = roleRepository.findById(roleId) .orElseThrow(() -\u0026gt; new RoleNotFoundException(\u0026#34;角色不存在\u0026#34;)); user.getRoles().add(role); userRepository.save(user); } } 权限拦截器实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 @Component public class PermissionInterceptor implements HandlerInterceptor { @Autowired private RBACPermissionService permissionService; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { if (!(handler instanceof HandlerMethod)) { return true; } HandlerMethod handlerMethod = (HandlerMethod) handler; RequiresPermission annotation = handlerMethod.getMethodAnnotation(RequiresPermission.class); if (annotation == null) { return true; // 无权限要求，放行 } // 获取当前用户ID（从JWT或Session中获取） Long userId = getCurrentUserId(request); if (userId == null) { throw new UnauthorizedException(\u0026#34;未登录\u0026#34;); } // 检查权限 String resource = annotation.resource(); String action = annotation.action(); if (!permissionService.hasPermission(userId, resource, action)) { throw new ForbiddenException(\u0026#34;权限不足\u0026#34;); } return true; } } // 权限注解 @Target({ElementType.METHOD}) @Retention(RetentionPolicy.RUNTIME) public @interface RequiresPermission { String resource(); String action(); } // 使用示例 @RestController @RequestMapping(\u0026#34;/api/users\u0026#34;) public class UserController { @GetMapping @RequiresPermission(resource = \u0026#34;user\u0026#34;, action = \u0026#34;list\u0026#34;) public List\u0026lt;User\u0026gt; listUsers() { return userService.findAll(); } @PostMapping @RequiresPermission(resource = \u0026#34;user\u0026#34;, action = \u0026#34;create\u0026#34;) public User createUser(@RequestBody CreateUserRequest request) { return userService.create(request); } @DeleteMapping(\u0026#34;/{id}\u0026#34;) @RequiresPermission(resource = \u0026#34;user\u0026#34;, action = \u0026#34;delete\u0026#34;) public void deleteUser(@PathVariable Long id) { userService.delete(id); } } ACL：访问控制列表 基本原理 ACL直接定义主体对特定客体的访问权限，不需要角色这个中间层：\n1 用户(User) → 权限(Permission) → 资源(Resource) ACL的特点是细粒度、直观，能够精确控制每个用户对每个资源的访问权限。\nACL数据模型 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 // ACL条目 @Entity public class AccessControlEntry { @Id private Long id; // 主体（用户） @ManyToOne @JoinColumn(name = \u0026#34;user_id\u0026#34;) private User user; // 资源类型和ID private String resourceType; // 如 \u0026#34;document\u0026#34;, \u0026#34;project\u0026#34; private Long resourceId; // 具体资源的ID // 权限 private boolean canRead = false; private boolean canWrite = false; private boolean canDelete = false; private boolean canShare = false; // 授权相关信息 @ManyToOne @JoinColumn(name = \u0026#34;granted_by\u0026#34;) private User grantedBy; // 授权人 private LocalDateTime grantedAt; // 授权时间 private LocalDateTime expiresAt; // 过期时间 } // 资源基类 public abstract class Resource { protected Long id; protected String type; // 资源的所有者 @ManyToOne private User owner; // 创建时间 private LocalDateTime createdAt; } // 具体资源示例：文档 @Entity public class Document extends Resource { private String title; private String content; private String filePath; @Override public String getType() { return \u0026#34;document\u0026#34;; } } ACL服务实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 @Service public class ACLPermissionService { @Autowired private AccessControlEntryRepository aclRepository; /** * 检查用户对资源的具体权限 */ public boolean hasPermission(Long userId, String resourceType, Long resourceId, String action) { Optional\u0026lt;AccessControlEntry\u0026gt; acl = aclRepository .findByUserIdAndResourceTypeAndResourceId(userId, resourceType, resourceId); if (acl.isEmpty()) { return false; } AccessControlEntry entry = acl.get(); // 检查是否过期 if (entry.getExpiresAt() != null \u0026amp;\u0026amp; entry.getExpiresAt().isBefore(LocalDateTime.now())) { return false; } // 根据操作类型检查权限 switch (action.toLowerCase()) { case \u0026#34;read\u0026#34;: return entry.isCanRead(); case \u0026#34;write\u0026#34;: return entry.isCanWrite(); case \u0026#34;delete\u0026#34;: return entry.isCanDelete(); case \u0026#34;share\u0026#34;: return entry.isCanShare(); default: return false; } } /** * 授予权限 */ @Transactional public void grantPermission(Long userId, String resourceType, Long resourceId, Set\u0026lt;String\u0026gt; permissions, Long grantedBy, LocalDateTime expiresAt) { AccessControlEntry acl = aclRepository .findByUserIdAndResourceTypeAndResourceId(userId, resourceType, resourceId) .orElse(new AccessControlEntry()); acl.setUser(userRepository.findById(userId).orElse(null)); acl.setResourceType(resourceType); acl.setResourceId(resourceId); acl.setGrantedBy(userRepository.findById(grantedBy).orElse(null)); acl.setGrantedAt(LocalDateTime.now()); acl.setExpiresAt(expiresAt); // 设置具体权限 acl.setCanRead(permissions.contains(\u0026#34;read\u0026#34;)); acl.setCanWrite(permissions.contains(\u0026#34;write\u0026#34;)); acl.setCanDelete(permissions.contains(\u0026#34;delete\u0026#34;)); acl.setCanShare(permissions.contains(\u0026#34;share\u0026#34;)); aclRepository.save(acl); } /** * 撤销权限 */ @Transactional public void revokePermission(Long userId, String resourceType, Long resourceId) { aclRepository.deleteByUserIdAndResourceTypeAndResourceId(userId, resourceType, resourceId); } /** * 获取用户对资源的所有权限 */ public List\u0026lt;String\u0026gt; getUserPermissions(Long userId, String resourceType, Long resourceId) { Optional\u0026lt;AccessControlEntry\u0026gt; acl = aclRepository .findByUserIdAndResourceTypeAndResourceId(userId, resourceType, resourceId); if (acl.isEmpty()) { return Collections.emptyList(); } AccessControlEntry entry = acl.get(); List\u0026lt;String\u0026gt; permissions = new ArrayList\u0026lt;\u0026gt;(); if (entry.isCanRead()) permissions.add(\u0026#34;read\u0026#34;); if (entry.isCanWrite()) permissions.add(\u0026#34;write\u0026#34;); if (entry.isCanDelete()) permissions.add(\u0026#34;delete\u0026#34;); if (entry.isCanShare()) permissions.add(\u0026#34;share\u0026#34;); return permissions; } } ACL权限检查注解 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 @Target({ElementType.METHOD}) @Retention(RetentionPolicy.RUNTIME) public @interface RequiresACL { String resourceType(); String action(); String resourceIdParam() default \u0026#34;id\u0026#34;; // 从请求参数中获取资源ID的参数名 } @Component public class ACLInterceptor implements HandlerInterceptor { @Autowired private ACLPermissionService aclService; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { if (!(handler instanceof HandlerMethod)) { return true; } HandlerMethod handlerMethod = (HandlerMethod) handler; RequiresACL annotation = handlerMethod.getMethodAnnotation(RequiresACL.class); if (annotation == null) { return true; } Long userId = getCurrentUserId(request); if (userId == null) { throw new UnauthorizedException(\u0026#34;未登录\u0026#34;); } // 从请求参数中获取资源ID String resourceIdParam = annotation.resourceIdParam(); String resourceIdStr = request.getParameter(resourceIdParam); if (resourceIdStr == null) { // 尝试从路径变量中获取 resourceIdStr = getPathVariable(request, resourceIdParam); } if (resourceIdStr == null) { throw new BadRequestException(\u0026#34;缺少资源ID参数\u0026#34;); } Long resourceId = Long.parseLong(resourceIdStr); // 检查ACL权限 if (!aclService.hasPermission(userId, annotation.resourceType(), resourceId, annotation.action())) { throw new ForbiddenException(\u0026#34;权限不足\u0026#34;); } return true; } } // 使用示例 @RestController @RequestMapping(\u0026#34;/api/documents\u0026#34;) public class DocumentController { @GetMapping(\u0026#34;/{id}\u0026#34;) @RequiresACL(resourceType = \u0026#34;document\u0026#34;, action = \u0026#34;read\u0026#34;) public Document getDocument(@PathVariable Long id) { return documentService.findById(id); } @PutMapping(\u0026#34;/{id}\u0026#34;) @RequiresACL(resourceType = \u0026#34;document\u0026#34;, action = \u0026#34;write\u0026#34;) public Document updateDocument(@PathVariable Long id, @RequestBody UpdateDocumentRequest request) { return documentService.update(id, request); } @DeleteMapping(\u0026#34;/{id}\u0026#34;) @RequiresACL(resourceType = \u0026#34;document\u0026#34;, action = \u0026#34;delete\u0026#34;) public void deleteDocument(@PathVariable Long id) { documentService.delete(id); } } RBAC vs ACL：对比分析 优缺点对比 特性 RBAC ACL 管理复杂度 低（批量管理） 高（逐个管理） 权限粒度 粗粒度 细粒度 扩展性 好 一般 性能 较好 较差（大量记录） 灵活性 一般 很好 适用场景 企业级系统 文件系统、云存储 架构对比 graph TB subgraph \"RBAC架构\" U1[用户] --\u003e R1[角色] U2[用户] --\u003e R1 U3[用户] --\u003e R2[角色] R1 --\u003e P1[权限1] R1 --\u003e P2[权限2] R2 --\u003e P2 R2 --\u003e P3[权限3] end subgraph \"ACL架构\" U4[用户] --\u003e AC1[ACE1: 文档A读权限] U4 --\u003e AC2[ACE2: 文档B写权限] U5[用户] --\u003e AC3[ACE3: 文档A写权限] U6[用户] --\u003e AC4[ACE4: 项目C管理权限] end 混合权限模型 在实际项目中，单纯使用RBAC或ACL往往无法满足所有需求。我们可以结合两者的优势：\n分层权限设计 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 @Service public class HybridPermissionService { @Autowired private RBACPermissionService rbacService; @Autowired private ACLPermissionService aclService; /** * 混合权限检查：先检查RBAC，再检查ACL */ public boolean hasPermission(Long userId, String resourceType, Long resourceId, String action) { // 1. 首先检查RBAC全局权限 if (rbacService.hasPermission(userId, resourceType, action)) { return true; } // 2. 如果没有全局权限，检查ACL特定权限 return aclService.hasPermission(userId, resourceType, resourceId, action); } /** * 系统管理员检查 */ public boolean isSystemAdmin(Long userId) { return rbacService.hasPermission(userId, \u0026#34;system\u0026#34;, \u0026#34;admin\u0026#34;); } /** * 资源所有者检查 */ public boolean isResourceOwner(Long userId, String resourceType, Long resourceId) { // 查询资源所有者 switch (resourceType) { case \u0026#34;document\u0026#34;: Document doc = documentRepository.findById(resourceId).orElse(null); return doc != null \u0026amp;\u0026amp; doc.getOwner().getId().equals(userId); case \u0026#34;project\u0026#34;: Project project = projectRepository.findById(resourceId).orElse(null); return project != null \u0026amp;\u0026amp; project.getOwner().getId().equals(userId); default: return false; } } /** * 完整的权限检查逻辑 */ public boolean checkPermission(Long userId, String resourceType, Long resourceId, String action) { // 1. 系统管理员拥有所有权限 if (isSystemAdmin(userId)) { return true; } // 2. 资源所有者拥有所有权限 if (isResourceOwner(userId, resourceType, resourceId)) { return true; } // 3. 检查混合权限 return hasPermission(userId, resourceType, resourceId, action); } } 权限继承和委托 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 @Entity public class PermissionDelegation { @Id private Long id; @ManyToOne private User delegator; // 委托人 @ManyToOne private User delegatee; // 被委托人 private String resourceType; private Long resourceId; private String action; private LocalDateTime startTime; private LocalDateTime endTime; private boolean active = true; } @Service public class PermissionDelegationService { /** * 创建权限委托 */ public void createDelegation(Long delegatorId, Long delegateeId, String resourceType, Long resourceId, String action, LocalDateTime endTime) { // 检查委托人是否有该权限 if (!hybridPermissionService.checkPermission(delegatorId, resourceType, resourceId, action)) { throw new ForbiddenException(\u0026#34;委托人没有该权限\u0026#34;); } PermissionDelegation delegation = new PermissionDelegation(); delegation.setDelegator(userRepository.findById(delegatorId).orElse(null)); delegation.setDelegatee(userRepository.findById(delegateeId).orElse(null)); delegation.setResourceType(resourceType); delegation.setResourceId(resourceId); delegation.setAction(action); delegation.setStartTime(LocalDateTime.now()); delegation.setEndTime(endTime); delegationRepository.save(delegation); } /** * 检查委托权限 */ public boolean hasDelegatedPermission(Long userId, String resourceType, Long resourceId, String action) { return delegationRepository.existsByDelegateeIdAndResourceTypeAndResourceIdAndActionAndActiveAndEndTimeAfter( userId, resourceType, resourceId, action, true, LocalDateTime.now()); } } 实际应用场景 企业文档管理系统 结合两种模型的企业级应用：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 @RestController @RequestMapping(\u0026#34;/api/documents\u0026#34;) public class EnterpriseDocumentController { @Autowired private HybridPermissionService permissionService; @GetMapping(\u0026#34;/{id}\u0026#34;) public ResponseEntity\u0026lt;Document\u0026gt; getDocument(@PathVariable Long id, HttpServletRequest request) { Long userId = getCurrentUserId(request); // 使用混合权限检查 if (!permissionService.checkPermission(userId, \u0026#34;document\u0026#34;, id, \u0026#34;read\u0026#34;)) { return ResponseEntity.status(HttpStatus.FORBIDDEN).build(); } Document document = documentService.findById(id); return ResponseEntity.ok(document); } @PostMapping(\u0026#34;/{id}/share\u0026#34;) public ResponseEntity\u0026lt;Void\u0026gt; shareDocument(@PathVariable Long id, @RequestBody ShareDocumentRequest request) { Long userId = getCurrentUserId(); // 检查分享权限 if (!permissionService.checkPermission(userId, \u0026#34;document\u0026#34;, id, \u0026#34;share\u0026#34;)) { return ResponseEntity.status(HttpStatus.FORBIDDEN).build(); } // 为目标用户创建ACL权限 aclService.grantPermission( request.getTargetUserId(), \u0026#34;document\u0026#34;, id, request.getPermissions(), userId, request.getExpiresAt() ); return ResponseEntity.ok().build(); } } 性能优化策略 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 @Service public class PermissionCacheService { @Autowired private RedisTemplate\u0026lt;String, Object\u0026gt; redisTemplate; private static final String PERMISSION_CACHE_PREFIX = \u0026#34;perm:\u0026#34;; private static final int CACHE_EXPIRE_SECONDS = 300; // 5分钟 /** * 缓存权限检查结果 */ public boolean hasPermissionWithCache(Long userId, String resourceType, Long resourceId, String action) { String cacheKey = PERMISSION_CACHE_PREFIX + userId + \u0026#34;:\u0026#34; + resourceType + \u0026#34;:\u0026#34; + resourceId + \u0026#34;:\u0026#34; + action; Boolean cachedResult = (Boolean) redisTemplate.opsForValue().get(cacheKey); if (cachedResult != null) { return cachedResult; } // 实际权限检查 boolean hasPermission = hybridPermissionService.checkPermission(userId, resourceType, resourceId, action); // 缓存结果 redisTemplate.opsForValue().set(cacheKey, hasPermission, CACHE_EXPIRE_SECONDS, TimeUnit.SECONDS); return hasPermission; } /** * 清除用户权限缓存 */ public void clearUserPermissionCache(Long userId) { String pattern = PERMISSION_CACHE_PREFIX + userId + \u0026#34;:*\u0026#34;; Set\u0026lt;String\u0026gt; keys = redisTemplate.keys(pattern); if (!keys.isEmpty()) { redisTemplate.delete(keys); } } } 总结 通过实际项目的应用，我总结了以下经验：\n选择策略 纯RBAC适用场景：\n企业内部系统 用户角色相对固定 权限变更不频繁 纯ACL适用场景：\n文件系统 云存储服务 社交网络的内容分享 混合模型适用场景：\n大型企业级应用 需要临时授权 既有固定角色又有个性化需求 实施建议 从简单开始：先实现基础的RBAC，满足主要需求 按需扩展：在需要细粒度控制的地方引入ACL 性能考虑：使用缓存减少数据库查询 审计日志：记录所有权限变更操作 权限控制不仅是技术问题，更是业务问题。选择合适的模型，关键是要理解业务需求，平衡复杂性和灵活性。在我们的项目中，混合模型很好地解决了既要统一管理又要灵活授权的需求。\n","date":"2023-09-14T09:30:00+08:00","permalink":"https://tech-gt.github.io/p/rbac-acl-permission-control/","title":"RBAC 结合 ACL 实现灵活的权限控制系统"},{"content":" “最左匹配原则”是MySQL联合索引的经典说法，但它真的绝对吗？实际开发中有哪些容易被忽略的细节？本文结合实际案例，带你深入理解MySQL索引的最左匹配原则，并关注MySQL 8的新特性——Index Skip Scan。\n什么是最左匹配原则？ 假设有如下联合索引：\n1 index(A, B, C) 所谓“最左匹配原则”，指的是：查询条件必须从索引的最左前缀开始连续匹配，索引才能被有效利用。比如：\nwhere A=1 可以用到索引 where A=1 and B=2 可以用到索引 where A=1 and B=2 and C=3 可以用到索引 但 where B=2 and C=3 通常不能用到索引 常见误区：最左匹配不是“必须”！ 网上流行的说法是“必须最左”，但实际情况要复杂得多。来看下面的例子：\n误区一：跳过最左字段就一定不能用索引？ 假设有如下SQL：\n1 select * from student where B=\u0026#39;GT\u0026#39; and C=\u0026#39;男\u0026#39; 很多人会说：因为没有A，所以不满足最左匹配，不能用索引。但实际上，MySQL的优化器有时可以“跳跃”使用索引，尤其是在某些字段被等值查询且索引统计信息允许的情况下。\n例外情况：索引下推与条件重写 如果你的查询条件中，虽然没有A，但B和C的选择性很高，MySQL可能会选择用索引扫描（Index Condition Pushdown, ICP），但通常效率不如从最左字段开始。\n更常见的做法是重写SQL，让索引能被利用。例如：\n1 2 3 select * from student where (A=1 and B=\u0026#39;GT\u0026#39; and C=\u0026#39;男\u0026#39;) or (A=2 and B=\u0026#39;GT\u0026#39; and C=\u0026#39;男\u0026#39;) or (A=3 and B=\u0026#39;GT\u0026#39; and C=\u0026#39;男\u0026#39;) 这样，虽然没有直接写A=？，但通过“拆分”条件，依然可以让MySQL用到索引。\nMySQL 8 新特性：Index Skip Scan 打破最左匹配原则 MySQL 8.0 引入了 Index Skip Scan（索引跳跃扫描），它让“最左匹配原则”不再是绝对的。\nIndex Skip Scan 原理 当你有联合索引 index(A, B, C)，但查询条件没有包含最左的A字段时，MySQL 8 可以自动遍历A的所有可能值，对每个A值分别用B、C做索引查找，相当于自动帮你做了“条件拆分”。\n举例：\n1 select * from student where B=\u0026#39;GT\u0026#39; and C=\u0026#39;男\u0026#39; 在MySQL 8.0之前，这种写法通常不会用到索引。但开启 Index Skip Scan 后，MySQL 会自动遍历A的所有取值，分别查找B和C。\n适用场景 联合索引的最左字段基数（distinct值）较少时效果较好（如A只有1、2、3） 查询条件跳过了最左字段，但后续字段有高选择性 适合数据量不是特别大的表，或最左字段枚举值有限的场景 注意事项 Index Skip Scan 并不总是最优，尤其是最左字段基数很大时，遍历代价高，可能还不如全表扫描 是否启用可通过 optimizer_switch='index_skip_scan=on' 控制 实际是否用到，可以通过 EXPLAIN 查看执行计划，type 字段会显示 index_skip_scan EXPLAIN 示例 1 EXPLAIN SELECT * FROM student WHERE B=\u0026#39;GT\u0026#39; AND C=\u0026#39;男\u0026#39;; 输出示例：\nid select_type table type key key_len ref rows Extra 1 SIMPLE student index_skip_scan index_a_b_c \u0026hellip; NULL \u0026hellip; Using where 可以看到 type 字段为 index_skip_scan，说明 MySQL 自动使用了索引跳跃扫描。\n实际案例分析 假设有如下表结构：\n字段 含义 A 年级 B 学生名 C 性别 联合索引：index(A, B, C)\n查询1 1 select * from student where b=\u0026#39;GT\u0026#39; and c=\u0026#39;男\u0026#39; MySQL 8 之前：不满足最左匹配，不能用索引。\nMySQL 8 及以后：可能会用到 index_skip_scan。\n查询2 1 2 3 select * from student where (A=1 and b=\u0026#39;GT\u0026#39; and c=\u0026#39;男\u0026#39;) or (A=2 and b=\u0026#39;GT\u0026#39; and c=\u0026#39;男\u0026#39;) or (A=3 and b=\u0026#39;GT\u0026#39; and c=\u0026#39;男\u0026#39;) 优化后：通过枚举A的所有可能值，满足了最左匹配，索引可以被利用。\n总结与建议 最左匹配原则是MySQL索引的基础，但在MySQL 8以后已不是绝对规则。 Index Skip Scan 让跳过最左字段也有机会用到索引，但要关注最左字段基数和实际执行计划。 如果查询条件中跳过了最左字段，建议用 EXPLAIN 检查是否用到了 index_skip_scan。 实际开发中，优先让查询条件覆盖索引的最左字段，或通过IN/OR等方式补齐。 使用EXPLAIN分析SQL执行计划，判断索引是否被正确利用。 ","date":"2023-08-12T10:00:00+08:00","permalink":"https://tech-gt.github.io/p/mysql%E7%B4%A2%E5%BC%95%E4%B8%80%E5%AE%9A%E8%A6%81%E9%81%B5%E5%BE%AA%E6%9C%80%E5%B7%A6%E5%8C%B9%E9%85%8D%E5%8E%9F%E5%88%99%E5%90%97/","title":"MySQL索引一定要遵循最左匹配原则吗？"},{"content":"在日常写博客的过程中，流程图、时序图等可视化表达越来越重要。Mermaid 作为一款轻量级的图表语法工具，非常适合用来在 Markdown 里画图。但 Hugo Stack 主题默认并不支持 Mermaid 渲染，本文就来分享一下我是如何让它完美支持 Mermaid 的。\n问题分析 Hugo 的 Goldmark 渲染器默认不会把 mermaid 代码块当作图表处理，而 Stack 主题本身也没有内置 Mermaid 的支持。网上的教程五花八门，有的让你魔改主题，有的让你用第三方插件，但都不太优雅。\n解决思路 我的目标是：\n既能用代码块的方式写 Mermaid，也能用短代码（shortcode） 尽量不动主题源码，升级主题时不容易冲突 配置简单，易于维护 配置步骤 1. 配置 Goldmark 支持 Mermaid 代码块 编辑 config/_default/markup.toml，如下内容：\n1 2 3 [goldmark.extensions.passthrough.delimiters] block = [[\u0026#39;\\\\[\u0026#39;, \u0026#39;\\\\]\u0026#39;], [\u0026#39;$$\u0026#39;, \u0026#39;$$\u0026#39;], [\u0026#39;```mermaid\u0026#39;, \u0026#39;```\u0026#39;]] inline = [[\u0026#39;\\\\(\u0026#39;, \u0026#39;\\\\)\u0026#39;]] 这样 Hugo 就不会转义 mermaid 代码块内容。\n2. 新建 Mermaid 短代码 在 layouts/shortcodes/mermaid.html 新建如下内容：\n1 2 3 \u0026lt;div class=\u0026#34;mermaid\u0026#34;\u0026gt; {{- .Inner -}} \u0026lt;/div\u0026gt; 以后写博客时可以这样用：\n\u0026#123;\u0026#123;\u0026lt; mermaid \u0026gt;\u0026#125;\u0026#125; graph TD A[开始] --\u003e B{判断} B --\u003e|是| C[执行] B --\u003e|否| D[结束] C --\u003e D \u0026#123;\u0026#123;\u0026lt; /mermaid \u0026gt;\u0026#125;\u0026#125; 3. 全局引入 Mermaid 脚本 在 layouts/partials/head/custom.html 新建如下内容：\n1 2 3 4 5 6 7 8 9 10 11 12 \u0026lt;!-- Mermaid Diagram Support --\u0026gt; \u0026lt;script type=\u0026#34;module\u0026#34;\u0026gt; import mermaid from \u0026#39;https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs\u0026#39;; mermaid.initialize({ startOnLoad: true, theme: \u0026#39;default\u0026#39;, flowchart: { useMaxWidth: true, htmlLabels: true } }); \u0026lt;/script\u0026gt; 这样每个页面都会自动加载 Mermaid。\n踩过的坑 重复定义 Goldmark 配置：一开始我在 markup.toml 里多次写了 [goldmark.extensions.passthrough.delimiters]，导致 Hugo 报错。正确做法是合并到同一个表里。 主题覆盖问题：Stack 主题有自己的 head 模板，直接加在 head.html 里可能会被覆盖。用 custom.html 是最保险的。 浏览器缓存：有时候改完配置没生效，多刷新几次或者清空缓存就好了。 最终效果 现在无论是用代码块还是短代码，Mermaid 图表都能在博客里完美显示了！\n效果如下：\ngraph TD A[开始] --\u003e B{判断} B --\u003e|是| C[执行] B --\u003e|否| D[结束] C --\u003e D ","date":"2023-07-18T00:00:00Z","permalink":"https://tech-gt.github.io/p/%E8%AE%A9-hugo-stack-%E4%B8%BB%E9%A2%98%E5%AE%8C%E7%BE%8E%E6%94%AF%E6%8C%81-mermaid-%E6%B5%81%E7%A8%8B%E5%9B%BE/","title":"让 Hugo Stack 主题完美支持 Mermaid 流程图"},{"content":"在SaaS（软件即服务）应用的开发中，多租户是一个绕不开的核心概念。简单来说，就是一套系统要服务于多个不同的客户（租户），并且要保证他们之间的数据是严格隔离的。最常见的数据隔离方案就是在业务表中增加一个tenant_id字段。\n但问题随之而来：我们总不能在每个SQL查询后面都手动加上WHERE tenant_id = ?吧？这不仅工作量巨大，容易遗漏，而且对业务代码有很强的侵入性。\n今天，我们就来探讨如何利用Mybatis强大的插件（Interceptor）机制，开发一个通用的多租户插件，实现对业务代码的“无感”数据隔离。\nMybatis插件机制简介 Mybatis允许我们在SQL执行过程的特定时机点进行拦截和干预。它提供了四个可以拦截的核心对象：\nExecutor: SQL执行器，负责SQL的动态拼装和执行。 StatementHandler: 数据库会话处理器，负责处理JDBC语句。 ParameterHandler: 参数处理器，负责将用户参数映射到JDBC的PreparedStatement。 ResultSetHandler: 结果集处理器，负责将JDBC查询结果映射成Java对象。 对于多租户的场景，我们需要在SQL执行前对它进行改写，StatementHandler是最佳的拦截点。\n多租户插件实现步骤 我们的目标是自动为SQL语句（SELECT, UPDATE, DELETE, INSERT）添加tenant_id的条件。\n1. 引入JSqlParser 直接用字符串替换或拼接的方式改写SQL非常危险，容易出错。我们引入一个专业的SQL解析库——JSqlParser。\n1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.jsqlparser\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jsqlparser\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.6\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 2. 租户ID上下文 我们需要一个地方能暂存当前请求的tenant_id。ThreadLocal是处理这种场景的利器。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public class TenantContextHolder { private static final ThreadLocal\u0026lt;String\u0026gt; CONTEXT = new ThreadLocal\u0026lt;\u0026gt;(); public static void setTenantId(String tenantId) { CONTEXT.set(tenantId); } public static String getTenantId() { return CONTEXT.get(); } public static void clear() { CONTEXT.remove(); } } 通常，我们会通过一个Web Filter或Interceptor，在请求开始时从Session、Token或Header中获取租户ID并设置，在请求结束时清除。\n3. 核心拦截器TenantInterceptor 这是我们插件的核心，代码虽然有点长，但逻辑很清晰。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 @Intercepts({@Signature( type = StatementHandler.class, method = \u0026#34;prepare\u0026#34;, args = {Connection.class, Integer.class} )}) public class TenantInterceptor implements Interceptor { private final List\u0026lt;String\u0026gt; ignoreTables = Arrays.asList(\u0026#34;sys_config\u0026#34;, \u0026#34;tenant_info\u0026#34;); @Override public Object intercept(Invocation invocation) throws Throwable { StatementHandler statementHandler = (StatementHandler) invocation.getTarget(); BoundSql boundSql = statementHandler.getBoundSql(); String originalSql = boundSql.getSql(); String tenantId = TenantContextHolder.getTenantId(); // 如果没有获取到租户ID，则不处理 if (tenantId == null || tenantId.trim().isEmpty()) { return invocation.proceed(); } try { // 使用JSqlParser解析SQL Statement statement = CCJSqlParserUtil.parse(originalSql); if (statement instanceof Select) { processSelect((Select) statement, tenantId); } else if (statement instanceof Update) { processUpdate((Update) statement, tenantId); } else if (statement instanceof Delete) { processDelete((Delete) statement, tenantId); } else if (statement instanceof Insert) { processInsert((Insert) statement, tenantId); } // 将改写后的SQL重新设置回去 MetaObject metaObject = SystemMetaObject.forObject(statementHandler); metaObject.setValue(\u0026#34;delegate.boundSql.sql\u0026#34;, statement.toString()); } catch (Exception e) { // 解析失败或处理异常，可以选择直接放行或抛出异常 // 这里选择放行，避免影响正常业务 } return invocation.proceed(); } // 省略 processSelect, processUpdate, processDelete, processInsert 的具体实现 // 核心思想是获取到WHERE条件，并用AND拼接 tenant_id = \u0026#39;xxx\u0026#39; // 对于INSERT，则是在列中增加 tenant_id，在VALUES中增加对应的租户ID } 处理SELECT的示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 private void processSelect(Select select, String tenantId) { SelectBody selectBody = select.getSelectBody(); if (selectBody instanceof PlainSelect) { PlainSelect plainSelect = (PlainSelect) selectBody; // 忽略特定表 if (ignoreTables.contains(plainSelect.getFromItem().toString().toLowerCase())) { return; } addWhereCondition(plainSelect, tenantId); } } private void addWhereCondition(PlainSelect plainSelect, String tenantId) { Expression where = plainSelect.getWhere(); String tenantFilter = \u0026#34;tenant_id = \u0026#39;\u0026#34; + tenantId + \u0026#34;\u0026#39;\u0026#34;; if (where == null) { try { plainSelect.setWhere(CCJSqlParserUtil.parseCondExpression(tenantFilter)); } catch (JSQLParserException e) { // handle exception } } else { AndExpression and = new AndExpression(where, new StringValue(tenantFilter)); plainSelect.setWhere(and); } } 4. 注册插件 最后一步，在Mybatis的配置中注册我们的拦截器。\n1 2 3 4 5 6 7 8 9 10 11 12 @Configuration public class MybatisPlusConfig { @Bean public MybatisPlusInterceptor mybatisPlusInterceptor() { MybatisPlusInterceptor interceptor = new MybatisPlusInterceptor(); // 添加我们自定义的租户拦截器 interceptor.addInnerInterceptor(new TenantInterceptor()); // 还可以添加分页插件等 interceptor.addInnerInterceptor(new PaginationInnerInterceptor(DbType.MYSQL)); return interceptor; } } 注意：Mybatis-Plus的TenantLineInnerInterceptor提供了更完善的官方实现，这里是为了演示插件开发原理。若使用Mybatis-Plus，建议优先使用官方方案。\n总结 通过自定义Mybatis插件，我们成功地将多租户的数据隔离逻辑从业务代码中剥离出来，实现了对开发人员透明的无感切换。这种方式不仅优雅，而且易于维护和扩展。\n当然，这种方案也有一些需要注意的地方：\nSQL解析开销：JSqlParser会带来微小的性能开销，但通常可以忽略不计。 复杂SQL兼容性：对于极其复杂的SQL（如多层嵌套、JOIN等），需要充分测试以保证解析的正确性。 忽略表配置：需要维护一个不需要加租户ID的白名单表。 ","date":"2023-05-20T11:00:00+08:00","permalink":"https://tech-gt.github.io/p/%E6%89%8B%E6%8A%8A%E6%89%8B%E6%95%99%E4%BD%A0%E5%86%99%E4%B8%80%E4%B8%AAmybatis%E6%8F%92%E4%BB%B6%E5%AE%9E%E7%8E%B0%E5%A4%9A%E7%A7%9F%E6%88%B7%E6%97%A0%E6%84%9F%E5%88%87%E6%8D%A2/","title":"手把手教你写一个Mybatis插件，实现多租户无感切换"},{"content":"在高并发网络编程领域，Netty无疑是Java生态中的王者。但很多开发者在使用Netty时，往往只知其然而不知其所以然。今天我们就来深入剖析Netty的线程模型，看看它是如何用极少的线程处理海量并发连接的。\n核心概念 一句话概括：Netty 的线程模型是基于主从 Reactor 模式的、高度优化的事件驱动模型。它用极少数的线程，通过非阻塞 I/O 和事件循环，来高效地处理海量的并发连接。\n为了让你更好地理解，我们把它拆分成几个核心概念，并用一个生动的比喻来贯穿解释。\n比喻：一个高效的餐厅 想象一下 Netty 就是一个运营极为高效的餐厅：\nBossGroup (老板/迎宾)：餐厅门口有1个（或几个）迎宾员。他们非常专一，只做一件事：迎接客人（接受新的连接），然后把客人引导给服务员。他们从不点餐或上菜。 WorkerGroup (服务员)：餐厅里有一组服务员。一旦迎宾员把客人带到座位上，这位客人就由一位固定的服务员全程负责。这位服务员会处理这位客人的一切需求：点餐、上菜、倒水、结账（处理读写事件和业务逻辑）。 EventLoop (服务员本身)：每个服务员就是一个 EventLoop，他本质上是一个永不停止的循环。他手里有一个任务清单（Task Queue），不停地检查他负责的所有餐桌（Channels）有没有新的需求（I/O 事件），或者有没有人直接给他派发了任务。 Channel (餐桌)：每一张餐桌就是一个 Channel，代表一个客户端连接。关键点在于：一张餐桌（Channel）从始至终只由一位服务员（EventLoop）负责。 Pipeline (服务流程)：客人（数据）来了之后，服务员（EventLoop）会按照一套标准流程来服务，比如先上开胃菜，再上主菜，最后上甜点。这个流程就是 Pipeline，流程中的每个步骤就是一个 Handler。 Netty 线程模型的核心组件 现在我们把比喻和技术概念对应起来：\n1. EventLoopGroup 和 EventLoop：线程的管理者和执行者 EventLoopGroup：这是一个线程池。在 Netty 服务器中，我们通常会创建两个 EventLoopGroup： BossGroup：如比喻中的“迎宾”，专门负责接收客户端的连接请求。当一个新连接进来时，BossGroup 中的一个 EventLoop (线程) 会处理这个连接请求，创建一个代表该连接的 Channel，然后把它“注册”给 WorkerGroup 中的一个 EventLoop。BossGroup 通常只需要配置1个线程就足够了，因为它做的事情非常简单、快速。 WorkerGroup：如比喻中的“服务员团队”，负责处理所有已建立连接的后续 I/O 操作，比如数据的读取、写入以及执行业务逻辑。WorkerGroup 的线程数通常会设置为 CPU 核心数的 2 倍，这是 Netty 官方推荐的一个经验值。 EventLoop：这是 Netty 线程模型的核心。它本质上是一个单线程的执行器，内部维护着一个事件选择器（Selector）和一个任务队列（Task Queue）。 它在一个无限循环中不断地轮询注册在它上面的所有 Channel 的 I/O 事件（例如数据可读、可写等）。 一旦事件发生，它就负责处理这些事件，调用 ChannelPipeline 中的 Handler。 同时，它也会检查任务队列中是否有待执行的任务，并依次执行。 2. Channel 与 EventLoop 的绑定关系 (线程绑定) 这是 Netty 高效和线程安全的关键。一旦一个 Channel 被创建并注册到一个 EventLoop 上，那么该 Channel 的所有 I/O 操作和事件处理都将由这同一个 EventLoop 线程来完成。\n这种设计被称为线程封闭（Thread Confinement）。\n这样做的好处是什么？\n无锁化设计：因为一个 Channel 的所有操作都在同一个线程中执行，所以你不需要在 ChannelHandler 中对状态进行复杂的同步处理（比如加锁），大大简化了并发编程的难度，并提升了性能。 可预测的执行顺序：所有事件都由同一个线程按顺序处理，避免了多线程并发执行带来的不确定性。 工作流程图解 下面是一个典型的 Netty 服务器工作流程：\nsequenceDiagram participant Client as 客户端 participant Boss as BossGroup participant Worker as WorkerGroup participant Pipeline as ChannelPipeline Note over Boss,Worker: 服务器启动，创建线程组 Client-\u003e\u003eBoss: 1. 发起连接请求 Boss-\u003e\u003eBoss: 2. 监听ACCEPT事件 Boss-\u003e\u003eWorker: 3. 创建SocketChannel并注册到WorkerGroup loop 数据处理循环 Client-\u003e\u003eWorker: 4. 发送数据 Worker-\u003e\u003ePipeline: 5. 触发READ事件 Pipeline-\u003e\u003ePipeline: 6. 数据流经Handler链 Pipeline-\u003e\u003eWorker: 7. 处理完成 Worker-\u003e\u003eClient: 8. 返回响应 end Note over Worker: 同一个Channel的所有操作都由同一个EventLoop处理 详细步骤说明：\n启动与绑定：服务器启动时，创建 BossGroup 和 WorkerGroup。ServerBootstrap 将 BossGroup 绑定到某个端口上。 连接接入：一个客户端发起连接请求。 BossGroup 处理：BossGroup 中的一个 EventLoop 线程通过 Selector 监听到这个 ACCEPT 事件。 创建与注册：BossGroup 的 EventLoop 接受连接，创建一个新的 SocketChannel（代表与客户端的连接），然后从 WorkerGroup 中选择一个 EventLoop，并将这个 SocketChannel 注册到该 EventLoop 上。 WorkerGroup 工作：从此以后，这个 SocketChannel 的所有 READ、WRITE 事件都由这个被选中的 WorkerGroup 的 EventLoop 来全权负责处理。数据会通过该 Channel 的 Pipeline 进行流动和处理。 核心原则：绝不阻塞 I/O 线程！ 这是使用 Netty 时必须遵守的黄金法则。\nEventLoop 线程（WorkerGroup 中的线程）是非常宝贵的资源，它们需要快速地处理成千上万个连接的 I/O 事件。如果你在 ChannelHandler 中执行了任何耗时的操作，比如：\n长时间的计算 调用阻塞的数据库 API 进行阻塞的网络调用（如请求另一个服务） 那么，这个 EventLoop 线程就会被卡住，无法去处理它负责的其他几千个 Channel 的 I/O 事件，从而导致整个系统的响应延迟，甚至瘫痪。\n如何处理耗时任务？ 如果你的业务逻辑中确实有耗时操作，正确的做法是将这些任务从 I/O 线程中剥离出去，交给一个专门的业务线程池来处理。\nNetty 提供了 DefaultEventExecutorGroup，你可以用它来创建一个业务线程池。\n代码示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 public class NettyServer { public void start(int port) throws Exception { // 1. 创建线程组 EventLoopGroup bossGroup = new NioEventLoopGroup(1); // 通常1个线程足够 EventLoopGroup workerGroup = new NioEventLoopGroup(); // 默认CPU核心数*2 // 2. 创建独立的业务线程池，用于处理耗时任务 final EventExecutorGroup businessGroup = new DefaultEventExecutorGroup(16); try { ServerBootstrap bootstrap = new ServerBootstrap(); bootstrap.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 128) .childOption(ChannelOption.SO_KEEPALIVE, true) .childHandler(new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() { @Override public void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); // 3. 添加编解码器（在I/O线程中执行，必须快速） pipeline.addLast(\u0026#34;decoder\u0026#34;, new StringDecoder()); pipeline.addLast(\u0026#34;encoder\u0026#34;, new StringEncoder()); // 4. 添加业务Handler到独立线程池（避免阻塞I/O线程） pipeline.addLast(businessGroup, \u0026#34;business\u0026#34;, new BusinessHandler()); } }); // 5. 绑定端口并启动服务器 ChannelFuture future = bootstrap.bind(port).sync(); System.out.println(\u0026#34;Netty服务器启动成功，端口：\u0026#34; + port); // 6. 等待服务器关闭 future.channel().closeFuture().sync(); } finally { // 7. 优雅关闭所有线程组 bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); businessGroup.shutdownGracefully(); } } // 业务处理Handler private static class BusinessHandler extends ChannelInboundHandlerAdapter { @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { // 这里可以安全地执行耗时操作，因为运行在独立的业务线程池中 String request = (String) msg; // 模拟耗时的业务处理 Thread.sleep(100); // 这在I/O线程中是绝对禁止的！ String response = \u0026#34;处理完成: \u0026#34; + request; ctx.writeAndFlush(response); } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) { cause.printStackTrace(); ctx.close(); } } public static void main(String[] args) throws Exception { new NettyServer().start(8080); } } 实际应用场景 1. 高并发Web服务器 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 // 使用Netty构建HTTP服务器 public class NettyHttpServer { public void start(int port) throws Exception { EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workerGroup = new NioEventLoopGroup(); try { ServerBootstrap bootstrap = new ServerBootstrap(); bootstrap.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .childHandler(new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() { @Override protected void initChannel(SocketChannel ch) { ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(new HttpServerCodec()); pipeline.addLast(new HttpObjectAggregator(65536)); pipeline.addLast(new HttpServerHandler()); } }); ChannelFuture future = bootstrap.bind(port).sync(); future.channel().closeFuture().sync(); } finally { bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } } 2. 实时消息推送系统 在实时聊天、游戏服务器等场景中，Netty的线程模型能够：\n维持大量长连接（百万级） 低延迟消息传递（毫秒级） 高吞吐量数据处理 3. 微服务间通信 许多RPC框架（如Dubbo、gRPC的Java实现）都基于Netty构建，利用其高效的线程模型实现服务间的高性能通信。\n最佳实践建议 1. 线程池配置 1 2 3 4 5 6 7 8 // 推荐的线程池配置 EventLoopGroup bossGroup = new NioEventLoopGroup(1); // Boss通常1个线程足够 EventLoopGroup workerGroup = new NioEventLoopGroup(Runtime.getRuntime().availableProcessors() * 2); // 业务线程池大小根据业务特性调整 EventExecutorGroup businessGroup = new DefaultEventExecutorGroup( Math.max(16, Runtime.getRuntime().availableProcessors() * 4) ); 2. Handler设计原则 编解码Handler：放在I/O线程中，必须快速执行 业务逻辑Handler：放在独立线程池中，可以执行耗时操作 异常处理：每个Handler都要正确处理异常，避免影响整个Pipeline 总结 主从 Reactor 模式：BossGroup (主 Reactor) 负责连接，WorkerGroup (从 Reactors) 负责 I/O 和业务。 事件驱动：基于 Selector 的事件通知机制，线程只在有事件发生时才工作。 线程绑定：一个 Channel 终生绑定一个 EventLoop 线程，实现了无锁化和高效率。 黄金法则：永远不要阻塞 I/O 线程，耗时任务请交给独立的业务线程池。 ","date":"2022-11-08T16:45:00+08:00","permalink":"https://tech-gt.github.io/p/%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3netty%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B%E4%B8%80%E4%B8%AA%E9%AB%98%E6%95%88%E7%9A%84%E9%A4%90%E5%8E%85/","title":"如何理解Netty线程模型：一个高效的餐厅"},{"content":"问题背景 我们有一个仓库管理系统，其中有个出库的业务场景。数据库中存储着一条条的库存明细记录，当商品出库后，需要批量更新这些记录的状态为\u0026quot;已出库\u0026quot;。\n数据表结构 1 2 3 4 5 6 7 8 9 10 11 12 13 14 CREATE TABLE `inventory_detail` ( `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT \u0026#39;主键ID\u0026#39;, `product_id` varchar(50) NOT NULL COMMENT \u0026#39;商品ID\u0026#39;, `warehouse_id` varchar(50) NOT NULL COMMENT \u0026#39;仓库ID\u0026#39;, `quantity` int(11) NOT NULL COMMENT \u0026#39;数量\u0026#39;, `status` tinyint(4) NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;状态：0-在库，1-已出库\u0026#39;, `batch_no` varchar(50) DEFAULT NULL COMMENT \u0026#39;批次号\u0026#39;, `create_time` datetime NOT NULL COMMENT \u0026#39;创建时间\u0026#39;, `update_time` datetime NOT NULL COMMENT \u0026#39;更新时间\u0026#39;, PRIMARY KEY (`id`), KEY `idx_product_warehouse` (`product_id`, `warehouse_id`), KEY `idx_status` (`status`), KEY `idx_create_time` (`create_time`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 原始的慢查询 最初的实现是这样的：\n1 2 3 4 5 6 7 8 9 10 11 -- 1. 先查询出需要出库的记录ID SELECT id FROM inventory_detail WHERE product_id = \u0026#39;PROD001\u0026#39; AND warehouse_id = \u0026#39;WH001\u0026#39; AND status = 0 LIMIT 10000; -- 2. 批量更新状态 UPDATE inventory_detail SET status = 1, update_time = NOW() WHERE id IN (1001, 1002, 1003, ..., 11000); 当需要批量出库1万条记录时，这个UPDATE语句竟然耗时8秒！\n执行计划分析 遇到慢查询，第一步就是用EXPLAIN来分析执行计划：\n1 2 3 EXPLAIN UPDATE inventory_detail SET status = 1, update_time = NOW() WHERE id IN (1001, 1002, 1003, ..., 11000); 执行结果：\n1 2 3 4 5 +----+-------------+------------------+-------+---------------+---------+---------+------+------+-------------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +----+-------------+------------------+-------+---------------+---------+---------+------+------+-------------+ | 1 | UPDATE | inventory_detail | range | PRIMARY | PRIMARY | 8 | NULL | 5000 | Using where | +----+-------------+------------------+-------+---------------+---------+---------+------+------+-------------+ 理解执行计划的type字段 这里的关键是type字段，它表示MySQL访问表的方式。性能从好到差的顺序是：\nsystem - 表只有一行记录（系统表），这是const类型的特例 const - 通过索引一次就找到了，用于比较primary key或unique索引 eq_ref - 唯一性索引扫描，对于每个索引键，表中只有一条记录与之匹配 ref - 非唯一性索引扫描，返回匹配某个单独值的所有行 range - 只检索给定范围的行，使用一个索引来选择行 index - 全索引扫描，只遍历索引树 ALL - 全表扫描，性能最差 我们的查询type是range，虽然不是最差的，但在处理1万条IN查询时，性能还是不够理想。 EXPLAIN 结果中的 type 字段显示为 range。range 意味着MySQL正在使用索引进行范围扫描。虽然 range 级别不算差，但为什么在这里会这么慢？ IN 操作的本质：当 IN 列表包含大量值时，MySQL会将其视为一系列的等值查找。对于我们的10000个ID，数据库需要进行10000次独立的索引定位（Index Seek）。 这就像让一位图书管理员去书库里找10000本编码完全不连续的书，虽然他每次找书都很快（走了索引），但这来来回回的奔波和查找次数累加起来，总耗时就变得非常可观。\n优化思路 分析了执行计划后，我开始思考优化方案。既然IN查询的性能不够好，能不能换个思路？\n观察数据特点，我发现：\n表使用自增主键ID 出库时通常是按时间顺序，也就是ID较小的记录先出库 1万条记录的ID基本是连续的 基于这个特点，我想到了一个优化方案：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 -- 1. 查询出需要出库的最大ID SELECT MAX(id) as max_id FROM ( SELECT id FROM inventory_detail WHERE product_id = \u0026#39;PROD001\u0026#39; AND warehouse_id = \u0026#39;WH001\u0026#39; AND status = 0 ORDER BY id LIMIT 10000 ) t; -- 2. 直接更新ID小于等于max_id的记录 UPDATE inventory_detail SET status = 1, update_time = NOW() WHERE product_id = \u0026#39;PROD001\u0026#39; AND warehouse_id = \u0026#39;WH001\u0026#39; AND status = 0 AND id \u0026lt;= @max_id LIMIT 10000; 优化后的执行计划 让我们看看优化后的执行计划：\n1 2 3 4 5 6 7 EXPLAIN UPDATE inventory_detail SET status = 1, update_time = NOW() WHERE product_id = \u0026#39;PROD001\u0026#39; AND warehouse_id = \u0026#39;WH001\u0026#39; AND status = 0 AND id \u0026lt;= 11000 LIMIT 10000; 执行结果：\n1 2 3 4 5 +----+-------------+------------------+-------------+---------------------------+---------------------------+---------+------+------+------------------------------------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +----+-------------+------------------+-------------+---------------------------+---------------------------+---------+------+------+------------------------------------+ | 1 | UPDATE | inventory_detail | index_merge | PRIMARY,idx_product_warehouse,idx_status | idx_product_warehouse,idx_status | 206,1 | NULL | 3200 | Using intersect(idx_product_warehouse,idx_status); Using where | +----+-------------+------------------+-------------+---------------------------+---------------------------+---------+------+------+------------------------------------+ 可以看到，type变成了index_merge，这意味着MySQL使用了索引合并优化，同时使用了idx_product_warehouse和idx_status两个索引，然后取交集。\n代码实现 在Java代码中，优化后的实现是这样的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 @Service public class InventoryService { @Autowired private InventoryDetailMapper inventoryDetailMapper; /** * 批量出库优化版本 */ @Transactional public int batchOutbound(String productId, String warehouseId, int quantity) { // 1. 查询需要出库的最大ID Long maxId = inventoryDetailMapper.findMaxIdForOutbound(productId, warehouseId, quantity); if (maxId == null) { return 0; } // 2. 批量更新状态 return inventoryDetailMapper.batchUpdateStatusOptimized(productId, warehouseId, maxId, quantity); } } Mapper接口：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 @Mapper public interface InventoryDetailMapper { @Select(\u0026#34;SELECT MAX(id) FROM (\u0026#34; + \u0026#34;SELECT id FROM inventory_detail \u0026#34; + \u0026#34;WHERE product_id = #{productId} \u0026#34; + \u0026#34;AND warehouse_id = #{warehouseId} \u0026#34; + \u0026#34;AND status = 0 \u0026#34; + \u0026#34;ORDER BY id LIMIT #{quantity}\u0026#34; + \u0026#34;) t\u0026#34;) Long findMaxIdForOutbound(@Param(\u0026#34;productId\u0026#34;) String productId, @Param(\u0026#34;warehouseId\u0026#34;) String warehouseId, @Param(\u0026#34;quantity\u0026#34;) int quantity); @Update(\u0026#34;UPDATE inventory_detail \u0026#34; + \u0026#34;SET status = 1, update_time = NOW() \u0026#34; + \u0026#34;WHERE product_id = #{productId} \u0026#34; + \u0026#34;AND warehouse_id = #{warehouseId} \u0026#34; + \u0026#34;AND status = 0 \u0026#34; + \u0026#34;AND id \u0026lt;= #{maxId} \u0026#34; + \u0026#34;LIMIT #{quantity}\u0026#34;) int batchUpdateStatusOptimized(@Param(\u0026#34;productId\u0026#34;) String productId, @Param(\u0026#34;warehouseId\u0026#34;) String warehouseId, @Param(\u0026#34;maxId\u0026#34;) Long maxId, @Param(\u0026#34;quantity\u0026#34;) int quantity); } 性能对比 优化前后的性能对比：\n方案 执行时间 type类型 使用索引 性能提升 原始IN查询 8秒 range PRIMARY - 优化后范围查询 3.2秒 index_merge idx_product_warehouse + idx_status 60% 优化原理分析 为什么优化后性能提升这么明显？主要原因有几个：\n1. 索引使用更高效 原始方案使用IN查询，MySQL需要对每个ID值进行查找，虽然走的是主键索引，但1万个值的查找开销还是很大。\n优化后使用范围查询配合复合条件，MySQL可以同时利用多个索引进行index_merge优化。\n2. 减少了回表操作 1 2 3 4 5 6 -- 原始方案需要先查询ID，再用IN更新 SELECT id FROM inventory_detail WHERE ...; -- 第一次查询 UPDATE inventory_detail WHERE id IN (...); -- 第二次查询 -- 优化方案只需要一次更新操作 UPDATE inventory_detail WHERE ... AND id \u0026lt;= max_id; 3. 利用了数据的局部性 由于ID是自增的，需要出库的记录ID基本连续，范围查询比IN查询更适合这种场景。\n进一步优化思考 虽然性能已经提升了60%，但还可以考虑进一步优化：\n1. 分批处理 对于超大批量的更新，可以分批进行：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 public int batchOutboundInChunks(String productId, String warehouseId, int totalQuantity) { int chunkSize = 5000; // 每批5000条 int totalUpdated = 0; while (totalUpdated \u0026lt; totalQuantity) { int currentChunk = Math.min(chunkSize, totalQuantity - totalUpdated); int updated = batchOutbound(productId, warehouseId, currentChunk); if (updated == 0) { break; // 没有更多记录可更新 } totalUpdated += updated; } return totalUpdated; } 2. 异步处理 对于非实时要求的场景，可以考虑异步处理：\n1 2 3 4 5 @Async public CompletableFuture\u0026lt;Integer\u0026gt; asyncBatchOutbound(String productId, String warehouseId, int quantity) { int result = batchOutbound(productId, warehouseId, quantity); return CompletableFuture.completedFuture(result); } 总结 这次慢查询优化的关键点：\n善用EXPLAIN：执行计划是定位性能问题的第一步 理解type类型：不同的访问类型性能差异巨大 结合业务特点：利用数据的自然特性进行优化 索引合并：MySQL的index_merge可以同时利用多个索引 减少查询次数：能一次完成的操作不要分两次 ","date":"2022-09-18T15:20:00+08:00","permalink":"https://tech-gt.github.io/p/%E4%BB%8E8%E7%A7%92%E5%88%B03%E7%A7%92%E4%B8%80%E6%AC%A1sql%E6%89%B9%E9%87%8F%E6%9B%B4%E6%96%B0%E7%9A%84%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/","title":"从8秒到3秒：一次SQL批量更新的性能优化"},{"content":"前言 多个用户同时购买同一件商品，需要扣减库存。传统的关系型数据库可以用事务来保证数据一致性，那Redis支持事务吗？ 今天就来聊聊Redis的事务到底是什么样的，它和我们熟悉的MySQL事务有什么区别，以及在实际项目中该如何使用。\nRedis事务的基本概念 简单回答：Redis是支持事务的，但它的事务机制与传统关系型数据库有很大不同。\nRedis事务是通过四个命令来实现的：\nMULTI：开启事务 EXEC：执行事务 DISCARD：取消事务 WATCH：监视键值变化 让我们先看一个最基本的例子：\n1 2 3 4 5 6 7 8 9 10 11 12 127.0.0.1:6379\u0026gt; MULTI OK 127.0.0.1:6379\u0026gt; SET key1 \u0026#34;value1\u0026#34; QUEUED 127.0.0.1:6379\u0026gt; SET key2 \u0026#34;value2\u0026#34; QUEUED 127.0.0.1:6379\u0026gt; INCR counter QUEUED 127.0.0.1:6379\u0026gt; EXEC 1) OK 2) OK 3) (integer) 1 可以看到，在MULTI和EXEC之间的命令都被放入了队列中，等待EXEC时一次性执行。\nRedis事务的特点 1. 原子性（有限制的） Redis事务具有一定的原子性，但和传统数据库不同：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 // Java代码示例 @Service public class RedisTransactionService { @Autowired private RedisTemplate\u0026lt;String, String\u0026gt; redisTemplate; public void transferPoints(String fromUser, String toUser, int points) { // 开启事务 redisTemplate.multi(); try { // 扣减from用户积分 redisTemplate.opsForValue().decrement(\u0026#34;user:\u0026#34; + fromUser + \u0026#34;:points\u0026#34;, points); // 增加to用户积分 redisTemplate.opsForValue().increment(\u0026#34;user:\u0026#34; + toUser + \u0026#34;:points\u0026#34;, points); // 执行事务 redisTemplate.exec(); } catch (Exception e) { // 回滚事务 redisTemplate.discard(); throw new RuntimeException(\u0026#34;积分转移失败\u0026#34;, e); } } } 重要特点：Redis事务中，如果某个命令执行失败，其他命令依然会执行，不会回滚！这和MySQL的事务机制完全不同。\n2. 一致性 Redis保证事务执行前后数据的一致性，但仅限于语法正确的命令。\n3. 隔离性 Redis是单线程执行命令的，所以事务天然具有隔离性。\n4. 持久性 取决于Redis的持久化策略（RDB/AOF）。\nWATCH命令：实现乐观锁 这是Redis事务最有用的特性之一。WATCH可以监视一个或多个键，如果在事务执行前这些键被修改，事务就会失败。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 // 实现库存扣减的乐观锁 @Service public class InventoryService { @Autowired private RedisTemplate\u0026lt;String, String\u0026gt; redisTemplate; public boolean decreaseStock(String productId, int quantity) { String stockKey = \u0026#34;product:\u0026#34; + productId + \u0026#34;:stock\u0026#34;; for (int i = 0; i \u0026lt; 3; i++) { // 重试3次 // 监视库存键 redisTemplate.watch(stockKey); // 获取当前库存 String currentStockStr = redisTemplate.opsForValue().get(stockKey); if (currentStockStr == null) { redisTemplate.unwatch(); return false; } int currentStock = Integer.parseInt(currentStockStr); if (currentStock \u0026lt; quantity) { redisTemplate.unwatch(); return false; // 库存不足 } // 开启事务 redisTemplate.multi(); // 扣减库存 redisTemplate.opsForValue().set(stockKey, String.valueOf(currentStock - quantity)); // 执行事务 List\u0026lt;Object\u0026gt; results = redisTemplate.exec(); if (results != null \u0026amp;\u0026amp; !results.isEmpty()) { return true; // 成功 } // 如果results为null，说明被其他客户端修改了，重试 } return false; // 重试失败 } } 实际应用场景 场景1：秒杀系统 在秒杀系统中，我们需要原子性地完成以下操作：\n检查商品库存 扣减库存 创建订单记录 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 @Service public class SeckillService { public boolean seckill(String userId, String productId) { String stockKey = \u0026#34;seckill:\u0026#34; + productId + \u0026#34;:stock\u0026#34;; String orderKey = \u0026#34;seckill:\u0026#34; + productId + \u0026#34;:orders\u0026#34;; // 使用Lua脚本确保原子性 String luaScript = \u0026#34;local stock = redis.call(\u0026#39;get\u0026#39;, KEYS[1]) \u0026#34; + \u0026#34;if not stock or tonumber(stock) \u0026lt;= 0 then \u0026#34; + \u0026#34; return 0 \u0026#34; + \u0026#34;end \u0026#34; + \u0026#34;redis.call(\u0026#39;decr\u0026#39;, KEYS[1]) \u0026#34; + \u0026#34;redis.call(\u0026#39;sadd\u0026#39;, KEYS[2], ARGV[1]) \u0026#34; + \u0026#34;return 1\u0026#34;; Long result = redisTemplate.execute( RedisScript.of(luaScript, Long.class), Arrays.asList(stockKey, orderKey), userId ); return result != null \u0026amp;\u0026amp; result == 1; } } 场景2：分布式计数器 1 2 3 4 5 6 7 8 9 10 11 12 // 实现网站访问量统计 public void recordPageView(String page) { String dailyKey = \u0026#34;pv:daily:\u0026#34; + LocalDate.now(); String hourlyKey = \u0026#34;pv:hourly:\u0026#34; + LocalDateTime.now().getHour(); String pageKey = \u0026#34;pv:page:\u0026#34; + page; redisTemplate.multi(); redisTemplate.opsForValue().increment(dailyKey); redisTemplate.opsForValue().increment(hourlyKey); redisTemplate.opsForValue().increment(pageKey); redisTemplate.exec(); } Redis事务的执行流程 sequenceDiagram participant Client participant Redis Client-\u003e\u003eRedis: WATCH key1 key2 Redis--\u003e\u003eClient: OK Client-\u003e\u003eRedis: MULTI Redis--\u003e\u003eClient: OK Client-\u003e\u003eRedis: SET key1 value1 Redis--\u003e\u003eClient: QUEUED Client-\u003e\u003eRedis: INCR key2 Redis--\u003e\u003eClient: QUEUED Client-\u003e\u003eRedis: EXEC alt 被WATCH的键未被修改 Redis--\u003e\u003eClient: 1) OK 2) (integer) 1 else 被WATCH的键已被修改 Redis--\u003e\u003eClient: (nil) end 注意事项和最佳实践 1. 避免长事务 Redis事务会阻塞其他操作，应该尽量保持事务简短：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // 不好的做法 redisTemplate.multi(); for (int i = 0; i \u0026lt; 1000; i++) { redisTemplate.opsForValue().set(\u0026#34;key\u0026#34; + i, \u0026#34;value\u0026#34; + i); } redisTemplate.exec(); // 好的做法：使用Pipeline redisTemplate.executePipelined(new RedisCallback\u0026lt;Object\u0026gt;() { @Override public Object doInRedis(RedisConnection connection) { for (int i = 0; i \u0026lt; 1000; i++) { connection.set((\u0026#34;key\u0026#34; + i).getBytes(), (\u0026#34;value\u0026#34; + i).getBytes()); } return null; } }); 2. 使用Lua脚本替代复杂事务 对于复杂的原子操作，建议使用Lua脚本：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 -- 限流脚本示例 local key = KEYS[1] local limit = tonumber(ARGV[1]) local window = tonumber(ARGV[2]) local current = redis.call(\u0026#39;incr\u0026#39;, key) if current == 1 then redis.call(\u0026#39;expire\u0026#39;, key, window) end if current \u0026gt; limit then return 0 else return 1 end 3. 合理使用WATCH WATCH适合读多写少的场景，如果冲突频繁，性能会下降：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 // 优化冲突处理 public boolean updateWithOptimisticLock(String key, Function\u0026lt;String, String\u0026gt; updater) { int maxRetries = 10; for (int i = 0; i \u0026lt; maxRetries; i++) { redisTemplate.watch(key); String oldValue = redisTemplate.opsForValue().get(key); String newValue = updater.apply(oldValue); redisTemplate.multi(); redisTemplate.opsForValue().set(key, newValue); if (redisTemplate.exec() != null) { return true; } // 指数退避 try { Thread.sleep((long) Math.pow(2, i) * 10); } catch (InterruptedException e) { Thread.currentThread().interrupt(); return false; } } return false; } 总结 Redis确实支持事务，但它的事务机制与传统数据库有很大不同：\n有限的原子性：命令要么全部进入队列，要么执行时全部执行，但不保证全部成功 无回滚机制：失败的命令不会影响其他命令的执行 适合特定场景：更适合简单的原子操作，复杂逻辑建议用Lua脚本 在实际项目中，我更倾向于将Redis事务用于：\n简单的原子操作（如计数器更新） 配合WATCH实现乐观锁 批量操作的一致性保证 对于复杂的业务逻辑，还是建议使用关系型数据库的事务，或者通过Lua脚本在Redis层面实现。\n记住一点：选择合适的工具做合适的事情，Redis事务有其适用场景，理解其特点并合理使用，才能发挥最大价值。\n","date":"2022-08-15T10:30:00+08:00","permalink":"https://tech-gt.github.io/p/redis-transaction-mechanism/","title":"Redis事务机制：MULTI、EXEC与乐观锁的实际应用"},{"content":"你的Java代码是如何被执行的？ 在日常开发中，我们经常会遇到各种JVM相关的问题，比如内存溢出、类加载异常、性能瓶颈等。很多同学可能对JVM的印象还停留在“Java虚拟机能让Java代码跨平台运行”，但实际上，JVM的内部机制远比我们想象的要复杂和有趣。今天就带大家从一个Class文件的视角，聊聊JVM是如何一步步把你的Java代码变成可以运行的程序的。\n一、Class文件是什么？ 我们写的Java代码，最终会被编译成以.class结尾的字节码文件。Class文件其实就是一堆二进制数据，里面包含了类的结构、方法、字段、常量池等信息。它是JVM能够识别和执行的“说明书”。\nClass文件结构简述 魔数与版本号：每个Class文件开头都有魔数0xCAFEBABE，用来标识这是个Class文件，后面跟着版本号。 常量池：存储类中的各种常量，比如字符串、类名、方法名等。 访问标志：描述类的访问权限（public、final等）。 类信息：包括当前类、父类、实现的接口等。 字段表、方法表：类的属性和方法定义。 属性表：比如源码文件名、行号表等调试信息。 二、类加载机制：Class文件如何被JVM识别？ JVM并不是一次性把所有Class文件都加载进来，而是“用到才加载”，这就是类加载机制。整个过程分为：\n加载（Loading）：JVM通过类加载器（ClassLoader）读取Class文件，生成对应的Class对象。 链接（Linking）：包括验证（校验Class文件格式和安全性）、准备（为静态变量分配内存）、解析（将符号引用转为直接引用）。 初始化（Initialization）：执行类的静态代码块和静态变量初始化。 类加载器的双亲委派模型 JVM内置了三种主要的类加载器：\n启动类加载器（Bootstrap ClassLoader）：加载JDK核心类库（rt.jar等）。 扩展类加载器（Extension ClassLoader）：加载JDK扩展库（ext目录）。 应用类加载器（App ClassLoader）：加载我们自己写的代码（classpath下的类）。 加载请求会先交给父加载器，只有父加载器找不到才会自己加载，这样可以保证Java核心类的安全性。\n三、运行时数据区：JVM的“内存分区” Class文件加载进来后，JVM会把它们的信息放到不同的内存区域，这些区域统称为运行时数据区。每个区域都有自己的职责：\n1. 方法区（Method Area） 存放已加载的类信息、常量、静态变量、JIT编译后的代码等。 也叫“永久代”（PermGen，JDK8之前）或“元空间”（Metaspace，JDK8之后）。 2. 堆（Heap） 存放所有对象实例和数组，是垃圾回收的主要区域。 也是Java内存溢出（OutOfMemoryError）最常见的地方。 3. 虚拟机栈（JVM Stack） 每个线程独有，存放方法调用时的局部变量、操作数栈、方法出口等。 栈溢出（StackOverflowError）就发生在这里。 4. 本地方法栈（Native Method Stack） 为JVM调用本地（C/C++）方法服务。 5. 程序计数器（Program Counter Register） 记录当前线程正在执行的字节码行号指示器。 多线程切换时，靠它来恢复执行位置。 四、代码示例：一个简单的Java类是如何被执行的 为了更直观地理解上述过程，我们来看一个简单的例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class Simple { private static int s = 1; private int m = 2; public int add(int a, int b) { return a + b + m; } public static void main(String[] args) { Simple simple = new Simple(); int result = simple.add(3, 4); System.out.println(result); } } JVM执行Simple.main方法的流程如下：\nsequenceDiagram participant User as 用户 participant JVM as JVM participant ClassLoader as 类加载器 participant MethodArea as 方法区 participant Heap as 堆 participant Stack as 虚拟机栈 User-\u003e\u003eJVM: 执行 java Simple JVM-\u003e\u003eClassLoader: 加载 Simple.class ClassLoader--\u003e\u003eJVM: 返回 Class 对象 JVM-\u003e\u003eMethodArea: 存储类信息、静态变量s JVM-\u003e\u003eStack: 为main方法创建栈帧 Stack-\u003e\u003eHeap: new Simple() 创建对象实例 Heap--\u003e\u003eStack: 返回对象引用 Stack-\u003e\u003eStack: 执行 simple.add(3, 4) Stack-\u003e\u003eStack: 为add方法创建新栈帧 Note right of Stack: add方法栈帧包含局部变量a,b和this引用 Stack--\u003e\u003eStack: add方法返回结果 Stack-\u003e\u003eStack: main方法接收结果 Stack-\u003e\u003eJVM: System.out.println() 输出结果 五、JVM执行Java代码的流程 编译：Java源码（.java） → 编译器 → 字节码（.class） 加载：类加载器读取Class文件，加载到方法区 实例化：在堆中创建对象实例 执行：JVM解释执行字节码，或通过JIT即时编译成本地机器码 方法调用与栈帧：每次方法调用都会在虚拟机栈中创建一个栈帧，方法执行完毕后栈帧出栈 6. 字节码指令执行：JVM的\u0026quot;汇编语言\u0026quot; 让我们深入看看JVM是如何执行字节码指令的。以上面的add方法为例，编译后的字节码大致如下：\n1 2 3 4 5 6 7 8 9 public int add(int, int); Code: 0: iload_1 // 将第一个参数a压入操作数栈 1: iload_2 // 将第二个参数b压入操作数栈 2: iadd // 弹出栈顶两个int值，相加后压入栈 3: aload_0 // 将this引用压入栈 4: getfield #2 // 获取实例字段m的值 7: iadd // 再次相加 8: ireturn // 返回栈顶int值 每条字节码指令都对应JVM内部的一个操作，JVM通过操作数栈和局部变量表来完成计算：\n局部变量表：存储方法参数和局部变量 操作数栈：用于计算的临时存储区域 7. JIT即时编译器：让Java跑得更快 JVM不仅仅是解释执行字节码，为了提升性能，它还引入了JIT（Just-In-Time）即时编译器。当某个方法被频繁调用（成为\u0026quot;热点代码\u0026quot;）时，JIT会将其编译成本地机器码并缓存起来，后续调用就直接执行机器码，速度远超解释执行。\n1 2 3 4 5 6 7 8 // 这样的循环代码很容易被JIT优化 public long calculate(int n) { long sum = 0; for (int i = 0; i \u0026lt; n; i++) { sum += i * i; // 热点代码，会被JIT编译优化 } return sum; } JIT编译器有两种：\nC1编译器（Client）：编译速度快，优化程度一般 C2编译器（Server）：编译速度慢，但优化程度高 现代JVM采用分层编译策略，先用C1快速编译，再用C2深度优化。\n8. 垃圾回收（GC）：自动内存管理 堆是存放对象的区域，如果不及时清理无用的对象，内存迟早会耗尽。垃圾回收（GC） 就是JVM自动管理堆内存的机制。\n堆内存分代模型 1 2 3 4 5 6 堆内存布局： ┌─────────────────┬─────────────────┐ │ 年轻代(Young) │ 老年代(Old) │ ├─────┬─────┬─────┼─────────────────┤ │Eden │ S0 │ S1 │ Old Generation │ └─────┴─────┴─────┴─────────────────┘ Eden区：新对象首先分配在这里 Survivor区（S0、S1）：经过一次GC后存活的对象 老年代：长期存活的对象最终会被移到这里 GC触发时机与过程 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 public class GCDemo { public static void main(String[] args) { List\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); // 不断创建对象，观察GC行为 for (int i = 0; i \u0026lt; 100000; i++) { list.add(\u0026#34;String \u0026#34; + i); // 每1000次打印一下堆使用情况 if (i % 1000 == 0) { Runtime runtime = Runtime.getRuntime(); long used = runtime.totalMemory() - runtime.freeMemory(); System.out.println(\u0026#34;已使用内存: \u0026#34; + used / 1024 / 1024 + \u0026#34;MB\u0026#34;); } } } } 9. 内存模型与线程安全 JVM内存模型（JMM）定义了多线程环境下内存的可见性规则：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 public class MemoryModelDemo { private volatile boolean flag = false; // volatile保证可见性 private int count = 0; public void writer() { count = 42; // 1. 写入count flag = true; // 2. 写入flag（volatile） } public void reader() { if (flag) { // 3. 读取flag // 由于volatile的happens-before规则 // 这里一定能看到count=42 System.out.println(count); } } } happens-before规则保证了内存操作的有序性：\n程序顺序规则：单线程内，代码按顺序执行 volatile规则：volatile写happens-before后续的volatile读 锁规则：unlock happens-before 后续的lock 线程启动规则：Thread.start() happens-before 线程内的所有操作 六、性能调优与监控 了解了JVM的运行机制后，我们就能更好地进行性能调优。以下是一些常用的JVM参数和监控手段：\nJVM调优参数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 堆内存设置 -Xms2g -Xmx4g # 初始堆2G，最大堆4G -XX:NewRatio=3 # 老年代:年轻代 = 3:1 -XX:SurvivorRatio=8 # Eden:Survivor = 8:1 # GC选择 -XX:+UseG1GC # 使用G1垃圾收集器 -XX:MaxGCPauseMillis=200 # G1最大停顿时间200ms # JIT编译优化 -XX:+TieredCompilation # 开启分层编译 -XX:CompileThreshold=10000 # 方法调用10000次后JIT编译 # 内存溢出时生成dump文件 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp/heapdump.hprof 性能监控工具 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // 使用JMX监控JVM状态 public class JVMMonitor { public static void printMemoryInfo() { MemoryMXBean memoryBean = ManagementFactory.getMemoryMXBean(); MemoryUsage heapUsage = memoryBean.getHeapMemoryUsage(); System.out.println(\u0026#34;堆内存使用情况:\u0026#34;); System.out.println(\u0026#34;已使用: \u0026#34; + heapUsage.getUsed() / 1024 / 1024 + \u0026#34;MB\u0026#34;); System.out.println(\u0026#34;最大值: \u0026#34; + heapUsage.getMax() / 1024 / 1024 + \u0026#34;MB\u0026#34;); System.out.println(\u0026#34;使用率: \u0026#34; + (heapUsage.getUsed() * 100.0 / heapUsage.getMax()) + \u0026#34;%\u0026#34;); } public static void printGCInfo() { List\u0026lt;GarbageCollectorMXBean\u0026gt; gcBeans = ManagementFactory.getGarbageCollectorMXBeans(); for (GarbageCollectorMXBean gcBean : gcBeans) { System.out.println(\u0026#34;GC名称: \u0026#34; + gcBean.getName()); System.out.println(\u0026#34;GC次数: \u0026#34; + gcBean.getCollectionCount()); System.out.println(\u0026#34;GC时间: \u0026#34; + gcBean.getCollectionTime() + \u0026#34;ms\u0026#34;); } } } 七、开发中的常见问题与解决方案 1. 类加载问题 1 2 3 4 5 6 7 8 9 10 11 12 13 14 // ClassNotFoundException vs NoClassDefFoundError public class ClassLoadingIssue { public static void main(String[] args) { try { // ClassNotFoundException: 编译时类存在，运行时找不到 Class.forName(\u0026#34;com.example.MissingClass\u0026#34;); } catch (ClassNotFoundException e) { System.out.println(\u0026#34;类未找到: \u0026#34; + e.getMessage()); } // NoClassDefFoundError: 编译时和加载时都存在，但初始化时出错 // 通常是静态代码块抛异常导致 } } 2. 内存泄漏排查 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // 常见的内存泄漏场景 public class MemoryLeakDemo { private static List\u0026lt;Object\u0026gt; cache = new ArrayList\u0026lt;\u0026gt;(); // 静态集合持有对象引用 public void addToCache(Object obj) { cache.add(obj); // 对象永远不会被GC回收 } // 解决方案：使用WeakReference private static List\u0026lt;WeakReference\u0026lt;Object\u0026gt;\u0026gt; weakCache = new ArrayList\u0026lt;\u0026gt;(); public void addToWeakCache(Object obj) { weakCache.add(new WeakReference\u0026lt;\u0026gt;(obj)); // 允许GC回收 } } 3. 线程安全与性能平衡 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 public class ThreadSafetyDemo { // 方案1：synchronized - 简单但性能较差 private int count1 = 0; public synchronized void increment1() { count1++; } // 方案2：AtomicInteger - 无锁，性能更好 private AtomicInteger count2 = new AtomicInteger(0); public void increment2() { count2.incrementAndGet(); } // 方案3：ThreadLocal - 线程隔离，避免竞争 private ThreadLocal\u0026lt;Integer\u0026gt; count3 = ThreadLocal.withInitial(() -\u0026gt; 0); public void increment3() { count3.set(count3.get() + 1); } } 八、实战：分析一个真实的性能问题 假设我们遇到了一个接口响应慢的问题，通过JVM分析来定位：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // 问题代码：频繁的字符串拼接 public class PerformanceIssue { public String buildLargeString(List\u0026lt;String\u0026gt; items) { String result = \u0026#34;\u0026#34;; for (String item : items) { result += item + \u0026#34;,\u0026#34;; // 每次都创建新的String对象 } return result; } // 优化后：使用StringBuilder public String buildLargeStringOptimized(List\u0026lt;String\u0026gt; items) { StringBuilder sb = new StringBuilder(items.size() * 20); // 预估容量 for (String item : items) { sb.append(item).append(\u0026#34;,\u0026#34;); } return sb.toString(); } } 分析过程：\n通过JProfiler或VisualVM发现大量String对象创建 查看GC日志发现年轻代GC频繁 定位到字符串拼接代码 使用StringBuilder优化，性能提升10倍 总结 从一个简单的Class文件到在JVM中高效运行，Java代码经历了一系列精妙的设计：\n编译与加载：Java源码编译成字节码，通过类加载器加载到JVM 内存管理：运行时数据区的精心设计，让不同类型的数据各司其职 执行优化：从解释执行到JIT编译，让Java越跑越快 自动回收：GC机制解放了程序员的双手，但也需要我们理解其原理 并发安全：JMM保证了多线程环境下的内存一致性 理解这些底层机制，不仅能帮助我们写出更高效、更健壮的代码，还能在遇到性能问题和内存异常时，更有底气地去定位和解决。JVM的世界博大精深，这篇文章只是一个开始，希望能为你打开一扇深入了解JVM的窗户。\n在实际开发中，建议大家：\n合理设置JVM参数，根据应用特点调优 定期监控JVM状态，及时发现问题 理解GC原理，避免内存泄漏 掌握性能分析工具，快速定位瓶颈 只有深入理解了JVM的运行机制，我们才能真正驾驭Java这门语言，写出高性能的企业级应用。\n","date":"2022-07-15T10:23:00+08:00","permalink":"https://tech-gt.github.io/p/%E4%BD%A0%E7%9A%84java%E4%BB%A3%E7%A0%81%E6%98%AF%E5%A6%82%E4%BD%95%E8%A2%AB%E6%89%A7%E8%A1%8C%E7%9A%84/","title":"你的Java代码是如何被执行的？"},{"content":"在实际的后端开发中，我们经常会遇到聚合多个服务响应的需求。比如在直播App的“动态中心”页面，需要同时展示用户信息、帖子内容、评论数等数据。这些数据往往来自不同的后端服务，传统的做法是串行调用各个RPC接口，导致整体响应时间受限于最慢的那个服务。\n传统串行调用的痛点 以往的代码大致如下：\n1 2 3 4 5 6 UserInfo userInfo = userService.getUserInfo(userId); // 阻塞 Post post = postService.getPost(postId); // 阻塞 int commentCount = commentService.getCommentCount(postId); // 阻塞 DynamicVO vo = new DynamicVO(userInfo, post, commentCount); return vo; 如果每个RPC耗时100ms，串行下来就要300ms，用户体验很差。\n用 CompletableFuture 改造为并行异步 Java 8 引入的 CompletableFuture，让我们可以非常优雅地将这些阻塞调用改造成并行异步，大幅提升聚合接口的性能。\n核心思路 每个RPC调用用 CompletableFuture.supplyAsync 包装，放到线程池里并行执行。 用 thenCombine、allOf 等方法组合多个Future，等所有结果都返回后再组装最终VO。 代码示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 ExecutorService executor = Executors.newFixedThreadPool(3); CompletableFuture\u0026lt;UserInfo\u0026gt; userFuture = CompletableFuture.supplyAsync(() -\u0026gt; userService.getUserInfo(userId), executor); CompletableFuture\u0026lt;Post\u0026gt; postFuture = CompletableFuture.supplyAsync(() -\u0026gt; postService.getPost(postId), executor); CompletableFuture\u0026lt;Integer\u0026gt; commentCountFuture = CompletableFuture.supplyAsync(() -\u0026gt; commentService.getCommentCount(postId), executor); CompletableFuture\u0026lt;DynamicVO\u0026gt; resultFuture = userFuture.thenCombine(postFuture, (user, post) -\u0026gt; new Object[]{user, post}) .thenCombine(commentCountFuture, (arr, commentCount) -\u0026gt; { UserInfo user = (UserInfo) arr[0]; Post post = (Post) arr[1]; return new DynamicVO(user, post, commentCount); }); DynamicVO vo = resultFuture.get(); // 阻塞等待所有结果 这样，整体耗时只取决于最慢的那个RPC，理论上可以缩短到100ms左右。\n实际工作中的经验 线程池要合理配置，避免线程资源耗尽。 异常处理要完善，可以用 exceptionally、handle 等方法兜底，避免某个服务挂掉导致整体失败。 链式组合更优雅，复杂场景下可以用 allOf 聚合多个Future，再统一处理结果。 更复杂的聚合场景 如果聚合的服务更多，可以这样：\n1 2 3 4 5 6 7 CompletableFuture.allOf(userFuture, postFuture, commentCountFuture) .thenApply(v -\u0026gt; { UserInfo user = userFuture.join(); Post post = postFuture.join(); int commentCount = commentCountFuture.join(); return new DynamicVO(user, post, commentCount); }); 流程图示意 sequenceDiagram participant C as Controller participant U as UserService participant P as PostService participant M as CommentService C-\u003e\u003eU: getUserInfo(userId) C-\u003e\u003eP: getPost(postId) C-\u003e\u003eM: getCommentCount(postId) U--\u003e\u003eC: UserInfo P--\u003e\u003eC: Post M--\u003e\u003eC: CommentCount C-\u003e\u003eC: 聚合结果 总结 在高并发、聚合型接口场景下，合理利用 CompletableFuture 进行异步并发编排，可以极大提升接口性能和用户体验。实际项目中，建议优先考虑这种方式替代传统串行阻塞调用。\n","date":"2022-07-15T10:23:00+08:00","permalink":"https://tech-gt.github.io/p/%E7%94%A8-completablefuture-%E8%81%9A%E5%90%88%E5%A4%9A%E4%B8%AA%E5%90%8E%E7%AB%AF%E6%9C%8D%E5%8A%A1%E5%93%8D%E5%BA%94/","title":"用 CompletableFuture 聚合多个后端服务响应"},{"content":"在分布式系统中，唯一ID的生成是一个常见问题。MyBatisPlus提供了内置的雪花算法（Snowflake）来生成分布式ID，使用起来非常方便。但在实际项目中，如果不注意一些细节，很容易踩坑。\n雪花算法简介 雪花算法是Twitter开源的分布式ID生成算法，生成的ID是一个64位的长整型，包含：\n1位符号位（固定为0） 41位时间戳（毫秒级） 10位工作机器ID（5位数据中心ID + 5位机器ID） 12位序列号（同一毫秒内的自增序列） MyBatisPlus中的配置 实体类配置 1 2 3 4 5 6 7 8 9 10 @Data @TableName(\u0026#34;user\u0026#34;) public class User { @TableId(type = IdType.ASSIGN_ID) private Long id; private String name; private String email; // 其他字段... } 全局配置 1 2 3 4 5 6 7 8 9 @Configuration public class MybatisPlusConfig { @Bean public MybatisPlusInterceptor mybatisPlusInterceptor() { MybatisPlusInterceptor interceptor = new MybatisPlusInterceptor(); // 其他配置... return interceptor; } } 实际踩坑经历 1. 机器ID重复问题 在容器化部署时，如果多个实例使用相同的机器ID，会导致ID重复。MyBatisPlus默认使用机器IP的最后几位作为机器ID，但在容器环境中可能不够稳定。\n解决方案：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 @Component public class CustomIdGenerator implements IdentifierGenerator { @Override public Number nextId(Object entity) { // 自定义机器ID生成逻辑 long workerId = getWorkerId(); long datacenterId = getDatacenterId(); return new Snowflake(workerId, datacenterId).nextId(); } private long getWorkerId() { // 从环境变量或配置中心获取 String workerId = System.getenv(\u0026#34;WORKER_ID\u0026#34;); return workerId != null ? Long.parseLong(workerId) : 1L; } private long getDatacenterId() { String datacenterId = System.getenv(\u0026#34;DATACENTER_ID\u0026#34;); return datacenterId != null ? Long.parseLong(datacenterId) : 1L; } } 2. 时钟回拨问题 如果服务器时间被调整（比如NTP同步），可能导致时钟回拨，生成重复ID。\n处理方案：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 public class SafeSnowflake { private final Snowflake snowflake; private long lastTimestamp = -1L; public SafeSnowflake(long workerId, long datacenterId) { this.snowflake = new Snowflake(workerId, datacenterId); } public synchronized long nextId() { long timestamp = System.currentTimeMillis(); // 检测时钟回拨 if (timestamp \u0026lt; lastTimestamp) { throw new RuntimeException(\u0026#34;Clock moved backwards!\u0026#34;); } lastTimestamp = timestamp; return snowflake.nextId(); } } 3. 性能考虑 在高并发场景下，雪花算法的性能表现良好，但需要注意：\n序列号溢出：同一毫秒内序列号超过4096时会等待下一毫秒 时间戳精度：确保系统时间精度为毫秒级 机器ID分配：确保不同机器使用不同的机器ID 最佳实践 1. 机器ID管理 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 @Component public class MachineIdManager { private static final String MACHINE_ID_KEY = \u0026#34;machine_id\u0026#34;; @Autowired private RedisTemplate\u0026lt;String, String\u0026gt; redisTemplate; public long getMachineId() { String machineId = redisTemplate.opsForValue().get(MACHINE_ID_KEY); if (machineId == null) { // 从Redis获取可用机器ID machineId = allocateMachineId(); } return Long.parseLong(machineId); } private String allocateMachineId() { // 实现机器ID分配逻辑 // 可以使用Redis的原子操作 return \u0026#34;1\u0026#34;; // 简化示例 } } 2. 监控告警 1 2 3 4 5 6 7 8 9 10 11 12 13 @Component public class IdGeneratorMonitor { private final AtomicLong lastId = new AtomicLong(0); public void checkIdSequence(long currentId) { long previousId = lastId.get(); if (currentId \u0026lt;= previousId) { // 发送告警 log.error(\u0026#34;ID生成异常: currentId={}, previousId={}\u0026#34;, currentId, previousId); } lastId.set(currentId); } } 总结 MyBatisPlus的雪花ID生成器虽然使用简单，但在生产环境中需要注意：\n机器ID唯一性：确保不同实例使用不同的机器ID 时钟同步：避免时钟回拨导致ID重复 监控告警：及时发现ID生成异常 性能优化：在高并发场景下合理配置 在实际项目中，建议根据业务需求选择合适的ID生成策略，并做好相应的监控和告警机制。\n","date":"2021-11-08T14:30:00+08:00","permalink":"https://tech-gt.github.io/p/mybatisplus%E5%86%85%E7%BD%AE%E7%9A%84%E9%9B%AA%E8%8A%B1id%E7%94%9F%E6%88%90%E7%AE%97%E6%B3%95%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/","title":"MyBatisPlus内置的雪花ID生成算法注意事项"},{"content":"引言 在开发业务系统时，我们经常会遇到复杂的业务规则判断。比如电商系统的促销规则、风控系统的风险评估、保险系统的理赔审核等。这些规则往往变化频繁，如果硬编码在代码里，每次修改都要重新发布，维护成本很高。\n这时候，规则引擎就派上用场了。今天就来聊聊Drools规则引擎在实际项目中的应用。\n什么是Drools Drools是一个开源的业务规则管理系统（BRMS），它提供了一个核心的业务规则引擎（BRE）。简单来说，Drools可以让我们把复杂的业务逻辑从代码中抽离出来，用更直观的规则语言来表达。\n核心概念 在使用之前，先了解几个核心概念：\nFact：事实，即输入到规则引擎的数据对象 Rule：规则，包含条件（when）和动作（then） Working Memory：工作内存，存放Fact的地方 Knowledge Base：知识库，包含所有规则的集合 Session：会话，规则执行的上下文 项目集成 首先在项目中引入Drools依赖：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.drools\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;drools-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;7.74.1.Final\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.drools\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;drools-compiler\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;7.74.1.Final\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.drools\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;drools-decisiontables\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;7.74.1.Final\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 实战案例：电商促销规则 我们以一个电商促销系统为例，来看看Drools的具体使用。\n1. 定义业务对象 首先定义订单和用户对象：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 public class Order { private String orderId; private BigDecimal totalAmount; private String userId; private List\u0026lt;OrderItem\u0026gt; items; private BigDecimal discountAmount = BigDecimal.ZERO; // 构造函数、getter、setter省略 } public class User { private String userId; private String level; // VIP, GOLD, SILVER, NORMAL private int orderCount; // 历史订单数 private boolean isNewUser; // 构造函数、getter、setter省略 } public class OrderItem { private String productId; private String category; private BigDecimal price; private int quantity; // 构造函数、getter、setter省略 } 2. 编写规则文件 在src/main/resources/rules目录下创建promotion.drl文件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 package com.example.promotion import com.example.model.Order import com.example.model.User import com.example.model.OrderItem import java.math.BigDecimal // 新用户首单优惠 rule \u0026#34;新用户首单8折优惠\u0026#34; when $user: User(isNewUser == true) $order: Order(userId == $user.userId, totalAmount \u0026gt; 100) then BigDecimal discount = $order.getTotalAmount().multiply(new BigDecimal(\u0026#34;0.2\u0026#34;)); $order.setDiscountAmount(discount); System.out.println(\u0026#34;应用新用户首单8折优惠，优惠金额：\u0026#34; + discount); end // VIP用户满500减100 rule \u0026#34;VIP用户满500减100\u0026#34; when $user: User(level == \u0026#34;VIP\u0026#34;) $order: Order(userId == $user.userId, totalAmount \u0026gt;= 500) then $order.setDiscountAmount(new BigDecimal(\u0026#34;100\u0026#34;)); System.out.println(\u0026#34;应用VIP满500减100优惠\u0026#34;); end // 图书类商品满200减50 rule \u0026#34;图书满200减50\u0026#34; when $order: Order() $bookAmount: BigDecimal() from accumulate( OrderItem(category == \u0026#34;BOOK\u0026#34;, $price: price, $qty: quantity) from $order.items, sum($price.multiply(new BigDecimal($qty))) ) eval($bookAmount.compareTo(new BigDecimal(\u0026#34;200\u0026#34;)) \u0026gt;= 0) then BigDecimal currentDiscount = $order.getDiscountAmount(); $order.setDiscountAmount(currentDiscount.add(new BigDecimal(\u0026#34;50\u0026#34;))); System.out.println(\u0026#34;应用图书满200减50优惠\u0026#34;); end // 老用户回购优惠 rule \u0026#34;老用户回购优惠\u0026#34; salience 10 // 优先级，数字越大优先级越高 when $user: User(orderCount \u0026gt;= 10, level != \u0026#34;VIP\u0026#34;) $order: Order(userId == $user.userId, totalAmount \u0026gt; 300) then BigDecimal discount = $order.getTotalAmount().multiply(new BigDecimal(\u0026#34;0.05\u0026#34;)); BigDecimal currentDiscount = $order.getDiscountAmount(); $order.setDiscountAmount(currentDiscount.add(discount)); System.out.println(\u0026#34;应用老用户回购5%优惠，优惠金额：\u0026#34; + discount); end 3. 规则引擎服务 创建一个规则引擎服务类：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 @Service public class PromotionRuleService { private KieContainer kieContainer; @PostConstruct public void init() { KieServices kieServices = KieServices.Factory.get(); KieFileSystem kieFileSystem = kieServices.newKieFileSystem(); // 加载规则文件 Resource resource = kieServices.getResources() .newClassPathResource(\u0026#34;rules/promotion.drl\u0026#34;); kieFileSystem.write(resource); // 构建知识库 KieBuilder kieBuilder = kieServices.newKieBuilder(kieFileSystem); kieBuilder.buildAll(); if (kieBuilder.getResults().hasMessages(Level.ERROR)) { throw new RuntimeException(\u0026#34;规则编译失败：\u0026#34; + kieBuilder.getResults()); } KieModule kieModule = kieBuilder.getKieModule(); this.kieContainer = kieServices.newKieContainer(kieModule.getReleaseId()); } public void applyPromotionRules(Order order, User user) { KieSession kieSession = kieContainer.newKieSession(); try { // 插入事实 kieSession.insert(order); kieSession.insert(user); // 执行规则 int firedRules = kieSession.fireAllRules(); System.out.println(\u0026#34;执行了 \u0026#34; + firedRules + \u0026#34; 条规则\u0026#34;); } finally { kieSession.dispose(); } } } 4. 控制器使用 在控制器中使用规则引擎：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 @RestController @RequestMapping(\u0026#34;/api/orders\u0026#34;) public class OrderController { @Autowired private PromotionRuleService promotionRuleService; @Autowired private UserService userService; @PostMapping(\u0026#34;/calculate-discount\u0026#34;) public ResponseEntity\u0026lt;OrderDiscountResponse\u0026gt; calculateDiscount(@RequestBody Order order) { // 获取用户信息 User user = userService.getUserById(order.getUserId()); // 应用促销规则 promotionRuleService.applyPromotionRules(order, user); // 返回结果 OrderDiscountResponse response = new OrderDiscountResponse(); response.setOrderId(order.getOrderId()); response.setOriginalAmount(order.getTotalAmount()); response.setDiscountAmount(order.getDiscountAmount()); response.setFinalAmount(order.getTotalAmount().subtract(order.getDiscountAmount())); return ResponseEntity.ok(response); } } 高级特性 1. 规则优先级 使用salience属性可以控制规则执行顺序：\n1 2 3 4 5 6 7 rule \u0026#34;高优先级规则\u0026#34; salience 100 when // 条件 then // 动作 end 2. 规则组 使用agenda-group可以将规则分组：\n1 2 3 4 5 6 7 rule \u0026#34;VIP专享规则\u0026#34; agenda-group \u0026#34;vip-promotion\u0026#34; when // 条件 then // 动作 end 在代码中激活特定组：\n1 2 kieSession.getAgenda().getAgendaGroup(\u0026#34;vip-promotion\u0026#34;).setFocus(); kieSession.fireAllRules(); 3. 全局变量 可以在规则中使用全局变量：\n1 2 3 4 5 6 7 8 global java.util.List promotionLogs; rule \u0026#34;记录促销日志\u0026#34; when $order: Order(discountAmount \u0026gt; 0) then promotionLogs.add(\u0026#34;订单 \u0026#34; + $order.getOrderId() + \u0026#34; 享受优惠 \u0026#34; + $order.getDiscountAmount()); end 在代码中设置全局变量：\n1 2 List\u0026lt;String\u0026gt; logs = new ArrayList\u0026lt;\u0026gt;(); kieSession.setGlobal(\u0026#34;promotionLogs\u0026#34;, logs); 性能优化 1. 会话复用 对于频繁调用的场景，可以考虑复用KieSession：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 @Component public class RuleSessionPool { private final Queue\u0026lt;KieSession\u0026gt; sessionPool = new ConcurrentLinkedQueue\u0026lt;\u0026gt;(); private final KieContainer kieContainer; public RuleSessionPool(KieContainer kieContainer) { this.kieContainer = kieContainer; } public KieSession borrowSession() { KieSession session = sessionPool.poll(); if (session == null) { session = kieContainer.newKieSession(); } return session; } public void returnSession(KieSession session) { // 清理会话状态 session.getFactHandles().forEach(session::delete); sessionPool.offer(session); } } 2. 规则编译缓存 将编译好的规则缓存起来，避免重复编译：\n1 2 3 4 5 6 7 8 9 10 11 @Configuration public class DroolsConfig { @Bean @Scope(\u0026#34;singleton\u0026#34;) public KieContainer kieContainer() { KieServices kieServices = KieServices.Factory.get(); KieContainer kieContainer = kieServices.getKieClasspathContainer(); return kieContainer; } } 规则管理 在生产环境中，我们通常需要动态管理规则。可以考虑以下方案：\n1. 数据库存储规则 1 2 3 4 5 6 7 8 9 10 11 12 @Entity public class BusinessRule { @Id private String ruleId; private String ruleName; private String ruleContent; private boolean enabled; private Date createTime; private Date updateTime; // getter、setter省略 } 2. 动态加载规则 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 public void reloadRules() { List\u0026lt;BusinessRule\u0026gt; rules = businessRuleRepository.findByEnabled(true); KieServices kieServices = KieServices.Factory.get(); KieFileSystem kieFileSystem = kieServices.newKieFileSystem(); for (BusinessRule rule : rules) { String resourcePath = \u0026#34;src/main/resources/rules/\u0026#34; + rule.getRuleId() + \u0026#34;.drl\u0026#34;; kieFileSystem.write(resourcePath, rule.getRuleContent()); } KieBuilder kieBuilder = kieServices.newKieBuilder(kieFileSystem); kieBuilder.buildAll(); if (!kieBuilder.getResults().hasMessages(Level.ERROR)) { KieModule kieModule = kieBuilder.getKieModule(); this.kieContainer = kieServices.newKieContainer(kieModule.getReleaseId()); } } 最佳实践 基于实际使用经验，总结几个最佳实践：\n1. 规则设计原则 单一职责：每个规则只处理一个业务逻辑 避免循环：注意规则之间的依赖关系，避免无限循环 合理分组：使用agenda-group对规则进行分类管理 2. 性能考虑 减少事实数量：只插入必要的事实对象 优化规则条件：将最容易失败的条件放在前面 使用索引：对于大量数据，考虑在Fact对象上建立索引 3. 测试策略 1 2 3 4 5 6 7 8 9 10 11 12 @Test public void testPromotionRules() { // 准备测试数据 User vipUser = new User(\u0026#34;user1\u0026#34;, \u0026#34;VIP\u0026#34;, 5, false); Order order = new Order(\u0026#34;order1\u0026#34;, new BigDecimal(\u0026#34;600\u0026#34;), \u0026#34;user1\u0026#34;); // 执行规则 promotionRuleService.applyPromotionRules(order, vipUser); // 验证结果 assertEquals(new BigDecimal(\u0026#34;100\u0026#34;), order.getDiscountAmount()); } 当然，Drools也不是万能的。对于简单的业务逻辑，直接用代码实现可能更简单。但对于复杂多变的业务规则，Drools确实是一个很好的选择。\n在实际项目中，建议从简单的规则开始，逐步积累经验，然后再处理更复杂的场景。同时要注意规则的版本管理和测试，确保系统的稳定性。\n","date":"2021-03-22T09:15:00+08:00","permalink":"https://tech-gt.github.io/p/drools%E8%A7%84%E5%88%99%E5%BC%95%E6%93%8E%E5%9C%A8%E4%B8%9A%E5%8A%A1%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E5%AE%9E%E6%88%98%E5%BA%94%E7%94%A8/","title":"Drools规则引擎在业务系统中的实战应用"},{"content":"在高并发的Java应用中，异常处理往往是一个被忽视的性能瓶颈。最近在优化一个API网关项目时，发现大量的用户认证异常创建导致CPU占用过高，通过profiling工具分析后发现，异常对象的创建成本远比我们想象的要高。\n异常创建的性能瓶颈 问题现象 在我们的网关系统中，有这样一段代码：\n1 2 3 4 5 6 7 8 9 10 11 12 public class AuthenticationFilter { public void doFilter(HttpServletRequest request, HttpServletResponse response) { String token = request.getHeader(\u0026#34;Authorization\u0026#34;); if (StringUtils.isEmpty(token)) { throw new UnauthorizedException(\u0026#34;缺少认证token\u0026#34;); } if (!tokenValidator.isValid(token)) { throw new UnauthorizedException(\u0026#34;token已过期或无效\u0026#34;); } // 继续处理请求... } } 在高峰期，这个认证过滤器每秒要处理数万次请求，其中约15%的请求会因为token问题触发认证异常。通过JProfiler分析发现，fillInStackTrace方法占用了大量CPU时间。\n根本原因分析 当我们创建一个异常对象时，JVM会自动调用fillInStackTrace()方法来收集当前线程的调用栈信息。这个过程包括：\n遍历调用栈：从当前方法开始，逐层向上遍历整个调用链 收集栈帧信息：记录每个方法的类名、方法名、文件名、行号等 创建StackTraceElement数组：将收集到的信息封装成对象数组 这个过程在深层调用栈的情况下会变得非常耗时。\n优化方案一：覆盖fillInStackTrace禁用堆栈跟踪 实现思路 既然填充堆栈是性能瓶颈，最直接的优化方法就是阻止这个行为。我们可以创建一个自定义的\u0026quot;快速\u0026quot;异常类：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public class FastException extends RuntimeException { public FastException(String message) { super(message); } public FastException(String message, Throwable cause) { super(message, cause); } @Override public Throwable fillInStackTrace() { // 直接返回this，不填充堆栈信息 return this; } } 业务异常类的改造 基于FastException，我们可以创建具体的业务异常：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 public class UnauthorizedException extends FastException { private final String errorCode; public UnauthorizedException(String errorCode, String message) { super(message); this.errorCode = errorCode; } public String getErrorCode() { return errorCode; } } public class AuthenticationFilter { public void doFilter(HttpServletRequest request, HttpServletResponse response) { String token = request.getHeader(\u0026#34;Authorization\u0026#34;); if (StringUtils.isEmpty(token)) { throw new UnauthorizedException(\u0026#34;MISSING_TOKEN\u0026#34;, \u0026#34;缺少认证token\u0026#34;); } if (!tokenValidator.isValid(token)) { throw new UnauthorizedException(\u0026#34;INVALID_TOKEN\u0026#34;, \u0026#34;token已过期或无效\u0026#34;); } } } 性能测试对比 我们做了一个简单的性能测试：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 public class ExceptionPerformanceTest { private static final int ITERATIONS = 1_000_000; @Test public void testNormalException() { long start = System.currentTimeMillis(); for (int i = 0; i \u0026lt; ITERATIONS; i++) { try { throw new RuntimeException(\u0026#34;测试异常\u0026#34;); } catch (Exception e) { // 捕获并忽略 } } long end = System.currentTimeMillis(); System.out.println(\u0026#34;普通异常耗时: \u0026#34; + (end - start) + \u0026#34;ms\u0026#34;); } @Test public void testFastException() { long start = System.currentTimeMillis(); for (int i = 0; i \u0026lt; ITERATIONS; i++) { try { throw new FastException(\u0026#34;测试异常\u0026#34;); } catch (Exception e) { // 捕获并忽略 } } long end = System.currentTimeMillis(); System.out.println(\u0026#34;快速异常耗时: \u0026#34; + (end - start) + \u0026#34;ms\u0026#34;); } } 测试结果显示，FastException的性能提升了约80%。\n优化方案二：使用Supplier进行延迟创建 问题分析 覆盖fillInStackTrace解决了\u0026quot;创建时\u0026quot;的成本问题，但如果连创建这个动作本身都可以避免，性能会更好。考虑这样的场景：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public class GatewayFilter { public void processRequest(HttpServletRequest request) { // 大部分情况下认证都会通过 validateAuth(request, new UnauthorizedException(\u0026#34;AUTH_FAILED\u0026#34;, \u0026#34;认证失败\u0026#34;)); // 处理请求逻辑... } private void validateAuth(HttpServletRequest request, RuntimeException exception) { String token = request.getHeader(\u0026#34;Authorization\u0026#34;); if (StringUtils.isEmpty(token)) { throw exception; // 只有在真正需要时才抛出 } } } 在上面的代码中，即使大部分情况下认证都会通过，我们仍然创建了异常对象，这是不必要的开销。\nSupplier模式的应用 使用Supplier\u0026lt;T\u0026gt;可以实现真正的延迟创建：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public class GatewayFilter { public void processRequest(HttpServletRequest request) { // 传递异常的创建逻辑，而不是异常对象本身 validateAuth(request, () -\u0026gt; new UnauthorizedException(\u0026#34;AUTH_FAILED\u0026#34;, \u0026#34;认证失败\u0026#34;)); // 处理请求逻辑... } private void validateAuth(HttpServletRequest request, Supplier\u0026lt;RuntimeException\u0026gt; exceptionSupplier) { String token = request.getHeader(\u0026#34;Authorization\u0026#34;); if (StringUtils.isEmpty(token)) { throw exceptionSupplier.get(); // 只有在需要时才创建异常 } } } 更优雅的工具类封装 我们可以创建一个工具类来简化这种模式的使用：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 public class Assertions { public static void require(boolean condition, Supplier\u0026lt;RuntimeException\u0026gt; exceptionSupplier) { if (!condition) { throw exceptionSupplier.get(); } } public static void requireNonNull(Object obj, Supplier\u0026lt;RuntimeException\u0026gt; exceptionSupplier) { if (obj == null) { throw exceptionSupplier.get(); } } public static void requireNonEmpty(String str, Supplier\u0026lt;RuntimeException\u0026gt; exceptionSupplier) { if (StringUtils.isEmpty(str)) { throw exceptionSupplier.get(); } } } 使用示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class AuthenticationFilter { public void validateAuth(HttpServletRequest request) { String token = request.getHeader(\u0026#34;Authorization\u0026#34;); Assertions.requireNonEmpty(token, () -\u0026gt; new UnauthorizedException(\u0026#34;MISSING_TOKEN\u0026#34;, \u0026#34;缺少认证token\u0026#34;)); Assertions.require(tokenValidator.isValid(token), () -\u0026gt; new UnauthorizedException(\u0026#34;INVALID_TOKEN\u0026#34;, \u0026#34;token已过期或无效\u0026#34;)); Assertions.require(hasPermission(token, request.getRequestURI()), () -\u0026gt; new UnauthorizedException(\u0026#34;NO_PERMISSION\u0026#34;, \u0026#34;无权限访问该资源\u0026#34;)); } } 实际应用中的注意事项 1. 调试困难 使用FastException后，异常不再包含堆栈信息，这会给调试带来困难。建议：\n1 2 3 4 5 6 7 8 9 public class FastException extends RuntimeException { private static final boolean ENABLE_STACK_TRACE = Boolean.parseBoolean(System.getProperty(\u0026#34;fastexception.stacktrace\u0026#34;, \u0026#34;false\u0026#34;)); @Override public Throwable fillInStackTrace() { return ENABLE_STACK_TRACE ? super.fillInStackTrace() : this; } } 通过JVM参数-Dfastexception.stacktrace=true可以在需要时开启堆栈跟踪。\n2. 异常信息的完整性 在禁用堆栈跟踪后，要确保异常消息足够详细，包含必要的上下文信息：\n1 2 3 4 5 6 7 8 public void validateAuth(HttpServletRequest request) { String token = request.getHeader(\u0026#34;Authorization\u0026#34;); if (StringUtils.isEmpty(token)) { throw new UnauthorizedException(\u0026#34;MISSING_TOKEN\u0026#34;, String.format(\u0026#34;缺少认证token: uri=%s, method=%s, clientIp=%s\u0026#34;, request.getRequestURI(), request.getMethod(), getClientIp(request))); } } 3. 监控和日志 建议在异常处理的地方添加详细的日志记录：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 @ControllerAdvice public class GlobalExceptionHandler { private static final Logger logger = LoggerFactory.getLogger(GlobalExceptionHandler.class); @ExceptionHandler(UnauthorizedException.class) public ResponseEntity\u0026lt;ErrorResponse\u0026gt; handleUnauthorized(UnauthorizedException e) { // 记录详细的错误信息，包括当前线程的堆栈 logger.warn(\u0026#34;用户认证失败: errorCode={}, message={}, stackTrace={}\u0026#34;, e.getErrorCode(), e.getMessage(), getStackTrace()); return ResponseEntity.status(HttpStatus.UNAUTHORIZED) .body(new ErrorResponse(e.getErrorCode(), e.getMessage())); } private String getStackTrace() { return Arrays.stream(Thread.currentThread().getStackTrace()) .map(StackTraceElement::toString) .collect(Collectors.joining(\u0026#34;\\n\u0026#34;)); } } graph TD A[请求到达] --\u003e B{参数验证} B --\u003e|验证通过| C[业务处理] B --\u003e|验证失败| D[Supplier.get] D --\u003e E[FastException创建] E --\u003e F[异常抛出] C --\u003e G[返回结果] F --\u003e H[异常处理] H --\u003e I[错误响应] 总结 异常处理的性能优化往往被开发者忽视，但在高并发场景下，这种优化能带来显著的性能提升。通过覆盖fillInStackTrace和使用Supplier模式，我们可以在保持代码可读性的同时，大幅降低异常处理的CPU开销。\n","date":"2019-09-12T16:45:00+08:00","permalink":"https://tech-gt.github.io/p/java%E5%BC%82%E5%B8%B8%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%BD%BF%E7%94%A8supplier%E5%92%8C%E8%A6%86%E7%9B%96fillinstacktrace%E9%99%8D%E4%BD%8Ecpu%E5%8D%A0%E7%94%A8/","title":"Java异常性能优化：使用Supplier和覆盖fillInStackTrace降低CPU占用"},{"content":"引言 在维护公司的长连接网关时，我们经常会遇到一个棘手的问题：服务器显示有大量的连接，但实际上很多连接已经\u0026quot;死了\u0026quot;，客户端早就断开了，服务器却浑然不知。这些\u0026quot;活着却又死了\u0026quot;的连接，我们称之为僵尸连接（Zombie Connections）。\n今天就来聊聊在基于Netty的长连接网关中，僵尸连接是怎么产生的，以及我们是如何检测和清理它们的。\n什么是僵尸连接 僵尸连接指的是TCP连接在逻辑上已经断开，但服务器端仍然认为连接是活跃的。这种情况通常发生在：\n客户端异常退出：客户端程序崩溃、强制关闭，没有发送FIN包 网络中断：客户端网络突然断开，如拔网线、WiFi断开 防火墙/NAT超时：中间网络设备清理了连接状态，但两端不知道 客户端休眠：移动设备进入休眠模式，连接被系统回收 僵尸连接的危害 在我们的网关系统中，僵尸连接会带来以下问题：\n1. 资源浪费 每个连接都会占用服务器的文件描述符、内存等资源。大量僵尸连接会导致：\n1 2 3 4 5 # 查看当前连接数 netstat -an | grep :8080 | wc -l # 输出：50000 # 但实际活跃连接可能只有几千个 2. 性能下降 心跳检测浪费CPU和网络资源 消息推送到无效连接，增加无效网络IO 连接池满了，无法接受新的有效连接 3. 监控误导 运维同学看到连接数很高，以为系统负载很重，实际上大部分都是僵尸连接。\nNetty中的僵尸连接检测 在我们的网关项目中，主要通过以下几种方式来检测僵尸连接：\n1. 心跳机制 最常用的方法是实现应用层心跳：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 @Component public class HeartbeatHandler extends ChannelInboundHandlerAdapter { private static final int HEARTBEAT_TIMEOUT = 60; // 60秒超时 @Override public void channelActive(ChannelHandlerContext ctx) { // 连接建立时启动心跳检测 startHeartbeatCheck(ctx); ctx.fireChannelActive(); } @Override public void channelRead(ChannelHandlerContext ctx, Object msg) { if (msg instanceof HeartbeatMessage) { // 收到心跳，更新最后活跃时间 updateLastActiveTime(ctx.channel()); // 回复心跳响应 ctx.writeAndFlush(new HeartbeatResponse()); } else { // 普通消息也算活跃 updateLastActiveTime(ctx.channel()); ctx.fireChannelRead(msg); } } private void startHeartbeatCheck(ChannelHandlerContext ctx) { ctx.executor().scheduleAtFixedRate(() -\u0026gt; { Channel channel = ctx.channel(); if (channel.isActive()) { long lastActiveTime = getLastActiveTime(channel); long now = System.currentTimeMillis(); if (now - lastActiveTime \u0026gt; HEARTBEAT_TIMEOUT * 1000) { log.warn(\u0026#34;检测到僵尸连接，关闭连接: {}\u0026#34;, channel.remoteAddress()); channel.close(); } } }, HEARTBEAT_TIMEOUT, HEARTBEAT_TIMEOUT, TimeUnit.SECONDS); } } 2. TCP KeepAlive 虽然TCP自带KeepAlive机制，但默认参数太保守（2小时才开始检测）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 @Configuration public class NettyServerConfig { public ServerBootstrap createServerBootstrap() { ServerBootstrap bootstrap = new ServerBootstrap(); bootstrap.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 1024) // 启用TCP KeepAlive .childOption(ChannelOption.SO_KEEPALIVE, true) // 设置KeepAlive参数（需要系统支持） .childOption(ChannelOption.TCP_NODELAY, true); return bootstrap; } } 不过在生产环境中，我们通常还是依赖应用层心跳，因为更可控。\n3. Netty的IdleStateHandler Netty提供了现成的空闲检测处理器：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 @Component public class GatewayChannelInitializer extends ChannelInitializer\u0026lt;SocketChannel\u0026gt; { @Override protected void initChannel(SocketChannel ch) { ChannelPipeline pipeline = ch.pipeline(); // 空闲检测：30秒没有读取到数据就触发 pipeline.addLast(new IdleStateHandler(30, 0, 0, TimeUnit.SECONDS)); // 处理空闲事件 pipeline.addLast(new IdleStateEventHandler()); // 其他业务处理器 pipeline.addLast(new BusinessHandler()); } } @Component public class IdleStateEventHandler extends ChannelInboundHandlerAdapter { @Override public void userEventTriggered(ChannelHandlerContext ctx, Object evt) { if (evt instanceof IdleStateEvent) { IdleStateEvent event = (IdleStateEvent) evt; if (event.state() == IdleState.READER_IDLE) { log.info(\u0026#34;连接空闲超时，关闭连接: {}\u0026#34;, ctx.channel().remoteAddress()); ctx.close(); } } ctx.fireUserEventTriggered(evt); } } 僵尸连接的清理策略 在实际项目中，我们采用了多层清理策略：\n1. 定时清理任务 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 @Component public class ZombieConnectionCleaner { @Autowired private ConnectionManager connectionManager; @Scheduled(fixedRate = 30000) // 每30秒执行一次 public void cleanZombieConnections() { List\u0026lt;Channel\u0026gt; allChannels = connectionManager.getAllChannels(); int cleanedCount = 0; for (Channel channel : allChannels) { if (isZombieConnection(channel)) { log.info(\u0026#34;清理僵尸连接: {}\u0026#34;, channel.remoteAddress()); channel.close(); cleanedCount++; } } if (cleanedCount \u0026gt; 0) { log.info(\u0026#34;本次清理僵尸连接数量: {}\u0026#34;, cleanedCount); } } private boolean isZombieConnection(Channel channel) { if (!channel.isActive()) { return true; } // 检查最后活跃时间 Long lastActiveTime = channel.attr(LAST_ACTIVE_TIME).get(); if (lastActiveTime == null) { return false; } long idleTime = System.currentTimeMillis() - lastActiveTime; return idleTime \u0026gt; 60000; // 超过1分钟没有活动 } } 2. 连接状态监控 我们还实现了一个连接状态监控，实时统计连接情况：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 @Component public class ConnectionMonitor { private final AtomicInteger totalConnections = new AtomicInteger(0); private final AtomicInteger activeConnections = new AtomicInteger(0); @EventListener public void onChannelActive(ChannelActiveEvent event) { totalConnections.incrementAndGet(); activeConnections.incrementAndGet(); } @EventListener public void onChannelInactive(ChannelInactiveEvent event) { totalConnections.decrementAndGet(); activeConnections.decrementAndGet(); } @EventListener public void onHeartbeatReceived(HeartbeatEvent event) { // 心跳统计 } public ConnectionStats getConnectionStats() { return ConnectionStats.builder() .totalConnections(totalConnections.get()) .activeConnections(activeConnections.get()) .zombieConnections(totalConnections.get() - activeConnections.get()) .build(); } } 优化建议 基于我们的实践经验，有几个优化建议：\n1. 合理设置超时时间 心跳间隔不要太短（建议30-60秒），避免浪费资源 超时时间要考虑网络延迟和客户端处理时间 移动端可以适当放宽超时时间 2. 分层检测 1 2 3 4 5 6 7 8 9 10 11 12 // 应用层心跳 + TCP KeepAlive + 定时清理 public class LayeredZombieDetection { // 第一层：应用心跳（30秒） private static final int APP_HEARTBEAT_INTERVAL = 30; // 第二层：TCP KeepAlive（系统级别） private static final boolean ENABLE_TCP_KEEPALIVE = true; // 第三层：定时清理（60秒） private static final int CLEANUP_INTERVAL = 60; } 3. 监控告警 设置监控指标，当僵尸连接比例过高时及时告警：\n1 2 3 4 5 6 7 8 9 10 11 12 13 @Component public class ZombieConnectionAlert { @Scheduled(fixedRate = 60000) public void checkZombieRatio() { ConnectionStats stats = connectionMonitor.getConnectionStats(); double zombieRatio = (double) stats.getZombieConnections() / stats.getTotalConnections(); if (zombieRatio \u0026gt; 0.3) { // 僵尸连接超过30% alertService.sendAlert(\u0026#34;僵尸连接比例过高: \u0026#34; + String.format(\u0026#34;%.2f%%\u0026#34;, zombieRatio * 100)); } } } 总结 僵尸连接是长连接服务中的常见问题，特别是在移动互联网环境下。\n关键要点：\n多层检测：应用心跳 + 空闲检测 + 定时清理 合理参数：根据业务场景调整超时时间 监控告警：及时发现和处理异常情况 优雅处理：避免误杀正常连接 在实际项目中，还要根据具体的业务场景和网络环境来调整策略。比如IoT设备的心跳间隔可能需要更长，而实时聊天应用可能需要更短的检测间隔。\n","date":"2019-08-15T14:30:00+08:00","permalink":"https://tech-gt.github.io/p/%E4%BB%80%E4%B9%88%E6%98%AF%E5%83%B5%E5%B0%B8%E8%BF%9E%E6%8E%A5%E5%9F%BA%E4%BA%8Enetty%E9%95%BF%E8%BF%9E%E6%8E%A5%E7%BD%91%E5%85%B3%E7%9A%84%E5%AE%9E%E6%88%98%E5%88%86%E6%9E%90/","title":"什么是僵尸连接？基于Netty长连接网关的实战分析"},{"content":"前言 在压测期间遭遇了从 IllegalReferenceCountException 到各类 502 错误的。\n一 IllegalReferenceCountException 始于一次常规的性能压测。当并发量提升到一定阈值时，控制台开始零星地喷出 io.netty.util.IllegalReferenceCountException: refCnt: 0 异常。\n1 2 3 4 5 6 io.netty.util.IllegalReferenceCountException: refCnt: 0 at io.netty.buffer.AbstractByteBuf.ensureAccessible(AbstractByteBuf.java:1454) at io.netty.buffer.AbstractByteBuf.copy(AbstractByteBuf.java:1194) at com.gateway.service.AsyncHttpForwardService.createBackendRequest(AsyncHttpForwardService.java:224) at com.gateway.service.AsyncHttpForwardService$2.operationComplete(AsyncHttpForwardService.java:168) ... 这个异常指向 originalRequest.content().copy()，明示我们试图操作一个已经被释放的 ByteBuf。\n问题分析：竞态条件 Netty 的 ByteBuf 使用引用计数来管理内存。当我们尝试 retain() 一个已经被 release() 的 ByteBuf 时，就会触发此异常。\n经过对代码逻辑的仔细梳理，我们定位到了一个典型的异步竞态条件 (Race Condition)：\n获取连接: 从连接池获取一个到后端服务的 Channel。 添加处理器: 立即将 BackendResponseHandler 添加到该 Channel 的 pipeline 中。 发送请求: 异步调用 channel.writeAndFlush(request)。 问题就出在第 2 步和第 3 步之间：\n失败路径: 如果 writeAndFlush 操作因为网络原因瞬间失败（例如，连接刚建立就被对端重置），它的 FutureListener 会被触发。 连锁反应: 失败的 Listener 会调用 channel.close()，这会触发 pipeline 上的 channelInactive 事件。 提前释放: BackendResponseHandler 捕获到 channelInactive 事件后，认为请求已经结束，便调用 originalRequest.release()，将请求的引用计数减为 0。 致命一击: 与此同时，writeAndFlush 失败的 Listener 在关闭连接后，还会继续执行重试逻辑，当它再次尝试使用那个已被释放的 request 对象去 copy() 内容时，异常爆发。 解决方案 我们必须保证只有在请求成功发送后，才将响应处理器加入 pipeline。\n1 2 3 4 5 6 7 8 9 10 11 // ... backendChannel.writeAndFlush(backendRequest).addListener(writeFuture -\u0026gt; { if (writeFuture.isSuccess()) { // 请求发送成功后，再添加响应处理器 backendChannel.pipeline().addLast(\u0026#34;responseHandler\u0026#34;, new BackendResponseHandler(...)); } else { // 发送失败，销毁连接并重试 // ... } }); 如果发送失败，BackendResponseHandler 根本没有机会被添加，自然也不会有提前释放资源的问题。\n502问题 解决了引用计数问题后，压测过程平稳了许多。但新的问题随之而来，日志中开始出现 502 错误：{\u0026quot;error\u0026quot;: \u0026quot;Bad Gateway\u0026quot;, \u0026quot;message\u0026quot;: \u0026quot;Backend connection closed unexpectedly\u0026quot;, ...}。\n问题分析：连接池的陷阱 这个问题指向了一个在长连接（Keep-Alive）和连接池模式下非常经典的陷阱——陈旧连接（Stale Connection）。\nKeep-Alive 机制: 为了性能，网关与后端服务之间会复用 TCP 连接。 服务器超时: 后端服务（如 Tomcat）有自己的 Keep-Alive 超时设置。如果一个连接在网关的连接池里闲置过久，后端会单方面关闭它。 “假活”状态: 在网关侧，这个已被后端关闭的连接在被取用之前，可能仍然被认为是 active 的。 失败的请求: 当网关用这个“已死”的连接发送数据时，会立即触发 channelInactive 事件，而我们当时的处理器逻辑只是简单地向客户端返回 502，并未尝试挽救。 解决方案：为“意外断开”赋予重试能力 问题的核心在于，channelInactive 应当被视为一种可重试的瞬态网络错误。\n为了实现这一点，我们进行了一次重构：\n提取统一的重试方法: 我们创建了一个 handleConnectionFailure(...) 方法，它封装了所有重试逻辑（检查次数、延迟执行等）。 让 Handler 变得更“聪明”: BackendResponseHandler 不再是一个简单的响应转换器。我们让它持有重试所需的上下文信息，如 BackendService 和剩余重试次数 retriesLeft。 改造 channelInactive: 修改 channelInactive 的实现，让它在捕获到连接意外关闭时，调用 handleConnectionFailure 来触发重试，而不是直接报错。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 // 在 BackendResponseHandler 中 @Override public void channelInactive(ChannelHandlerContext ctx) throws Exception { if (!processed) { processed = true; // 后端连接意外关闭，这是一个典型的可重试场景 (stale connection) if (gatewayCtx.channel().isActive()) { // 调用统一的失败处理/重试逻辑 handleConnectionFailure(gatewayCtx, originalRequest, service, retriesLeft, \u0026#34;Backend connection closed unexpectedly, retrying...\u0026#34;, null); } else { originalRequest.release(); } } } ##超时与重置\n网关的健壮性已大大提升，但压测日志中仍有概率出现：ReadTimeoutException 和 IOException: Connection reset by peer。\nReadTimeoutException: 网关在指定时间内未收到后端响应。 IOException: 后端服务可能崩溃或重启，强行中止了连接。 这两种同样是典型的瞬态网络错误。我们现有的 exceptionCaught 处理器只会记录日志并返回 502，它需要变得更智能。\n解决方案：精准识别，分类处理 我们不能对所有异常都进行重试（例如 NullPointerException），这可能会掩盖真正的程序 Bug。因此，我们需要对异常进行分类处理。\n创建 isRetryableException 方法: 新增一个辅助方法，专门用于判断一个 Throwable 是否属于可重试的网络异常。\n1 2 3 4 5 6 7 8 9 10 11 private boolean isRetryableException(Throwable cause) { // 读超时，意味着后端可能繁忙，重试可能成功 if (cause instanceof io.netty.handler.timeout.ReadTimeoutException) { return true; } // 连接被重置等IO异常，是典型的网络问题 if (cause instanceof java.io.IOException) { return true; } return false; } 升级 exceptionCaught 方法:\n首先，任何导致 exceptionCaught 的 Channel 都被认为是有问题的，必须强制关闭，绝不放回连接池。 然后，调用 isRetryableException 判断异常类型。 如果是可重试的，就调用 handleConnectionFailure。 如果不是，则快速失败，记录严重错误并返回 502。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { // 抛出异常的 Channel 必须关闭 cleanupAndRelease(ctx, true); if (processed) { return; } processed = true; // 如果是可重试的瞬态网络错误，则尝试重试 if (isRetryableException(cause)) { handleConnectionFailure(gatewayCtx, originalRequest, service, retriesLeft, \u0026#34;Backend connection error, retrying...\u0026#34;, cause); } else { // 对于其他未知错误，快速失败 logger.error(\u0026#34;Non-retryable backend error: \u0026#34;, cause); sendErrorResponse(gatewayCtx, HttpResponseStatus.BAD_GATEWAY, \u0026#34;Backend processing error: \u0026#34; + cause.getMessage()); originalRequest.release(); } } 总结与心得 异步编程，时序为王: 在 Netty 的异步世界里，操作的执行顺序至关重要。错误的顺序是许多并发 Bug 的根源。 重试是服务可靠性的基石: 构建任何网络服务，都必须有一套完善的重试机制。关键在于识别哪些错误是“值得”重试的。 连接池不是银弹: 连接池带来了性能，也带来了“陈旧连接”等管理复杂性。必须主动处理这些问题，而不是期望它能“自动工作”。 异常处理必须精细化: 不要用一个 catch(Exception e) 来处理所有问题。对异常进行分类，区分瞬态网络错误和永久性应用错误，是构建健壮系统的关键。 ","date":"2019-08-12T10:00:00+08:00","permalink":"https://tech-gt.github.io/p/netty-%E7%BD%91%E5%85%B3%E9%97%AE%E9%A2%98%E7%9A%84%E6%8E%92%E6%9F%A5%E4%B8%8E%E4%BF%AE%E5%A4%8D%E8%AE%B0%E5%BD%95/","title":"Netty 网关问题的排查与修复记录"},{"content":"背景：RPC 调试的痛点 在微服务架构中，RPC（Remote Procedure Call）是服务间通信的主流方式。但相比 REST API，RPC 接口的调试一直是个痛点：\n协议复杂：需要手动构造二进制消息 工具匮乏：缺乏像 Postman 这样直观的调试工具 开发效率低：每次调试都要写客户端代码，编译运行 我们的目标：构建一个支持动态协议转换的接口调试工具，让用户上传 .proto 文件后，自动生成对应的 Web 表单，实现 HTTP(JSON) 到 Protobuf/RPC 的转换。\n技术架构设计 整体架构 1 2 3 4 5 6 7 ┌─────────────────┐ ┌─────────────────┐ ┌─────────────────┐ │ Web 前端 │ │ Java 后端 │ │ RPC 服务 │ │ │ │ │ │ │ │ - Proto 文件上传│───▶│ - 协议解析 │───▶│ - gRPC 服务 │ │ - 动态表单生成 │ │ - 消息转换 │ │ - Thrift 服务 │ │ - 请求发送 │ │ - RPC 调用 │ │ - Dubbo 服务 │ └─────────────────┘ └─────────────────┘ └─────────────────┘ 核心组件 协议解析器：解析上传的 .proto 文件，提取服务定义和消息结构 动态表单生成器：根据消息结构自动生成 Web 表单 消息转换器：将 JSON 数据转换为 Protobuf 消息 RPC 客户端管理器：管理不同类型的 RPC 客户端连接 核心实现 1. Proto 文件解析 首先，我们需要解析上传的 .proto 文件，提取服务定义和消息结构。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 @Service public class ProtoFileParser { /** * 解析 Proto 文件，提取服务定义 */ public ProtoServiceInfo parseProtoFile(String protoContent) throws Exception { // 使用 protobuf-java 库解析 DescriptorProtos.FileDescriptorProto fileProto = DescriptorProtos.FileDescriptorProto.parseFrom( generateDescriptorBytes(protoContent) ); ProtoServiceInfo serviceInfo = new ProtoServiceInfo(); // 提取服务定义 for (DescriptorProtos.ServiceDescriptorProto service : fileProto.getServiceList()) { ServiceInfo serviceInfo = new ServiceInfo(); serviceInfo.setName(service.getName()); // 提取方法定义 for (DescriptorProtos.MethodDescriptorProto method : service.getMethodList()) { MethodInfo methodInfo = new MethodInfo(); methodInfo.setName(method.getName()); methodInfo.setInputType(method.getInputType()); methodInfo.setOutputType(method.getOutputType()); serviceInfo.addMethod(methodInfo); } serviceInfo.addService(serviceInfo); } return serviceInfo; } /** * 根据消息类型名获取消息结构 */ public MessageStructure getMessageStructure(String messageTypeName) { // 通过反射获取消息类的字段信息 Class\u0026lt;?\u0026gt; messageClass = getMessageClass(messageTypeName); MessageStructure structure = new MessageStructure(); for (Field field : messageClass.getDeclaredFields()) { FieldInfo fieldInfo = new FieldInfo(); fieldInfo.setName(field.getName()); fieldInfo.setType(getFieldType(field)); fieldInfo.setRequired(isRequiredField(field)); structure.addField(fieldInfo); } return structure; } } 2. 动态表单生成 根据解析出的消息结构，动态生成 Web 表单。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 @Component public class DynamicFormGenerator { /** * 根据消息结构生成表单配置 */ public FormConfig generateFormConfig(MessageStructure structure) { FormConfig config = new FormConfig(); for (FieldInfo field : structure.getFields()) { FormField formField = new FormField(); formField.setName(field.getName()); formField.setLabel(generateFieldLabel(field.getName())); formField.setType(determineInputType(field.getType())); formField.setRequired(field.isRequired()); // 处理嵌套消息 if (field.getType().isMessage()) { formField.setNestedConfig(generateFormConfig(field.getType().getMessageStructure())); } // 处理重复字段（数组） if (field.getType().isRepeated()) { formField.setArray(true); } config.addField(formField); } return config; } /** * 确定输入类型 */ private String determineInputType(FieldType fieldType) { switch (fieldType.getBaseType()) { case STRING: return \u0026#34;text\u0026#34;; case INT32: case INT64: return \u0026#34;number\u0026#34;; case BOOL: return \u0026#34;checkbox\u0026#34;; case DOUBLE: case FLOAT: return \u0026#34;number\u0026#34;; case BYTES: return \u0026#34;file\u0026#34;; default: return \u0026#34;text\u0026#34;; } } } 3. JSON 到 Protobuf 转换 核心功能：将用户提交的 JSON 数据转换为 Protobuf 消息。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 @Component public class MessageConverter { /** * 将 JSON 转换为 Protobuf 消息 */ public Message jsonToProtobuf(String jsonData, String messageTypeName) throws Exception { // 获取消息构建器 Message.Builder builder = getMessageBuilder(messageTypeName); // 解析 JSON JsonNode jsonNode = objectMapper.readTree(jsonData); // 递归设置字段值 setFieldsFromJson(builder, jsonNode, getMessageDescriptor(messageTypeName)); return builder.build(); } /** * 递归设置字段值 */ private void setFieldsFromJson(Message.Builder builder, JsonNode jsonNode, Descriptors.Descriptor descriptor) { for (Descriptors.FieldDescriptor field : descriptor.getFields()) { String fieldName = field.getName(); if (!jsonNode.has(fieldName)) { continue; } JsonNode fieldValue = jsonNode.get(fieldName); if (field.isRepeated()) { // 处理重复字段 if (fieldValue.isArray()) { for (JsonNode item : fieldValue) { addRepeatedField(builder, field, item); } } } else { // 处理单个字段 setSingleField(builder, field, fieldValue); } } } /** * 设置单个字段值 */ private void setSingleField(Message.Builder builder, Descriptors.FieldDescriptor field, JsonNode value) { switch (field.getType()) { case STRING: builder.setField(field, value.asText()); break; case INT32: builder.setField(field, value.asInt()); break; case INT64: builder.setField(field, value.asLong()); break; case BOOL: builder.setField(field, value.asBoolean()); break; case DOUBLE: builder.setField(field, value.asDouble()); break; case MESSAGE: // 处理嵌套消息 Message.Builder nestedBuilder = builder.newBuilderForField(field); setFieldsFromJson(nestedBuilder, value, field.getMessageType()); builder.setField(field, nestedBuilder.build()); break; } } } 4. RPC 客户端管理 支持多种 RPC 协议的统一客户端管理。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 @Component public class RpcClientManager { private final Map\u0026lt;String, RpcClient\u0026gt; clients = new ConcurrentHashMap\u0026lt;\u0026gt;(); /** * 创建 gRPC 客户端 */ public RpcClient createGrpcClient(String serviceUrl) { ManagedChannel channel = ManagedChannelBuilder.forTarget(serviceUrl) .usePlaintext() .build(); GrpcClient client = new GrpcClient(channel); clients.put(serviceUrl, client); return client; } /** * 执行 RPC 调用 */ public Object executeRpcCall(String serviceUrl, String methodName, Message request, String responseType) throws Exception { RpcClient client = clients.get(serviceUrl); if (client == null) { client = createGrpcClient(serviceUrl); } return client.call(methodName, request, responseType); } } /** * gRPC 客户端实现 */ public class GrpcClient implements RpcClient { private final ManagedChannel channel; public GrpcClient(ManagedChannel channel) { this.channel = channel; } @Override public Object call(String methodName, Message request, String responseType) throws Exception { // 通过反射调用 gRPC 方法 Class\u0026lt;?\u0026gt; serviceClass = getServiceClass(methodName); Object serviceStub = getServiceStub(serviceClass, channel); Method method = findMethod(serviceClass, methodName); return method.invoke(serviceStub, request); } } 5. Web 控制器 提供 REST API 接口供前端调用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 @RestController @RequestMapping(\u0026#34;/api/rpc-debug\u0026#34;) public class RpcDebugController { @Autowired private ProtoFileParser protoParser; @Autowired private DynamicFormGenerator formGenerator; @Autowired private MessageConverter messageConverter; @Autowired private RpcClientManager clientManager; /** * 上传 Proto 文件并解析 */ @PostMapping(\u0026#34;/upload-proto\u0026#34;) public ResponseEntity\u0026lt;ProtoServiceInfo\u0026gt; uploadProtoFile(@RequestParam(\u0026#34;file\u0026#34;) MultipartFile file) { try { String protoContent = new String(file.getBytes(), StandardCharsets.UTF_8); ProtoServiceInfo serviceInfo = protoParser.parseProtoFile(protoContent); return ResponseEntity.ok(serviceInfo); } catch (Exception e) { return ResponseEntity.badRequest().build(); } } /** * 获取方法对应的表单配置 */ @GetMapping(\u0026#34;/form-config/{messageType}\u0026#34;) public ResponseEntity\u0026lt;FormConfig\u0026gt; getFormConfig(@PathVariable String messageType) { try { MessageStructure structure = protoParser.getMessageStructure(messageType); FormConfig config = formGenerator.generateFormConfig(structure); return ResponseEntity.ok(config); } catch (Exception e) { return ResponseEntity.badRequest().build(); } } /** * 执行 RPC 调用 */ @PostMapping(\u0026#34;/execute\u0026#34;) public ResponseEntity\u0026lt;Object\u0026gt; executeRpcCall(@RequestBody RpcCallRequest request) { try { // 转换 JSON 到 Protobuf Message protobufMessage = messageConverter.jsonToProtobuf( request.getJsonData(), request.getRequestType() ); // 执行 RPC 调用 Object result = clientManager.executeRpcCall( request.getServiceUrl(), request.getMethodName(), protobufMessage, request.getResponseType() ); return ResponseEntity.ok(result); } catch (Exception e) { return ResponseEntity.badRequest().body(e.getMessage()); } } } 前端实现要点 1. 动态表单渲染 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 // 根据后端返回的表单配置动态渲染表单 function renderDynamicForm(formConfig) { const form = document.createElement(\u0026#39;form\u0026#39;); formConfig.fields.forEach(field =\u0026gt; { const fieldElement = createFormField(field); form.appendChild(fieldElement); }); return form; } function createFormField(field) { const container = document.createElement(\u0026#39;div\u0026#39;); const label = document.createElement(\u0026#39;label\u0026#39;); label.textContent = field.label; let input; switch (field.type) { case \u0026#39;text\u0026#39;: input = document.createElement(\u0026#39;input\u0026#39;); input.type = \u0026#39;text\u0026#39;; break; case \u0026#39;number\u0026#39;: input = document.createElement(\u0026#39;input\u0026#39;); input.type = \u0026#39;number\u0026#39;; break; case \u0026#39;checkbox\u0026#39;: input = document.createElement(\u0026#39;input\u0026#39;); input.type = \u0026#39;checkbox\u0026#39;; break; case \u0026#39;array\u0026#39;: input = createArrayField(field); break; case \u0026#39;nested\u0026#39;: input = createNestedField(field); break; } input.name = field.name; input.required = field.required; container.appendChild(label); container.appendChild(input); return container; } 2. 表单数据收集 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 function collectFormData(form) { const formData = new FormData(form); const jsonData = {}; for (let [key, value] of formData.entries()) { setNestedValue(jsonData, key, value); } return jsonData; } function setNestedValue(obj, path, value) { const keys = path.split(\u0026#39;.\u0026#39;); let current = obj; for (let i = 0; i \u0026lt; keys.length - 1; i++) { const key = keys[i]; if (!current[key]) { current[key] = {}; } current = current[key]; } current[keys[keys.length - 1]] = value; } 2. 支持更多 RPC 协议 1 2 3 4 5 6 7 8 9 // 支持 Thrift public class ThriftClient implements RpcClient { // Thrift 客户端实现 } // 支持 Dubbo public class DubboClient implements RpcClient { // Dubbo 客户端实现 } 总结 通过这个动态协议转换工具，我们实现了：\n协议解析：自动解析 .proto 文件，提取服务定义 动态表单：根据消息结构自动生成 Web 表单 消息转换：JSON 到 Protobuf 的自动转换 统一调用：支持多种 RPC 协议的统一调用接口 这样，RPC 接口调试就变得像 REST API 一样简单了！用户只需要：\n上传 .proto 文件 选择要调用的方法 填写表单数据 点击发送 工具会自动处理所有的协议转换和 RPC 调用细节。\n告别手动写 RPC 客户端代码，让接口调试变得优雅而高效！\n","date":"2018-11-28T09:15:00+08:00","permalink":"https://tech-gt.github.io/p/%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%8A%A8%E6%80%81%E5%8D%8F%E8%AE%AE%E8%BD%AC%E6%8D%A2%E7%9A%84%E6%8E%A5%E5%8F%A3%E8%B0%83%E8%AF%95%E5%B7%A5%E5%85%B7/","title":"构建一个动态协议转换的接口调试工具"}]